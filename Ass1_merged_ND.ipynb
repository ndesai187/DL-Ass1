{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Ass1_merged_ND.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OigpLIHWTQU5"
      },
      "source": [
        "# COMP5329 - Deep Learning\n",
        "## Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxMRrQEBTQU7"
      },
      "source": [
        "\n",
        "\n",
        "## Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiIktNG2TQU8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl\n",
        "from ipywidgets import interact, widgets\n",
        "from matplotlib import animation\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfknvYWYTQU_"
      },
      "source": [
        " ## Mount and load dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiIehkfrx3zC",
        "outputId": "ca2e4f25-29f5-4ab8-d552-908dd7e7fb77"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g4wZR_MxCg23TVXjKgxY54pByOdJAY267mCvu-bgBAwQ-hdDqQep1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOTWTdCXySpK"
      },
      "source": [
        "train_data_whole = np.load('/content/gdrive/MyDrive/COMP5329/Assignment1-Dataset/train_data.npy')\n",
        "test_data = np.load('/content/gdrive/MyDrive/COMP5329/Assignment1-Dataset/test_data.npy')\n",
        "\n",
        "train_label_whole = np.load('/content/gdrive/MyDrive/COMP5329/Assignment1-Dataset/train_label.npy')\n",
        "test_label = np.load('/content/gdrive/MyDrive/COMP5329/Assignment1-Dataset/test_label.npy')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS5Og5PG3meN"
      },
      "source": [
        "### Train and Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlt97Gk_3ln9",
        "outputId": "df9be1a1-d911-4d70-9971-1cf92b7b7afe"
      },
      "source": [
        "def train_validation_split(data_to_split, labels_to_split, \n",
        "                           train_pct = 0.75, validation_pct = 0.25, \n",
        "                           seed_param=0):\n",
        "  np.random.seed(seed_param)\n",
        "  index_len = len(data_to_split)\n",
        "  random_indices = np.random.permutation(index_len)\n",
        "  split_index = int(train_pct * index_len)\n",
        "  train_data = np.take(data_to_split, random_indices[0:split_index],axis=0)\n",
        "  train_label = np.take(labels_to_split, random_indices[0:split_index],axis=0)\n",
        "  validation_data = np.take(data_to_split, random_indices[split_index:],axis=0)\n",
        "  validation_label = np.take(labels_to_split, random_indices[split_index:],axis=0)\n",
        "  return train_data, train_label, validation_data, validation_label\n",
        "  # print(random_indices)\n",
        "  # print(len(random_indices))\n",
        "  # print(split_index)\n",
        "  # print(train_data.shape)\n",
        "  # print(validation_data.shape)\n",
        "  # print(train_data[0] == data_to_split[20354])\n",
        "  # print(train_data[2] == data_to_split[49384])\n",
        "  # print(train_label[0] == labels_to_split[20354])\n",
        "  # print(train_label[2] == labels_to_split[49384])\n",
        "  # print(validation_data[-1] == data_to_split[40689])\n",
        "  # print(validation_data[-3] == data_to_split[9227])\n",
        "  # print(validation_label[-1] == labels_to_split[40689])\n",
        "  # print(validation_label[-3] == labels_to_split[9227])\n",
        "\n",
        "\n",
        "train_data, train_label, valid_data, valid_label = train_validation_split(train_data_whole,\n",
        "                                                                          train_label_whole,\n",
        "                                                                          seed_param=180)\n",
        "\n",
        "print(\"Training data : {} split into => train set : {}, and validation set : {}\".format(train_data_whole.shape,\n",
        "                                                                                        train_data.shape,\n",
        "                                                                                        valid_data.shape))\n",
        "print(\"Similarly, Training labels : {} split into => train labels : {}, and validation labels : {}\".format(\n",
        "                                                                              train_label_whole.shape,\n",
        "                                                                              train_label.shape,\n",
        "                                                                              valid_label.shape))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data : (50000, 128) split into => train set : (37500, 128), and validation set : (12500, 128)\n",
            "Similarly, Training labels : (50000, 1) split into => train labels : (37500, 1), and validation labels : (12500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1YLqe0zTQVF"
      },
      "source": [
        "## Dataset exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSvKdlYXAFTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b97680f-0f20-4f2d-9068-a57461943798"
      },
      "source": [
        "print('Shape of training data: ', train_data.shape)\n",
        "print('Shape of testing data: ', test_data.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data:  (37500, 128)\n",
            "Shape of testing data:  (10000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1jR3qaDNavg"
      },
      "source": [
        "unique_labels=np.unique(train_label)\n",
        "\n",
        "# add a dummy value of 100 for binning using histogram function\n",
        "bin_size = np.append(unique_labels,[100])\n",
        "plot_points = np.histogram(train_label, bins=bin_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxNa99zkwEmY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "4171058c-09a3-4459-e146-c0f6b7ad7e96"
      },
      "source": [
        "%matplotlib inline\n",
        "pl.rcParams['figure.figsize'] = [8, 8]\n",
        "pl.title('Training Data Label Distribution')\n",
        "pl.ylabel('Count of Samples')\n",
        "pl.xlabel('Prediction Label')\n",
        "pl.xticks(np.arange(0,10,1))\n",
        "pl.bar(plot_points[1][:-1], plot_points[0], width=0.5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "zkPOlBuPNkDU",
        "outputId": "b53002ca-0fca-4b29-b3d5-686afd090266"
      },
      "source": [
        "pl.rcParams['figure.figsize'] = [14,8]\n",
        "fig1, ax1 = pl.subplots()\n",
        "random_features=np.random.randint(0,train_data.shape[1]-1,15)\n",
        "ax1.set_title('Feature distribution for random selection')\n",
        "ax1.set_xlabel('Feature Index')\n",
        "ax1.set_xticklabels(random_features)\n",
        "ax1.boxplot(train_data[:,random_features])\n",
        "pl.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHlA1Tvreu9W"
      },
      "source": [
        "# Pre Processing\n",
        "### Normalise Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf-pV6MdaVFU"
      },
      "source": [
        "# Define Normalisation function with Zero Mean and unit variance\n",
        "def normalize_data(data_set):\n",
        "  \"\"\"\n",
        "    argument\n",
        "      - Input numpy array\n",
        "    Return\n",
        "      - Array returned with zero Mean and unit variance\n",
        "  \"\"\"\n",
        "  mu = data_set.mean(0)\n",
        "  stdv = data_set.std(0)\n",
        "  normalized_data_set = (data_set - mu) / stdv\n",
        "  return normalized_data_set\n",
        "\n",
        "\n",
        "norm_train_data = normalize_data(train_data)\n",
        "norm_test_data = normalize_data(test_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "b0qDtUGqgM-T",
        "outputId": "c1c1c4b3-6baa-4883-ebb1-37b2dbca1c95"
      },
      "source": [
        "pl.rcParams['figure.figsize'] = [14,8]\n",
        "fig2, ax2 = pl.subplots()\n",
        "ax2.set_title('Feature distribution for random selection')\n",
        "ax2.set_xlabel('Feature Index')\n",
        "ax2.set_xticklabels(random_features)\n",
        "ax2.boxplot(norm_train_data[:,random_features])\n",
        "pl.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaKjlOWo_8E0"
      },
      "source": [
        "#### One hot Encoding Target labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nzkqH713Zyi",
        "outputId": "a27959cc-9369-4ea1-8470-ddcc0e1c14bd"
      },
      "source": [
        "def one_hot_encoder(arry):\n",
        "  arry_flat = arry.flatten()\n",
        "  class_lables = arry.max() + 1\n",
        "  return np.eye(class_lables)[arry_flat]\n",
        "# a = np.array([1, 0, 3])\n",
        "# a = test_label[0:3,:]\n",
        "# a_flatten = a.flatten()\n",
        "# print(a, a_flatten)\n",
        "# print(a_flatten.size)\n",
        "# b = np.zeros((a_flatten.size, a.max()+1))\n",
        "# b[np.arange(a_flatten.size),a] = 1\n",
        "# print(b)\n",
        "\n",
        "# #values = [1, 0, 3]\n",
        "# n_values = a.max()+1\n",
        "# np.eye(n_values)[a_flatten]\n",
        "\n",
        "\n",
        "y_train_label = one_hot_encoder(train_label)\n",
        "print(y_train_label.shape)\n",
        "print(train_label.shape)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37500, 10)\n",
            "(37500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBbVI6fyTQVI"
      },
      "source": [
        "## Definition of selected activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4ZooR-OTQVK"
      },
      "source": [
        "Linear\n",
        "$$output = x$$\n",
        "\n",
        "Tanh  \n",
        "$$output = tanh(x)$$  \n",
        "\n",
        "Sigmoid\n",
        "$$output = \\frac {1}{1 + e^{-x}}$$\n",
        "\n",
        "ReLU\n",
        "$$output = \\max\\{0, x\\}$$\n",
        "\n",
        "#CHANGES MADE: \n",
        "Added softmax layer... need to add the softmax derivative somewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csIF2JfSTQVK"
      },
      "source": [
        "# create class for activation functions\n",
        "\n",
        "class Activation(object):\n",
        "    def __tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "    def __tanh_deriv(self, a):\n",
        "        # a = np.tanh(x)   \n",
        "        return 1.0 - a**2\n",
        "\n",
        "    def __logistic(self, x):\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "    def __logistic_deriv(self, a):\n",
        "        # a = logistic(x) \n",
        "        return  a * (1 - a )\n",
        "\n",
        "    def __relu(self,x): \n",
        "        return np.maximum(0,x)\n",
        "    def __relu_deriv(self, a): #what about case when x = 0? Derivative should be 1\n",
        "        # a = max{0,x}\n",
        "        return 1.0*(a>0)\n",
        "\n",
        "    def __sigmoid(self, x):\n",
        "        return 1/np.exp(-x)\n",
        "    def __sigmoid_deriv(self,a):\n",
        "        return a*(1-a)\n",
        "\n",
        "    def __softmax(self, x):\n",
        "        exps = np.exp(x)\n",
        "        print(\"softmax exp : {} , exp[0] : {} \".format(exps.shape, exps[0]))\n",
        "        total_sums = np.sum(exps, axis = 1, keepdims=True) \n",
        "        print(\"softmax sums : {} , sums[0] : {} \".format(total_sums.shape, total_sums[0]))\n",
        "        softmax_out = exps/total_sums\n",
        "        print(\"softmax shape : {} , output[0] : {} \".format(softmax_out.shape, softmax_out[0]))\n",
        "        print(\"softmax check : {}\".format(np.sum(softmax_out[0:10,],axis=1)))\n",
        "        return softmax_out\n",
        "        # returns Cx1 vector of probabilities\n",
        "        ## Possibly needed for minibatch - returns Cxm matrix (C = #categories, m = #observations)\n",
        "        # t = np.exp(x)\n",
        "        # total = np.sum(t, axis = 1)\n",
        "        # return t/total[:, None]\n",
        "        # def __softmax_deriv(): ## softmax partial derivative = y_hat - y...? define in hidden layer section?\n",
        "    \n",
        "    def __init__(self,activation='tanh'):\n",
        "        if activation == 'logistic':\n",
        "            self.f = self.__logistic\n",
        "            self.f_deriv = self.__logistic_deriv\n",
        "        elif activation == 'tanh':\n",
        "            self.f = self.__tanh\n",
        "            self.f_deriv = self.__tanh_deriv\n",
        "        elif activation == 'relu':\n",
        "            self.f = self.__relu\n",
        "            self.f_deriv = self.__relu_deriv\n",
        "        elif activation == 'sigmoid':\n",
        "            self.f = self.__sigmoid\n",
        "            self.f_deriv = self.__sigmoid_deriv\n",
        "        elif activation == 'softmax':\n",
        "            self.f = self.__softmax\n",
        "        "
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfpecqvfaqJX"
      },
      "source": [
        "### Define softmax layer\n",
        "\n",
        "Softmax layer is used in multi-class classification problems to assign conditional probabilities of $x$ belonging to class $k$: \n",
        "\n",
        "$$ \\hat{P}(class_k|x) = z_k = \\frac{e^{net_k}}{\\sum_{i=1}^K e^{net_i}} $$ \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m4Q29g8aycn"
      },
      "source": [
        "# define softmax layer\n",
        "# def softmax(x):\n",
        "#     \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "#     e_x = np.exp(x - np.max(x))\n",
        "#     return e_x / e_x.sum(axis=1) # only difference\n",
        "\n",
        "# Check Softmax dimensions at the end\n",
        "\n",
        "  "
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91dBdVq4TQVN"
      },
      "source": [
        "### Define HiddenLayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBnDirODTQVO"
      },
      "source": [
        "$$output = f_{act}(\\sum_{i=0}^{1}{(I_{i} * W_{i})} + b)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GymZcsO0TQVO"
      },
      "source": [
        "# now we define the hidden layer for the mlp\n",
        "# for example, h1 = HiddenLayer(10, 5, activation=\"tanh\") means we create a layer with 10 dimension input and 5 dimension output, and using tanh activation function.\n",
        "# notes: make sure the input size of middle layer is matched with the output size of the previous layer!\n",
        "\n",
        "## Need to see where the dimensionality gets matched!\n",
        "class HiddenLayer(object):    \n",
        "    def __init__(self,n_in, n_out,\n",
        "                 activation_last_layer='tanh',activation='tanh', W=None, b=None):\n",
        "        \"\"\"\n",
        "        Typical hidden layer of a MLP: units are fully-connected and have\n",
        "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
        "        and the bias vector b is of shape (n_out,).\n",
        "\n",
        "        NOTE : The nonlinearity used here is tanh\n",
        "\n",
        "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
        "\n",
        "        :type n_in: int\n",
        "        :param n_in: dimensionality of input\n",
        "\n",
        "        :type n_out: int\n",
        "        :param n_out: number of hidden units\n",
        "\n",
        "        :type activation: string\n",
        "        :param activation: Non linearity to be applied in the hidden\n",
        "                           layer\n",
        "        \"\"\"\n",
        "        self.input=None\n",
        "        self.activation=Activation(activation).f\n",
        "        \n",
        "        # activation deriv of last layer\n",
        "        self.activation_deriv=None\n",
        "        if activation_last_layer:\n",
        "            self.activation_deriv=Activation(activation_last_layer).f_deriv\n",
        "\n",
        "        # we randomly assign small values for the weights as the initialization\n",
        "        # good weight initialisation is important for model performance! \n",
        "        # These numbers come from Xavier weight initialisation - intialise weights\n",
        "        # by taking a random sample from a uniform distribution, bounded by 'low' \n",
        "        # and 'high' - bounds depend on the n_in and n_out\n",
        "        # Good weight initialisation is important for faster convergence\n",
        "        # Look up good weight initialisation for good values for each activation fn\n",
        "\n",
        "        ## https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/#:~:text=each%20in%20turn.-,Xavier%20Weight%20Initialization,of%20inputs%20to%20the%20node.\n",
        "        # normalised xavier initialisation is drawn from U(-(sqrt(6)/sqrt(n + m)) and sqrt(6)/sqrt(n + m)) distribution\n",
        "        # commonly used for sigmoid and tanh functions - although derived with the assumption that the activation is linear (not actually the case with these functions)\n",
        "        # makes sense for activations which are symmetric about zero and have outputs within [-1,1]\n",
        "        # see https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79 \n",
        "        self.W = np.random.uniform(\n",
        "                low=-np.sqrt(6. / (n_in + n_out)),\n",
        "                high=np.sqrt(6. / (n_in + n_out)),\n",
        "                size=(n_in, n_out)\n",
        "        )\n",
        "        if activation == 'logistic':\n",
        "            self.W *= 4\n",
        "\n",
        "        # reLU weight initialisation - He initialisation (simulate from N(0, sigma^2 = (2/n)))\n",
        "        if activation == 'relu': \n",
        "            sigma = np.sqrt(2/n_in)\n",
        "            self.W = np.random.normal(loc = 0, scale = sigma, size = (n_in, n_out))\n",
        "\n",
        "        # set the size of bias as the size of output dimension\n",
        "        self.b = np.zeros((1,n_out))\n",
        "        \n",
        "        # set the size of weight gradation as the size of weight\n",
        "        self.grad_W = np.zeros(self.W.shape)\n",
        "        self.grad_b = np.zeros(self.b.shape)\n",
        "        print(\"At initilization, grad_W.shape : {}, grad_b.shape : {},  W.shape : {}, b.shape : {}\".format(\n",
        "            self.grad_W.shape, self.grad_b.shape, self.W.shape, self.b.shape))\n",
        "\n",
        "    \n",
        "    # forward and backward progress for each training epoch\n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        :type input: numpy.array\n",
        "        :param input: a symbolic tensor of shape (n_in,)\n",
        "        '''\n",
        "        lin_output = np.dot(input, self.W) + self.b\n",
        "        print(\"At forward, input.shape : {}, lin_output.shape : {}\".format(input.shape, lin_output.shape))\n",
        "        self.output = (\n",
        "            lin_output if self.activation is None\n",
        "            else self.activation(lin_output)\n",
        "        )\n",
        "        self.input=input\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, delta, output_layer=False):         \n",
        "        self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta))\n",
        "        # self.grad_b = delta\n",
        "        self.grad_b = np.sum(delta, axis=0, keepdims = True)\n",
        "        if self.activation_deriv:\n",
        "            delta = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
        "        return delta"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwsUH3fhTQVR"
      },
      "source": [
        "## The MLP\n",
        "\n",
        "The class implements a MLP with a fully configurable number of layers and neurons. It adapts its weights using the backpropagation algorithm in an online manner.\n",
        "\n",
        "# EDITS MADE:\n",
        "Changes: added function criterion_cross_entropy()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU9V8FdQhn9g",
        "outputId": "8f9c383b-71a0-4288-d826-c0ecc668fe64"
      },
      "source": [
        "dum1 = np.random.random((5,5))\n",
        "dum2 = np.argmax(dum1, axis=1)\n",
        "print(dum1, \"and\", dum2)\n",
        "print(dum1[range(dum1.shape[0]), dum2])\n",
        "dum2 -= 1\n",
        "print(dum2)\n",
        "np.mean([128,10])\n",
        "np.mean([69,10])\n",
        "\n",
        "print(np.zeros((1,3)))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.46683264 0.76547035 0.5535929  0.35728203 0.63120001]\n",
            " [0.79740055 0.22782478 0.71332774 0.69751062 0.38488733]\n",
            " [0.36380833 0.93363651 0.79285894 0.63538327 0.03776742]\n",
            " [0.97974211 0.71528159 0.36670772 0.63230726 0.0683242 ]\n",
            " [0.08203685 0.68825337 0.14344253 0.98186976 0.69424622]] and [1 0 1 0 3]\n",
            "[0.76547035 0.79740055 0.93363651 0.97974211 0.98186976]\n",
            "[ 0 -1  0 -1  2]\n",
            "[[0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWpvH41iTQVR"
      },
      "source": [
        "class MLP:\n",
        "    \"\"\"\n",
        "    \"\"\" \n",
        "\n",
        "    # for initialization, the code will create all layers automatically based on the provided parameters.     \n",
        "    def __init__(self, layers, activation=[None,'relu','relu','softmax'],\n",
        "                 batch_norm_enabled = False):\n",
        "        \"\"\"\n",
        "        :param layers: A list containing the number of units in each layer.\n",
        "        Should be at least two values\n",
        "        :param activation: The activation function to be used\n",
        "        \"\"\"        \n",
        "        ### initialize layers\n",
        "        self.layers=[]\n",
        "        self.params=[]\n",
        "        \n",
        "        self.activation=activation\n",
        "        for i in range(len(layers)-1):\n",
        "            self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1]))\n",
        "\n",
        "    # forward progress: pass the information through the layers and out the results of final output layer\n",
        "    # HMMMM - REREAD?\n",
        "    def forward(self,input):\n",
        "        for layer in self.layers:\n",
        "            output=layer.forward(input)\n",
        "            input=output\n",
        "        return output\n",
        "\n",
        "    \n",
        "    # # define cross-entropy loss function\n",
        "    def criterion_cross_entropy(self, y_pred, y_target):\n",
        "        total_targets = y_target.shape[0] # total number of targets\n",
        "        target_idx = np.argmax(y_target, axis=1)\n",
        "        negLogLoss = -np.log(y_pred[range(total_targets), target_idx]) # multiply by target value not required as target values = 1 (target probability)\n",
        "        y_pred[range(total_targets), target_idx] -= 1 # again target probabilities = 1\n",
        "        delta = y_pred / total_targets\n",
        "        loss = np.sum(negLogLoss) / total_targets\n",
        "        print(\"loss shape : {} , loss[0] : {}, delta shape : {}, delta[0] : {}\".format(\n",
        "            loss.shape, loss, delta.shape, delta[0]\n",
        "        ))\n",
        "        return loss, delta\n",
        "\n",
        "\n",
        "    # backward progress  \n",
        "    def backward(self,delta):\n",
        "        delta=self.layers[-1].backward(delta,output_layer=True)\n",
        "        for layer in reversed(self.layers[:-1]):\n",
        "            delta=layer.backward(delta)\n",
        "\n",
        "    # update the network weights after backward.\n",
        "    # make sure you run the backward function before the update function!    \n",
        "    def update(self,lr):\n",
        "        for layer in self.layers:\n",
        "            print(\"At Update, grad_W.shape : {}, grad_b.shape : {},  W.shape : {}, b.shape : {}\".format(\n",
        "                layer.grad_W.shape, layer.grad_b.shape, layer.W.shape, layer.b.shape))\n",
        "            layer.W -= lr * layer.grad_W\n",
        "            layer.b -= lr * layer.grad_b\n",
        " \n",
        "    # define the training function\n",
        "    # it will return all losses within the whole training process.\n",
        "    def fit(self,X,y,learning_rate=0.1, epochs=100):\n",
        "        \"\"\"\n",
        "        Online learning.\n",
        "        :param X: Input data or features\n",
        "        :param y: Input targets\n",
        "        :param learning_rate: parameters defining the speed of learning\n",
        "        :param epochs: number of times the dataset is presented to the network for learning\n",
        "\n",
        "        returns: np.array of size (epochs,)\n",
        "        \"\"\" \n",
        "        # X=np.array(X)\n",
        "        # y=np.array(y)\n",
        "        to_return = np.zeros(epochs)\n",
        "        \n",
        "\n",
        "        # THIS NEEDS TO BE EDITED - currently takes in one observation at a time (SGD - need minibatch)\n",
        "        for k in range(epochs):\n",
        "            loss=np.zeros(X.shape[0])\n",
        "                          \n",
        "            # forward pass\n",
        "            y_pred = self.forward(X)\n",
        "                \n",
        "            # backward pass\n",
        "            loss[k],delta=self.criterion_cross_entropy(y_pred, y)\n",
        "            self.backward(delta)\n",
        "            \n",
        "            # update\n",
        "            self.update(learning_rate)\n",
        "            to_return[k] = np.mean(loss)\n",
        "        return to_return\n",
        "\n",
        "    # define the prediction function\n",
        "    # we can use predict function to predict the results of new data using the trained network.\n",
        "    def predict(self, x):\n",
        "        x = np.array(x)\n",
        "        output = np.zeros(x.shape[0])\n",
        "        for i in np.arange(x.shape[0]):\n",
        "            output[i] = self.forward(x[i,:])\n",
        "        return output"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlgcO0CNTQVU"
      },
      "source": [
        "## Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu7RlvZYTQVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afb5c2a-d209-448f-8732-cc03ae1904e7"
      },
      "source": [
        "### Test subset of training set\n",
        "input_sample_x = train_data[:2000, ]\n",
        "input_sample_y = y_train_label[:2000,]\n",
        "print(input_sample_x.shape, input_sample_y.shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 128) (2000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEo7LPtITQVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950e754a-32dc-48ba-b4fb-dd4ab1b5b422"
      },
      "source": [
        "### Try different learning rate and epochs\n",
        "nn = MLP([128,64,32,10], [None,'relu','relu', 'softmax'])\n",
        "MSE = nn.fit(input_sample_x, input_sample_y , learning_rate=0.01, epochs=500)\n",
        "print('loss:%f'%MSE[-1])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  8.27886403e-05 -2.98728020e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.13785644 0.78720189 0.45914737 0.6233234  0.10723518 0.22258143\n",
            " 0.06873899 0.22659842 1.01426692 2.45336695] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.100317] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02259824 0.12904278 0.07526615 0.10217885 0.01757862 0.03648686\n",
            " 0.0112681  0.03714535 0.16626463 0.4021704 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.2061052050301404, delta shape : (2000, 10), delta[0] : [ 1.12991209e-05  6.45213924e-05  3.76330744e-05  5.10894271e-05\n",
            "  8.78931245e-06  1.82434314e-05  5.63405076e-06  1.85726760e-05\n",
            "  8.31323129e-05 -2.98914798e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.13821074 0.7888175  0.4587806  0.62209216 0.1070698  0.22220084\n",
            " 0.06847046 0.22691394 1.01916234 2.45282398] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.10454236] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02264064 0.12921812 0.07515397 0.10190644 0.01753937 0.03639926\n",
            " 0.01121631 0.03717133 0.16695147 0.40180309] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.2049085890864726, delta shape : (2000, 10), delta[0] : [ 1.13203192e-05  6.46090609e-05  3.75769856e-05  5.09532181e-05\n",
            "  8.76968300e-06  1.81996310e-05  5.60815680e-06  1.85856638e-05\n",
            "  8.34757366e-05 -2.99098455e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.13856225 0.79043139 0.45840486 0.62088041 0.10690014 0.22182196\n",
            " 0.06820316 0.22723767 1.02406356 2.45226395] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.10876936] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02268252 0.1293929  0.07504046 0.10163756 0.01749946 0.03631205\n",
            " 0.01116479 0.0371986  0.16763828 0.40143338] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.2037150513245267, delta shape : (2000, 10), delta[0] : [ 1.13412575e-05  6.46964507e-05  3.75202299e-05  5.08187797e-05\n",
            "  8.74972826e-06  1.81560268e-05  5.58239734e-06  1.85993000e-05\n",
            "  8.38191378e-05 -2.99283308e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.13891591 0.79207433 0.4580179  0.61971902 0.10673303 0.22144026\n",
            " 0.06794096 0.22754786 1.02898199 2.45183234] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.11320361] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02272391 0.1295678  0.07492273 0.10137386 0.01745943 0.03622328\n",
            " 0.01111381 0.03722236 0.16832124 0.4010716 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.202522852444601, delta shape : (2000, 10), delta[0] : [ 1.13619568e-05  6.47838990e-05  3.74613647e-05  5.06869279e-05\n",
            "  8.72971309e-06  1.81116378e-05  5.55690341e-06  1.86111798e-05\n",
            "  8.41606185e-05 -2.99464201e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.13926989 0.79381708 0.45759712 0.61862408 0.10655814 0.22105639\n",
            " 0.06767917 0.22785393 1.03384355 2.45125551] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.11755486] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02276561 0.12976052 0.07480066 0.10112277 0.01741842 0.03613476\n",
            " 0.01106311 0.03724592 0.1689962  0.40069204] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.201335315697066, delta shape : (2000, 10), delta[0] : [ 1.13828064e-05  6.48802582e-05  3.74003286e-05  5.05613841e-05\n",
            "  8.70920972e-06  1.80673811e-05  5.53155428e-06  1.86229575e-05\n",
            "  8.44981023e-05 -2.99653982e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.13962165 0.79552121 0.45718389 0.61751837 0.10639022 0.22066848\n",
            " 0.06741984 0.22814077 1.03868334 2.45090121] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.12204899] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02280636 0.12994362 0.07467825 0.10086792 0.01737821 0.03604487\n",
            " 0.01101263 0.03726543 0.1696627  0.40034002] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.200154856146902, delta shape : (2000, 10), delta[0] : [ 1.14031798e-05  6.49718101e-05  3.73391238e-05  5.04339620e-05\n",
            "  8.68910264e-06  1.80224370e-05  5.50631357e-06  1.86327136e-05\n",
            "  8.48313479e-05 -2.99829990e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1399644  0.79723109 0.45675185 0.61646633 0.10621927 0.22028492\n",
            " 0.06716477 0.22844308 1.04351125 2.45063117] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.12666813] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02284511 0.13012474 0.07455143 0.10062016 0.0173372  0.03595509\n",
            " 0.01096269 0.03728667 0.1703228  0.39999411] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1989803334182674, delta shape : (2000, 10), delta[0] : [ 1.14225545e-05  6.50623692e-05  3.72757136e-05  5.03100805e-05\n",
            "  8.66859966e-06  1.79775460e-05  5.48134586e-06  1.86433373e-05\n",
            "  8.51613983e-05 -3.00002945e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14031062 0.79894154 0.456318   0.61539536 0.10604321 0.21990604\n",
            " 0.06690646 0.22875451 1.04840872 2.45029371] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.13127815] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0228844  0.13030587 0.07442461 0.10036983 0.01729545 0.03586626\n",
            " 0.01091232 0.03730943 0.1709935  0.39963832] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.197809677638431, delta shape : (2000, 10), delta[0] : [ 1.14421996e-05  6.51529358e-05  3.72123061e-05  5.01849159e-05\n",
            "  8.64772426e-06  1.79331316e-05  5.45615949e-06  1.86547161e-05\n",
            "  8.54967507e-05 -3.00180839e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1406622  0.80059596 0.45590045 0.61430065 0.10585906 0.21953695\n",
            " 0.06664689 0.22904634 1.05331773 2.45000133] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.13586756] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02292458 0.13047804 0.07430089 0.10011635 0.0172525  0.03577929\n",
            " 0.01086185 0.03732909 0.17166566 0.39929176] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.196642571366191, delta shape : (2000, 10), delta[0] : [ 1.14622913e-05  6.52390192e-05  3.71504470e-05  5.00581737e-05\n",
            "  8.62625044e-06  1.78896425e-05  5.43092602e-06  1.86645437e-05\n",
            "  8.58328280e-05 -3.00354122e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14101486 0.80224162 0.45548049 0.61323457 0.10567491 0.21917659\n",
            " 0.06638921 0.22933021 1.05810663 2.44987569] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.14052478] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02296463 0.13064708 0.07417615 0.0998668  0.01720943 0.03569346\n",
            " 0.01081165 0.03734701 0.17231534 0.39896846] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1954824348831643, delta shape : (2000, 10), delta[0] : [ 1.14823130e-05  6.53235390e-05  3.70880755e-05  4.99334007e-05\n",
            "  8.60471351e-06  1.78467314e-05  5.40582529e-06  1.86735028e-05\n",
            "  8.61576708e-05 -3.00515772e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14136711 0.80389707 0.45505559 0.61218699 0.10549326 0.2188193\n",
            " 0.06613557 0.22960053 1.06278644 2.44985451] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.14519638] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02300449 0.13081715 0.07405062 0.09962041 0.01716678 0.03560819\n",
            " 0.01076216 0.0373626  0.17294589 0.39866171] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1943297200033722, delta shape : (2000, 10), delta[0] : [ 1.15022451e-05  6.54085745e-05  3.70253094e-05  4.98102059e-05\n",
            "  8.58339211e-06  1.78040935e-05  5.38107830e-06  1.86813013e-05\n",
            "  8.64729436e-05 -3.00669144e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14172476 0.80555418 0.4546505  0.61116676 0.10530755 0.21847054\n",
            " 0.06588651 0.22985673 1.06740569 2.44978476] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.14980798] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0230454  0.13098851 0.07392922 0.09937981 0.01712371 0.03552477\n",
            " 0.01071359 0.03737625 0.17356732 0.39835142] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1931848049022045, delta shape : (2000, 10), delta[0] : [ 1.15226979e-05  6.54942547e-05  3.69646092e-05  4.96899063e-05\n",
            "  8.56185676e-06  1.77623872e-05  5.35679378e-06  1.86881226e-05\n",
            "  8.67836597e-05 -3.00824288e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14209658 0.80728472 0.45425022 0.6101603  0.10512123 0.21812656\n",
            " 0.06563845 0.2301194  1.07212142 2.44951329] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.15443217] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0230885  0.13117128 0.07380863 0.09914161 0.01708057 0.03544219\n",
            " 0.01066523 0.03739084 0.17420314 0.39800801] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1920419254076506, delta shape : (2000, 10), delta[0] : [ 1.15442477e-05  6.55856377e-05  3.69043163e-05  4.95708042e-05\n",
            "  8.54028685e-06  1.77210951e-05  5.33261608e-06  1.86954206e-05\n",
            "  8.71015712e-05 -3.00995996e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14247737 0.80900315 0.45386294 0.6091475  0.10493734 0.21779671\n",
            " 0.06539329 0.23038247 1.07684473 2.44911332] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.15895882] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02313335 0.13135388 0.0736915  0.0989043  0.01703816 0.03536259\n",
            " 0.01061759 0.03740607 0.17484201 0.39765054] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1909067595914355, delta shape : (2000, 10), delta[0] : [ 1.15666762e-05  6.56769409e-05  3.68457522e-05  4.94521492e-05\n",
            "  8.51908124e-06  1.76812930e-05  5.30879450e-06  1.87030373e-05\n",
            "  8.74210041e-05 -3.01174729e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14285873 0.81072546 0.45347635 0.60812747 0.10475886 0.21747248\n",
            " 0.0651503  0.23064748 1.0815122  2.44874363] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.16347296] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02317828 0.13153712 0.07357481 0.09866636 0.01699673 0.03528408\n",
            " 0.01057039 0.03742167 0.17547123 0.39729932] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1897759024938406, delta shape : (2000, 10), delta[0] : [ 1.15891423e-05  6.57685580e-05  3.67874050e-05  4.93331822e-05\n",
            "  8.49836270e-06  1.76420407e-05  5.28519393e-06  1.87108374e-05\n",
            "  8.77356168e-05 -3.01350339e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14324633 0.8124804  0.4530785  0.60713186 0.10458454 0.2171455\n",
            " 0.06490906 0.23091516 1.08616416 2.44837911] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.1680346] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02322398 0.13172436 0.07345589 0.09843198 0.01695589 0.03520497\n",
            " 0.01052346 0.0374374  0.17609567 0.3969464 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.188648933979115, delta shape : (2000, 10), delta[0] : [ 1.16119913e-05  6.58621793e-05  3.67279470e-05  4.92159898e-05\n",
            "  8.47794712e-06  1.76024871e-05  5.26172937e-06  1.87186981e-05\n",
            "  8.80478329e-05 -3.01526802e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14363529 0.8142338  0.4526414  0.60611674 0.10441358 0.21680785\n",
            " 0.06466518 0.23118038 1.0907382  2.44809386] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.17252628] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0232701  0.13191257 0.07333163 0.09819589 0.01691586 0.03512465\n",
            " 0.01047629 0.03745312 0.17670856 0.39661133] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.187525954700463, delta shape : (2000, 10), delta[0] : [ 1.16350490e-05  6.59562844e-05  3.66658140e-05  4.90979472e-05\n",
            "  8.45792947e-06  1.75623267e-05  5.23814546e-06  1.87265610e-05\n",
            "  8.83542777e-05 -3.01694335e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14402433 0.81594293 0.45222    0.60512644 0.10424348 0.21647864\n",
            " 0.06442605 0.23145152 1.09527333 2.44784867] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.17703539] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02331609 0.13209297 0.07320988 0.09796389 0.01687597 0.03504572\n",
            " 0.01042993 0.03746968 0.17731375 0.39628212] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1864069169615603, delta shape : (2000, 10), delta[0] : [ 1.16580462e-05  6.60464836e-05  3.66049383e-05  4.89819471e-05\n",
            "  8.43798621e-06  1.75228587e-05  5.21496547e-06  1.87348383e-05\n",
            "  8.86568765e-05 -3.01858940e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1444061  0.81774779 0.4517517  0.60421571 0.10407747 0.2161248\n",
            " 0.06419181 0.23170533 1.0998446  2.44791945] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.18198477] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02335918 0.13227917 0.07307551 0.09773814 0.01683561 0.03496042\n",
            " 0.01038369 0.03748073 0.17791124 0.3959763 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1852893973465326, delta shape : (2000, 10), delta[0] : [ 1.16795902e-05  6.61395829e-05  3.65377562e-05  4.88690717e-05\n",
            "  8.41780422e-06  1.74802109e-05  5.19184437e-06  1.87403674e-05\n",
            "  8.89556223e-05 -3.02011850e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14479599 0.81958212 0.45126502 0.60332996 0.10391385 0.21576637\n",
            " 0.06396055 0.23194889 1.10434383 2.44805197] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.18695856] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02340342 0.13246931 0.0729381  0.09751641 0.01679563 0.03487438\n",
            " 0.01033796 0.03748997 0.17849543 0.39567939] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1841752400988446, delta shape : (2000, 10), delta[0] : [ 1.17017101e-05  6.62346541e-05  3.64690513e-05  4.87582029e-05\n",
            "  8.39781331e-06  1.74371924e-05  5.16898159e-06  1.87449853e-05\n",
            "  8.92477153e-05 -3.02160306e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14518881 0.82141543 0.45077136 0.602467   0.1037513  0.2154073\n",
            " 0.06373133 0.23218022 1.10882952 2.44828372] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.19202598] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02344771 0.13265697 0.07279869 0.09729723 0.01675563 0.03478785\n",
            " 0.01029248 0.03749665 0.17907378 0.395393  ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1830652151478422, delta shape : (2000, 10), delta[0] : [ 1.17238537e-05  6.63284866e-05  3.63993430e-05  4.86486168e-05\n",
            "  8.37781527e-06  1.73939271e-05  5.14624220e-06  1.87483242e-05\n",
            "  8.95368915e-05 -3.02303500e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14558084 0.82327776 0.45026114 0.60159859 0.10358976 0.2150415\n",
            " 0.06350328 0.23242521 1.11338845 2.44847813] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.19714466] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0234916  0.13284792 0.07265623 0.09707674 0.01671572 0.03470009\n",
            " 0.01024718 0.03750521 0.17966152 0.39509778] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1819615089363156, delta shape : (2000, 10), delta[0] : [ 1.17457999e-05  6.64239582e-05  3.63281131e-05  4.85383694e-05\n",
            "  8.35786201e-06  1.73500471e-05  5.12359155e-06  1.87526050e-05\n",
            "  8.98307616e-05 -3.02451108e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14597467 0.8251299  0.44975796 0.60071676 0.10342443 0.21468414\n",
            " 0.06327287 0.23266872 1.11799282 2.44872838] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.20235064] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02353538 0.13303503 0.07251411 0.09685308 0.01667504 0.03461335\n",
            " 0.01020143 0.03751299 0.18025308 0.3948065 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.180862459600038, delta shape : (2000, 10), delta[0] : [ 1.17676896e-05  6.65175144e-05  3.62570567e-05  4.84265398e-05\n",
            "  8.33751916e-06  1.73066756e-05  5.10071668e-06  1.87564949e-05\n",
            "  9.01265409e-05 -3.02596748e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14636754 0.82695116 0.44925267 0.59983264 0.10325743 0.21432602\n",
            " 0.06304089 0.23290729 1.12256723 2.44905491] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.20755778] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02357892 0.13321683 0.07237189 0.09662941 0.01663415 0.03452662\n",
            " 0.01015551 0.03751996 0.18083879 0.39452793] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1797680818244674, delta shape : (2000, 10), delta[0] : [ 1.17894623e-05  6.66084145e-05  3.61859432e-05  4.83147049e-05\n",
            "  8.31707364e-06  1.72633123e-05  5.07775261e-06  1.87599777e-05\n",
            "  9.04193947e-05 -3.02736036e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14675982 0.82876198 0.44873982 0.59894841 0.10309119 0.21396729\n",
            " 0.06281211 0.23313876 1.12711118 2.44942376] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.21275431] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02362234 0.13339687 0.07222881 0.09640626 0.01659348 0.03444\n",
            " 0.01011019 0.03752583 0.18141892 0.3942573 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1786782306765877, delta shape : (2000, 10), delta[0] : [ 1.18111719e-05  6.66984348e-05  3.61144027e-05  4.82031303e-05\n",
            "  8.29673805e-06  1.72200025e-05  5.05509359e-06  1.87629147e-05\n",
            "  9.07094598e-05 -3.02871348e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1471555  0.83051922 0.44824226 0.59803722 0.10292843 0.21361424\n",
            " 0.06258175 0.23335466 1.13162959 2.44986087] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.21792373] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02366634 0.13356858 0.07208874 0.09617957 0.0165535  0.03435459\n",
            " 0.01006473 0.03752935 0.18199477 0.39399983] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.177594061028718, delta shape : (2000, 10), delta[0] : [ 1.18331701e-05  6.67842878e-05  3.60443682e-05  4.80897842e-05\n",
            "  8.27675216e-06  1.71772968e-05  5.03236675e-06  1.87646768e-05\n",
            "  9.09973842e-05 -3.03000087e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14755366 0.83222498 0.44774941 0.59711075 0.10276532 0.213264\n",
            " 0.062349   0.23356468 1.1361371  2.45032595] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.22304484] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02371085 0.13373276 0.07195021 0.09595154 0.01651367 0.03427004\n",
            " 0.01001905 0.03753222 0.18256933 0.39375033] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1765132799289857, delta shape : (2000, 10), delta[0] : [ 1.18554233e-05  6.68663816e-05  3.59751071e-05  4.79757711e-05\n",
            "  8.25683563e-06  1.71350200e-05  5.00952497e-06  1.87661093e-05\n",
            "  9.12846626e-05 -3.03124836e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1479491  0.8339363  0.44724526 0.59618399 0.10260151 0.21291252\n",
            " 0.06211681 0.23377235 1.1406601  2.45080526] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.22818321] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02375478 0.1338972  0.07180991 0.09572358 0.01647375 0.03418533\n",
            " 0.0099735  0.0375346  0.18314492 0.39350244] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.175438504727463, delta shape : (2000, 10), delta[0] : [ 1.18773886e-05  6.69486003e-05  3.59049538e-05  4.78617900e-05\n",
            "  8.23687290e-06  1.70926671e-05  4.98675200e-06  1.87672987e-05\n",
            "  9.15724586e-05 -3.03248782e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14835886 0.83570389 0.44674466 0.5952717  0.10244339 0.21256541\n",
            " 0.06188918 0.23397623 1.14517684 2.45115824] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.2332884] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02380106 0.13407111 0.07167078 0.09549882 0.01643489 0.03410165\n",
            " 0.00992882 0.03753656 0.18371953 0.39323678] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1743686081113336, delta shape : (2000, 10), delta[0] : [ 1.19005293e-05  6.70355544e-05  3.58353915e-05  4.77494108e-05\n",
            "  8.21744342e-06  1.70508244e-05  4.96440831e-06  1.87682823e-05\n",
            "  9.18597673e-05 -3.03381612e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14877327 0.83745569 0.44624463 0.59437424 0.10228975 0.21222522\n",
            " 0.0616651  0.23417338 1.14964776 2.451526  ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.23837503] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02384808 0.1342426  0.07153219 0.09527709 0.01639686 0.03401931\n",
            " 0.0098848  0.03753756 0.18428641 0.39297509] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1733002129739534, delta shape : (2000, 10), delta[0] : [ 1.19240401e-05  6.71213002e-05  3.57660949e-05  4.76385466e-05\n",
            "  8.19842875e-06  1.70096554e-05  4.94240102e-06  1.87687805e-05\n",
            "  9.21432066e-05 -3.03512454e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1491985  0.8392238  0.44575264 0.59347383 0.1021386  0.21188217\n",
            " 0.06144494 0.23436006 1.15412697 2.45191959] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.2435211] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02389653 0.13441515 0.07139443 0.09505435 0.01635913 0.03393633\n",
            " 0.00984139 0.03753652 0.18485194 0.39271423] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1722319234298832, delta shape : (2000, 10), delta[0] : [ 1.19482657e-05  6.72075729e-05  3.56972159e-05  4.75271745e-05\n",
            "  8.17956701e-06  1.69681632e-05  4.92069599e-06  1.87682603e-05\n",
            "  9.24259689e-05 -3.03642884e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.14962663 0.84102626 0.44524208 0.59259597 0.10198378 0.21153742\n",
            " 0.06122671 0.2345427  1.15853755 2.45221626] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.24853536] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02394587 0.13459574 0.07125543 0.09483758 0.01632123 0.03385392\n",
            " 0.00979857 0.03753563 0.18540946 0.39244657] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1711698468242284, delta shape : (2000, 10), delta[0] : [ 1.19729361e-05  6.72978718e-05  3.56277153e-05  4.74187900e-05\n",
            "  8.16061487e-06  1.69269602e-05  4.89928467e-06  1.87678138e-05\n",
            "  9.27047286e-05 -3.03776715e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15005817 0.84286452 0.44473523 0.59174247 0.10182822 0.21119675\n",
            " 0.0610077  0.23471475 1.16287742 2.45247157] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.25349679] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02399588 0.13478291 0.07111785 0.09462585 0.0162834  0.03377258\n",
            " 0.00975577 0.03753336 0.18595635 0.39217603] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1701146810904812, delta shape : (2000, 10), delta[0] : [ 1.19979407e-05  6.73914573e-05  3.55589239e-05  4.73129263e-05\n",
            "  8.14170217e-06  1.68862923e-05  4.87788689e-06  1.87666800e-05\n",
            "  9.29781736e-05 -3.03911983e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15048684 0.8446722  0.44422837 0.59091147 0.10167014 0.21086118\n",
            " 0.06079089 0.23489015 1.16716363 2.45287095] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.25854581] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02404502 0.13496301 0.07097949 0.09441674 0.01624501 0.03369172\n",
            " 0.00971326 0.03753111 0.18649119 0.39192346] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1690626705180938, delta shape : (2000, 10), delta[0] : [ 1.20225086e-05  6.74815067e-05  3.54897432e-05  4.72083678e-05\n",
            "  8.12250488e-06  1.68458606e-05  4.85663067e-06  1.87655534e-05\n",
            "  9.32455928e-05 -3.04038269e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15090069 0.84639048 0.44372077 0.59005467 0.10150302 0.21052155\n",
            " 0.06056952 0.23506781 1.17149787 2.4533498 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.26357618] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02409178 0.13512895 0.07084144 0.09420412 0.01620528 0.03361044\n",
            " 0.00967012 0.03752933 0.18703339 0.39168515] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.168017474873869, delta shape : (2000, 10), delta[0] : [ 1.20458891e-05  6.75644759e-05  3.54207209e-05  4.71020592e-05\n",
            "  8.10264099e-06  1.68052200e-05  4.83505921e-06  1.87646645e-05\n",
            "  9.35166936e-05 -3.04157423e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15131665 0.84813169 0.44320513 0.58922854 0.10133809 0.21018005\n",
            " 0.06035241 0.23524264 1.17579598 2.45389865] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.26868985] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02413848 0.13529648 0.0707014  0.09399548 0.01616575 0.03352855\n",
            " 0.0096276  0.0375266  0.18756646 0.39145319] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.166974616281498, delta shape : (2000, 10), delta[0] : [ 1.20692408e-05  6.76482418e-05  3.53506987e-05  4.69977425e-05\n",
            "  8.08287673e-06  1.67642726e-05  4.81379757e-06  1.87633019e-05\n",
            "  9.37832312e-05 -3.04273404e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15173375 0.84983826 0.44271074 0.58837659 0.10117247 0.20984434\n",
            " 0.06013727 0.23541431 1.1801614  2.45456399] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.27395312] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02418471 0.13545499 0.07056328 0.09378084 0.01612579 0.03344691\n",
            " 0.00958523 0.03752248 0.18810491 0.39123085] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.165934091908376, delta shape : (2000, 10), delta[0] : [ 1.20923559e-05  6.77274955e-05  3.52816424e-05  4.68904199e-05\n",
            "  8.06289686e-06  1.67234543e-05  4.79261388e-06  1.87612422e-05\n",
            "  9.40524561e-05 -3.04384577e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15215432 0.85157258 0.44221481 0.58754688 0.10100593 0.20951098\n",
            " 0.05992503 0.23558105 1.18452343 2.45517964] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.27921465] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02423143 0.13561769 0.07042518 0.09357012 0.01608576 0.03336579\n",
            " 0.00954339 0.0375176  0.18864197 0.39100107] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1648981929138826, delta shape : (2000, 10), delta[0] : [ 1.21157128e-05  6.78088446e-05  3.52125894e-05  4.67850613e-05\n",
            "  8.04287907e-06  1.66828965e-05  4.77169749e-06  1.87587986e-05\n",
            "  9.43209857e-05 -3.04499466e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1525763  0.85331336 0.44174301 0.58670329 0.1008427  0.20918329\n",
            " 0.05971548 0.23575175 1.18896502 2.45576017] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.28455437] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02427798 0.13577945 0.07029027 0.09335639 0.01604612 0.0332853\n",
            " 0.00950194 0.03751288 0.18918844 0.39076123] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1638673935349324, delta shape : (2000, 10), delta[0] : [ 1.21389909e-05  6.78897270e-05  3.51451339e-05  4.66781934e-05\n",
            "  8.02305926e-06  1.66426511e-05  4.75097175e-06  1.87564415e-05\n",
            "  9.45942184e-05 -3.04619387e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15300274 0.85510113 0.44126066 0.5858531  0.1006789  0.2088535\n",
            " 0.05950687 0.23592565 1.19345425 2.4561583 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.2897951] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02432555 0.13595055 0.07015501 0.09314343 0.01600671 0.03320514\n",
            " 0.00946086 0.03750928 0.18974454 0.39049894] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.162840064767587, delta shape : (2000, 10), delta[0] : [ 1.21627761e-05  6.79752773e-05  3.50775070e-05  4.65717156e-05\n",
            "  8.00335259e-06  1.66025677e-05  4.73042997e-06  1.87546376e-05\n",
            "  9.48722676e-05 -3.04750531e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15342399 0.85688042 0.44078313 0.58501191 0.1005129  0.20852602\n",
            " 0.0592999  0.23610262 1.19793435 2.45655784] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.29503309] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02437223 0.13612008 0.07002078 0.0929323  0.01596702 0.03312548\n",
            " 0.00942011 0.03750618 0.19029834 0.39023748] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1618173220800405, delta shape : (2000, 10), delta[0] : [ 1.21861149e-05  6.80600412e-05  3.50103901e-05  4.64661508e-05\n",
            "  7.98350827e-06  1.65627424e-05  4.71005493e-06  1.87530879e-05\n",
            "  9.51491700e-05 -3.04881260e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15384724 0.85866286 0.44030363 0.58415569 0.10034656 0.20819891\n",
            " 0.05909122 0.23627464 1.20246277 2.45694375] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.30028727] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02441908 0.13628948 0.06988628 0.0927189  0.0159273  0.03304594\n",
            " 0.00937913 0.0375022  0.1908584  0.38997329] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1607996505313305, delta shape : (2000, 10), delta[0] : [ 1.22095417e-05  6.81447386e-05  3.49431392e-05  4.63594489e-05\n",
            "  7.96364917e-06  1.65229698e-05  4.68956581e-06  1.87511008e-05\n",
            "  9.54292016e-05 -3.05013356e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15427317 0.86042769 0.43985941 0.58330359 0.10018928 0.20787531\n",
            " 0.05888617 0.2364305  1.20702221 2.45741729] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.30568462] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02446573 0.1364527  0.06975601 0.0925044  0.01588872 0.03296633\n",
            " 0.00933858 0.03749482 0.19141811 0.38971459] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1597860305132053, delta shape : (2000, 10), delta[0] : [ 1.22328644e-05  6.82263502e-05  3.48780058e-05  4.62522017e-05\n",
            "  7.94436174e-06  1.64831673e-05  4.66929200e-06  1.87474089e-05\n",
            "  9.57090535e-05 -3.05142706e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15470405 0.86217023 0.4394075  0.58242143 0.10003214 0.20755406\n",
            " 0.05868369 0.23658387 1.2115974  2.4577963 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.31095066] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02451359 0.13661495 0.0696262  0.09228743 0.01585057 0.03288792\n",
            " 0.00929871 0.03748783 0.19198334 0.38944946] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.158774435003993, delta shape : (2000, 10), delta[0] : [ 1.22567947e-05  6.83074765e-05  3.48130993e-05  4.61437156e-05\n",
            "  7.92528263e-06  1.64439615e-05  4.64935410e-06  1.87439166e-05\n",
            "  9.59916712e-05 -3.05275272e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15514039 0.8639455  0.43894429 0.58151497 0.09987481 0.20723178\n",
            " 0.05847817 0.23672198 1.21622011 2.4581125 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.31618449] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02456236 0.13678282 0.06949517 0.09206745 0.01581252 0.03280965\n",
            " 0.00925846 0.03747864 0.19255614 0.38917681] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1577625201408566, delta shape : (2000, 10), delta[0] : [ 1.22811793e-05  6.83914079e-05  3.47475830e-05  4.60337226e-05\n",
            "  7.90626138e-06  1.64048232e-05  4.62923203e-06  1.87393177e-05\n",
            "  9.62780700e-05 -3.05411597e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15557981 0.86566887 0.43847379 0.58059377 0.09971833 0.20690676\n",
            " 0.05827494 0.23686362 1.22082204 2.45844778] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.32134971] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0246118  0.13694368 0.06936395 0.09184649 0.01577485 0.03273142\n",
            " 0.00921875 0.03747042 0.1931268  0.38891185] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.156754797706148, delta shape : (2000, 10), delta[0] : [ 1.23059014e-05  6.84718387e-05  3.46819751e-05  4.59232443e-05\n",
            "  7.88742386e-06  1.63657104e-05  4.60937472e-06  1.87352092e-05\n",
            "  9.65633997e-05 -3.05544077e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1560207  0.86733607 0.43800447 0.57964013 0.09955972 0.20658249\n",
            " 0.05807198 0.23702    1.22540709 2.45866619] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.32630884] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0246622  0.13709986 0.06923539 0.09162375 0.01573741 0.03265451\n",
            " 0.00917944 0.03746577 0.19370017 0.38864151] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1557498798524217, delta shape : (2000, 10), delta[0] : [ 1.23311003e-05  6.85499314e-05  3.46176956e-05  4.58118742e-05\n",
            "  7.86870532e-06  1.63272526e-05  4.58972058e-06  1.87328825e-05\n",
            "  9.68500846e-05 -3.05679247e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15646106 0.86895534 0.43752838 0.57865686 0.09940844 0.2062509\n",
            " 0.05787324 0.23718617 1.2300836  2.45902682] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.33143081] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0247118  0.1372447  0.06910419 0.09139433 0.01570079 0.03257572\n",
            " 0.00914063 0.0374617  0.19428209 0.38838406] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1547475585471174, delta shape : (2000, 10), delta[0] : [ 1.23559007e-05  6.86223514e-05  3.45520933e-05  4.56971639e-05\n",
            "  7.85039282e-06  1.62878588e-05  4.57031315e-06  1.87308505e-05\n",
            "  9.71410441e-05 -3.05807969e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15690323 0.87062345 0.43703763 0.57769183 0.09926002 0.20591942\n",
            " 0.05767875 0.23735086 1.23472548 2.4593294 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.33652006] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02476173 0.13739773 0.06897124 0.09116863 0.01566475 0.03249724\n",
            " 0.00910259 0.0374576  0.19485861 0.38811988] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1537483601556766, delta shape : (2000, 10), delta[0] : [ 1.23808674e-05  6.86988632e-05  3.44856186e-05  4.55843130e-05\n",
            "  7.83237674e-06  1.62486204e-05  4.55129531e-06  1.87288020e-05\n",
            "  9.74293039e-05 -3.05940061e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15734768 0.87230197 0.43653678 0.57676268 0.09911338 0.20558183\n",
            " 0.0574866  0.23751415 1.23925325 2.45972321] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.34162153] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0248119  0.13755188 0.06883678 0.09094877 0.01562903 0.03241787\n",
            " 0.00906497 0.03745322 0.19541583 0.38786976] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1527556588628722, delta shape : (2000, 10), delta[0] : [ 1.24059499e-05  6.87759404e-05  3.44183878e-05  4.54743853e-05\n",
            "  7.81451423e-06  1.62089327e-05  4.53248438e-06  1.87266100e-05\n",
            "  9.77079160e-05 -3.06065121e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15779033 0.87396195 0.436037   0.57583874 0.09896823 0.20524606\n",
            " 0.05729488 0.23767105 1.24368826 2.46020574] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.34670223] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02486178 0.13770332 0.06870292 0.09073039 0.01559365 0.03233901\n",
            " 0.0090275  0.03744796 0.19595819 0.38763529] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1517669494538714, delta shape : (2000, 10), delta[0] : [ 1.24308912e-05  6.88516583e-05  3.43514618e-05  4.53651926e-05\n",
            "  7.79682305e-06  1.61695045e-05  4.51375218e-06  1.87239802e-05\n",
            "  9.79790929e-05 -3.06182357e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15823645 0.87564436 0.43554774 0.57494331 0.09881927 0.20491565\n",
            " 0.05710615 0.23782385 1.24808882 2.46066539] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.351791] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0249121  0.13785787 0.06857086 0.09051672 0.0155577  0.03226108\n",
            " 0.00899056 0.03744202 0.196494   0.3873971 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.150780320443808, delta shape : (2000, 10), delta[0] : [ 1.24560501e-05  6.89289339e-05  3.42854277e-05  4.52583617e-05\n",
            "  7.77885075e-06  1.61305413e-05  4.49527940e-06  1.87210076e-05\n",
            "  9.82469999e-05 -3.06301452e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15869326 0.87720617 0.43508416 0.57398454 0.09866999 0.20459656\n",
            " 0.05691538 0.23797742 1.25253066 2.46099314] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.35665127] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02496492 0.13799816 0.0684455  0.09029669 0.01552232 0.03218622\n",
            " 0.00895367 0.03743754 0.19704253 0.38715245] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.149794099497519, delta shape : (2000, 10), delta[0] : [ 1.24824579e-05  6.89990792e-05  3.42227488e-05  4.51483426e-05\n",
            "  7.76116082e-06  1.60931085e-05  4.47683645e-06  1.87187725e-05\n",
            "  9.85212660e-05 -3.06423773e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15915168 0.87882358 0.43461645 0.57306179 0.09852459 0.20427733\n",
            " 0.05672713 0.23812476 1.25691725 2.46135358] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.36157814] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02501764 0.13814553 0.06831897 0.0900817  0.01548744 0.03211111\n",
            " 0.00891715 0.03743171 0.19757947 0.38690927] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1488101437518115, delta shape : (2000, 10), delta[0] : [ 1.25088205e-05  6.90727645e-05  3.41594837e-05  4.50408516e-05\n",
            "  7.74372217e-06  1.60555543e-05  4.45857396e-06  1.87158561e-05\n",
            "  9.87897359e-05 -3.06545363e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.15960659 0.88041901 0.43415874 0.5721463  0.09837584 0.20396152\n",
            " 0.05653684 0.23826174 1.26128246 2.4618853 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.36663433] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02506923 0.13828641 0.06819282 0.08986637 0.01545178 0.032036\n",
            " 0.00888018 0.0374235  0.1981082  0.38668552] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.147831262627299, delta shape : (2000, 10), delta[0] : [ 1.25346128e-05  6.91432055e-05  3.40964092e-05  4.49331839e-05\n",
            "  7.72589025e-06  1.60180014e-05  4.44008830e-06  1.87117498e-05\n",
            "  9.90540996e-05 -3.06657241e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16005824 0.88204981 0.43371299 0.57125519 0.09822979 0.20364699\n",
            " 0.05634867 0.23839685 1.26564481 2.46249811] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.37184146] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02511962 0.13842934 0.06806714 0.08965308 0.01541623 0.03196046\n",
            " 0.00884339 0.03741412 0.19863093 0.38646569] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1468531362787746, delta shape : (2000, 10), delta[0] : [ 1.25598105e-05  6.92146698e-05  3.40335675e-05  4.48265385e-05\n",
            "  7.70811622e-06  1.59802305e-05  4.42169459e-06  1.87070609e-05\n",
            "  9.93154660e-05 -3.06767155e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16051694 0.88364705 0.43327275 0.57033632 0.09808317 0.20333331\n",
            " 0.05615775 0.23851278 1.27006047 2.46307515] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.3769957] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02517125 0.13856792 0.06794308 0.08943652 0.01538078 0.03188544\n",
            " 0.0088063  0.03740206 0.19916282 0.38624382] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1458768095836773, delta shape : (2000, 10), delta[0] : [ 1.25856237e-05  6.92839616e-05  3.39715415e-05  4.47182616e-05\n",
            "  7.69039039e-06  1.59427199e-05  4.40315088e-06  1.87010304e-05\n",
            "  9.95814119e-05 -3.06878092e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16097899 0.88518551 0.43284311 0.56940599 0.0979353  0.20302191\n",
            " 0.05596677 0.23862189 1.27443649 2.4637936 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.38218955] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02522316 0.13869621 0.06782047 0.08921797 0.01534509 0.0318107\n",
            " 0.00876921 0.03738872 0.19968641 0.38604206] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1449038240684923, delta shape : (2000, 10), delta[0] : [ 1.26115803e-05  6.93481056e-05  3.39102359e-05  4.46089845e-05\n",
            "  7.67254683e-06  1.59053497e-05  4.38460587e-06  1.86943590e-05\n",
            "  9.98432027e-05 -3.06978970e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16145036 0.88672763 0.43241691 0.56848506 0.0977831  0.20272172\n",
            " 0.05577674 0.23872413 1.2787057  2.46432242] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.38711375] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02527751 0.13883072 0.06770146 0.089005   0.01530943 0.03173917\n",
            " 0.0087327  0.0373759  0.20020086 0.38582723] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1439328758575553, delta shape : (2000, 10), delta[0] : [ 1.26387571e-05  6.94153621e-05  3.38507290e-05  4.45025002e-05\n",
            "  7.65471694e-06  1.58695870e-05  4.36634908e-06  1.86879507e-05\n",
            "  1.00100432e-04 -3.07086384e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16191717 0.88821526 0.43201119 0.56756688 0.0976296  0.20242863\n",
            " 0.05558768 0.23882118 1.28298724 2.46492714] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.39209197] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02533086 0.13895533 0.06758526 0.08879204 0.0152735  0.0316686\n",
            " 0.00869632 0.03736198 0.20071477 0.38562135] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1429649937236808, delta shape : (2000, 10), delta[0] : [ 1.26654289e-05  6.94776661e-05  3.37926290e-05  4.43960192e-05\n",
            "  7.63674838e-06  1.58343021e-05  4.34816023e-06  1.86809878e-05\n",
            "  1.00357383e-04 -3.07189325e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16239268 0.889753   0.43157961 0.56668098 0.09748099 0.20213318\n",
            " 0.05539942 0.23892396 1.28721363 2.46542075] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.3969782] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02538584 0.13908958 0.06746617 0.08858573 0.0152386  0.03159823\n",
            " 0.00866025 0.0373495  0.20122214 0.38540396] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.141997636988622, delta shape : (2000, 10), delta[0] : [ 1.26929210e-05  6.95447891e-05  3.37330841e-05  4.42928649e-05\n",
            "  7.61929955e-06  1.57991145e-05  4.33012440e-06  1.86747517e-05\n",
            "  1.00611069e-04 -3.07298019e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16286494 0.89130825 0.43114416 0.56582252 0.09732351 0.20184469\n",
            " 0.05521002 0.23901995 1.29140296 2.46586929] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.40181031] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02544045 0.13922753 0.06734723 0.08838477 0.0152025  0.03152931\n",
            " 0.00862413 0.03733631 0.20172465 0.38518312] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.141030646923606, delta shape : (2000, 10), delta[0] : [ 1.27202254e-05  6.96137662e-05  3.36736128e-05  4.41923842e-05\n",
            "  7.60124883e-06  1.57646574e-05  4.31206348e-06  1.86681534e-05\n",
            "  1.00862327e-04 -3.07408438e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1633356  0.89279789 0.43071897 0.56494765 0.09716325 0.2015601\n",
            " 0.05502019 0.23910981 1.29555958 2.46642038] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.40663342] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02549476 0.13935523 0.06723016 0.08818167 0.01516604 0.03146116\n",
            " 0.008588   0.03732222 0.20222159 0.38497916] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1400681020071417, delta shape : (2000, 10), delta[0] : [ 1.27473818e-05  6.96776164e-05  3.36150785e-05  4.40908363e-05\n",
            "  7.58301945e-06  1.57305784e-05  4.29400149e-06  1.86611119e-05\n",
            "  1.01110794e-04 -3.07510418e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16380394 0.89426714 0.43029446 0.56407276 0.09700673 0.20127153\n",
            " 0.0548316  0.23919347 1.29968844 2.46714926] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.41157933] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02554814 0.13947689 0.06711209 0.08797719 0.01512993 0.03139188\n",
            " 0.00855196 0.03730648 0.20270956 0.38479587] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.139106259225828, delta shape : (2000, 10), delta[0] : [ 1.27740710e-05  6.97384449e-05  3.35560430e-05  4.39885971e-05\n",
            "  7.56496358e-06  1.56959398e-05  4.27598221e-06  1.86532413e-05\n",
            "  1.01354781e-04 -3.07602064e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16427121 0.89566144 0.42988805 0.5631674  0.09684925 0.20098585\n",
            " 0.054643   0.23927505 1.30375546 2.46782344] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.41632014] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02560209 0.13959114 0.06699916 0.08777109 0.0150942  0.03132416\n",
            " 0.00851625 0.03729163 0.20319364 0.38461663] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1381463821896967, delta shape : (2000, 10), delta[0] : [ 1.28010457e-05  6.97955695e-05  3.34995796e-05  4.38855439e-05\n",
            "  7.54710240e-06  1.56620806e-05  4.25812601e-06  1.86458160e-05\n",
            "  1.01596821e-04 -3.07691685e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16473933 0.89707966 0.42950191 0.56227899 0.09669916 0.20070764\n",
            " 0.0544529  0.23935198 1.30779438 2.46850938] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.42111534] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02565588 0.13970776 0.06688899 0.08756718 0.01505956 0.03125744\n",
            " 0.00848029 0.03727576 0.20367091 0.38443623] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.137187612700175, delta shape : (2000, 10), delta[0] : [ 1.28279376e-05  6.98538813e-05  3.34444946e-05  4.37835920e-05\n",
            "  7.52977947e-06  1.56287211e-05  4.24014322e-06  1.86378820e-05\n",
            "  1.01835453e-04 -3.07781884e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16521495 0.89852235 0.42910862 0.56141521 0.09655033 0.20042534\n",
            " 0.05426714 0.23943127 1.31188696 2.46920185] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.42602402] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02571029 0.13982555 0.06677669 0.08736587 0.01502489 0.03118963\n",
            " 0.0084449  0.03725963 0.2041522  0.38425033] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1362293987248533, delta shape : (2000, 10), delta[0] : [ 1.28551459e-05  6.99127756e-05  3.33883456e-05  4.36829373e-05\n",
            "  7.51244703e-06  1.55948170e-05  4.22245063e-06  1.86298141e-05\n",
            "  1.02076102e-04 -3.07874835e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16569919 0.89995438 0.42873038 0.56054074 0.0963986  0.20015398\n",
            " 0.05408101 0.23950459 1.31591995 2.46963193] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.43061475] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02576724 0.13994842 0.0666702  0.08716752 0.01499057 0.03112517\n",
            " 0.00840993 0.03724443 0.20463362 0.3840429 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1352718019384778, delta shape : (2000, 10), delta[0] : [ 1.28836197e-05  6.99742103e-05  3.33351006e-05  4.35837599e-05\n",
            "  7.49528652e-06  1.55625855e-05  4.20496443e-06  1.86222158e-05\n",
            "  1.02316808e-04 -3.07978551e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16618759 0.90139296 0.42832567 0.559686   0.09625466 0.19987267\n",
            " 0.05389834 0.2395767  1.31986533 2.47013094] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.43519086] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02582481 0.14007245 0.0665599  0.08697271 0.01495755 0.03105932\n",
            " 0.00837556 0.03722915 0.20510119 0.38384735] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.134316266239318, delta shape : (2000, 10), delta[0] : [ 1.29124059e-05  7.00362256e-05  3.32799507e-05  4.34863557e-05\n",
            "  7.47877309e-06  1.55296615e-05  4.18778072e-06  1.86145764e-05\n",
            "  1.02550597e-04 -3.08076326e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1666643  0.90280391 0.42791617 0.55883103 0.09611175 0.19958634\n",
            " 0.0537143  0.23964361 1.32380053 2.47083609] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.43990801] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02587992 0.14018894 0.06644756 0.08677624 0.0149244  0.03099211\n",
            " 0.00834085 0.03721227 0.20556202 0.38367568] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1333644852874944, delta shape : (2000, 10), delta[0] : [ 1.29399594e-05  7.00944722e-05  3.32237797e-05  4.33881218e-05\n",
            "  7.46219904e-06  1.54960549e-05  4.17042424e-06  1.86061363e-05\n",
            "  1.02781012e-04 -3.08162160e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1671463  0.90426406 0.42753856 0.55800718 0.0959802  0.19931471\n",
            " 0.05353058 0.23972218 1.32782049 2.47141068] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.44473494] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02593533 0.14031051 0.0663392  0.08658342 0.01489281 0.03092675\n",
            " 0.00830609 0.03719659 0.20603182 0.38347747] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.132418556588712, delta shape : (2000, 10), delta[0] : [ 1.29676626e-05  7.01552562e-05  3.31696003e-05  4.32917091e-05\n",
            "  7.44640378e-06  1.54633753e-05  4.15304733e-06  1.85982965e-05\n",
            "  1.03015912e-04 -3.08261263e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16763187 0.90571843 0.42716607 0.55719751 0.09585034 0.19904621\n",
            " 0.05334778 0.23979853 1.33183382 2.47203679] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.44962734] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02599094 0.14042958 0.06623112 0.0863922  0.01486138 0.03086166\n",
            " 0.00827145 0.03718022 0.20649779 0.38328366] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.131473580142202, delta shape : (2000, 10), delta[0] : [ 1.29954697e-05  7.02147880e-05  3.31155621e-05  4.31961012e-05\n",
            "  7.43068786e-06  1.54308300e-05  4.13572584e-06  1.85901076e-05\n",
            "  1.03248897e-04 -3.08358169e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16810919 0.90709587 0.42683238 0.55636093 0.09571273 0.1987831\n",
            " 0.0531611  0.23985903 1.3359649  2.47269128] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.45457052] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02604498 0.14053543 0.0661287  0.08619643 0.01482867 0.03079726\n",
            " 0.0082362  0.03716111 0.20697967 0.38309153] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.130529724362017, delta shape : (2000, 10), delta[0] : [ 1.30224921e-05  7.02677170e-05  3.30643518e-05  4.30982147e-05\n",
            "  7.41433743e-06  1.53986314e-05  4.11809777e-06  1.85805571e-05\n",
            "  1.03489837e-04 -3.08454236e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16859383 0.90849011 0.42651428 0.55551949 0.09557744 0.19852267\n",
            " 0.0529745  0.23989858 1.3401112  2.47326005] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.45946217] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02610029 0.14064485 0.06602938 0.08600089 0.0147965  0.03073362\n",
            " 0.00820107 0.0371391  0.20746483 0.38288947] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1295868478015145, delta shape : (2000, 10), delta[0] : [ 1.30501448e-05  7.03224270e-05  3.30146895e-05  4.30004443e-05\n",
            "  7.39825096e-06  1.53668110e-05  4.10053528e-06  1.85695479e-05\n",
            "  1.03732414e-04 -3.08555265e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16908393 0.90988038 0.42619693 0.5546846  0.09544243 0.19826545\n",
            " 0.05278854 0.23993157 1.34419863 2.47382501] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.46429747] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02615658 0.14075472 0.0659309  0.08580741 0.01476455 0.03067084\n",
            " 0.00816617 0.03711642 0.20794195 0.38269047] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1286470204850225, delta shape : (2000, 10), delta[0] : [ 1.30782914e-05  7.03773597e-05  3.29654488e-05  4.29037031e-05\n",
            "  7.38227390e-06  1.53354215e-05  4.08308407e-06  1.85582091e-05\n",
            "  1.03970976e-04 -3.08654767e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.16957687 0.91126352 0.42587771 0.55385417 0.09531022 0.19800922\n",
            " 0.05260486 0.23996601 1.34829042 2.47443073] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.46918373] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02621302 0.14086221 0.06583175 0.08561423 0.01473296 0.03060807\n",
            " 0.00813161 0.03709371 0.20841739 0.38249505] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1277103244664533, delta shape : (2000, 10), delta[0] : [ 1.31065123e-05  7.04311048e-05  3.29158765e-05  4.28071141e-05\n",
            "  7.36647942e-06  1.53040345e-05  4.06580389e-06  1.85468538e-05\n",
            "  1.04208697e-04 -3.08752477e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17007394 0.91263951 0.42556766 0.55306786 0.09517951 0.19775735\n",
            " 0.05242658 0.23999022 1.35228193 2.47511123] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.47409578] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02626991 0.14096787 0.06573391 0.08542782 0.01470159 0.03054594\n",
            " 0.0080979  0.0370693  0.2088758  0.38230995] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1267766773958545, delta shape : (2000, 10), delta[0] : [ 1.31349570e-05  7.04839361e-05  3.28669570e-05  4.27139078e-05\n",
            "  7.35079531e-06  1.52729708e-05  4.04895032e-06  1.85346516e-05\n",
            "  1.04437900e-04 -3.08845026e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17057141 0.9140233  0.42526584 0.55226976 0.0950486  0.19751083\n",
            " 0.05225021 0.24001532 1.35634516 2.47573103] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.47903147] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02632668 0.14107406 0.06563725 0.08523956 0.01467019 0.03048462\n",
            " 0.00806451 0.03704494 0.20934381 0.38211437] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.125846817169726, delta shape : (2000, 10), delta[0] : [ 1.31633420e-05  7.05370323e-05  3.28186271e-05  4.26197777e-05\n",
            "  7.33509313e-06  1.52423115e-05  4.03225494e-06  1.85224690e-05\n",
            "  1.04671907e-04 -3.08942815e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17107011 0.91542189 0.42494191 0.55151359 0.09491332 0.19725937\n",
            " 0.05207513 0.24002875 1.3601715  2.47625529] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.48365086] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02638484 0.14118926 0.06554053 0.0850622  0.01463887 0.03042412\n",
            " 0.00803176 0.03702062 0.20978482 0.38192299] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1249217896163275, delta shape : (2000, 10), delta[0] : [ 1.31924215e-05  7.05946320e-05  3.27702646e-05  4.25310985e-05\n",
            "  7.31943465e-06  1.52120598e-05  4.01588036e-06  1.85103080e-05\n",
            "  1.04892408e-04 -3.09038507e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17156079 0.91684182 0.42463096 0.55078236 0.09478476 0.19701348\n",
            " 0.05190038 0.24004919 1.36411233 2.47684123] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.4885173] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02644068 0.14130221 0.06544345 0.0848857  0.01460808 0.03036341\n",
            " 0.0079988  0.036996   0.21023483 0.38172684] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1239983016693897, delta shape : (2000, 10), delta[0] : [ 1.32203386e-05  7.06511040e-05  3.27217255e-05  4.24428520e-05\n",
            "  7.30403856e-06  1.51817027e-05  3.99940190e-06  1.84980000e-05\n",
            "  1.05117415e-04 -3.09136578e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17206449 0.91825942 0.42432781 0.55005358 0.09465876 0.19677063\n",
            " 0.05172714 0.24005546 1.3680045  2.47739005] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.49331183] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02649873 0.14141619 0.06534844 0.08471079 0.01457789 0.03030359\n",
            " 0.00796622 0.03696965 0.21067901 0.38152951] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.123078462479286, delta shape : (2000, 10), delta[0] : [ 1.32493627e-05  7.07080950e-05  3.26742207e-05  4.23553955e-05\n",
            "  7.28894279e-06  1.51517928e-05  3.98310895e-06  1.84848248e-05\n",
            "  1.05339504e-04 -3.09235247e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17257603 0.91970059 0.42399907 0.54931027 0.09453283 0.19651946\n",
            " 0.0515487  0.24006026 1.3718868  2.47787454] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.49800856] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02655829 0.14153576 0.06525062 0.08453517 0.01454797 0.03024303\n",
            " 0.007933   0.03694367 0.21112419 0.3813283 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.122160749866792, delta shape : (2000, 10), delta[0] : [ 1.32791473e-05  7.07678808e-05  3.26253087e-05  4.22675860e-05\n",
            "  7.27398442e-06  1.51215148e-05  3.96649994e-06  1.84718334e-05\n",
            "  1.05562096e-04 -3.09335851e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17310148 0.92110118 0.42368586 0.54855612 0.09440322 0.196282\n",
            " 0.05137061 0.24003377 1.37560412 2.47830706] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.50244542] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02662098 0.14165458 0.06515793 0.08436151 0.01451811 0.03018588\n",
            " 0.0079002  0.03691438 0.21155181 0.38113462] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1212454625061845, delta shape : (2000, 10), delta[0] : [ 1.33104907e-05  7.08272903e-05  3.25789634e-05  4.21807551e-05\n",
            "  7.25905495e-06  1.50929375e-05  3.95009913e-06  1.84571924e-05\n",
            "  1.05775907e-04 -3.09432690e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17363177 0.92251595 0.42337374 0.5478138  0.09427373 0.19604354\n",
            " 0.05119603 0.24000976 1.37935181 2.47864254] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.50685266] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02668445 0.14177606 0.06506583 0.08419029 0.01448838 0.03012878\n",
            " 0.00786802 0.03688569 0.21198448 0.38092803] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.120333442280962, delta shape : (2000, 10), delta[0] : [ 1.33422236e-05  7.08880310e-05  3.25329131e-05  4.20951438e-05\n",
            "  7.24418788e-06  1.50643906e-05  3.93400862e-06  1.84428458e-05\n",
            "  1.05992242e-04 -3.09535987e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17416708 0.92387198 0.42307989 0.54708908 0.09414744 0.19581743\n",
            " 0.05102313 0.23997899 1.38306363 2.47907495] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.51131361] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02674838 0.14188719 0.06497612 0.08402131 0.01445905 0.03007341\n",
            " 0.00783607 0.0368557  0.21240931 0.38073346] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1194226459943577, delta shape : (2000, 10), delta[0] : [ 1.33741888e-05  7.09435940e-05  3.24880597e-05  4.20106536e-05\n",
            "  7.22952742e-06  1.50367073e-05  3.91803664e-06  1.84278479e-05\n",
            "  1.06204655e-04 -3.09633271e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1746985  0.92524029 0.42278301 0.54638954 0.09401652 0.19559416\n",
            " 0.05085172 0.23994341 1.38669327 2.4795124 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.51572282] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02681184 0.14200117 0.06488659 0.08385709 0.01442918 0.0300188\n",
            " 0.00780446 0.03682529 0.21282263 0.38054295] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1185123794742418, delta shape : (2000, 10), delta[0] : [ 1.34059190e-05  7.10005867e-05  3.24432934e-05  4.19285436e-05\n",
            "  7.21458874e-06  1.50093987e-05  3.90223172e-06  1.84126470e-05\n",
            "  1.06411315e-04 -3.09728524e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17523722 0.92657281 0.42250866 0.54568612 0.09388723 0.19537743\n",
            " 0.05068314 0.23989831 1.39031145 2.4800811 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.52024348] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02687587 0.14210709 0.06479952 0.08369106 0.01439934 0.02996474\n",
            " 0.0077732  0.03679284 0.21322999 0.38036633] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.11760506428377, delta shape : (2000, 10), delta[0] : [ 1.34379351e-05  7.10535440e-05  3.23997611e-05  4.18455324e-05\n",
            "  7.19967242e-06  1.49823722e-05  3.88659877e-06  1.83964223e-05\n",
            "  1.06614995e-04 -3.09816833e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1757757  0.92792206 0.42222069 0.54499005 0.09375851 0.19515731\n",
            " 0.05051424 0.23985942 1.39393886 2.48064512] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.52478195] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02693971 0.14221503 0.06471031 0.08352617 0.0143696  0.02991017\n",
            " 0.0077419  0.03676129 0.21363762 0.3801882 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1166997229751896, delta shape : (2000, 10), delta[0] : [ 1.34698527e-05  7.11075150e-05  3.23551567e-05  4.17630850e-05\n",
            "  7.18480050e-06  1.49550825e-05  3.87095226e-06  1.83806467e-05\n",
            "  1.06818808e-04 -3.09905899e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1763166  0.92924396 0.42193414 0.54428855 0.09362927 0.194944\n",
            " 0.05034339 0.2398165  1.39759866 2.48124452] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.52935958] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02700366 0.14231778 0.06462106 0.08336017 0.01433973 0.02985653\n",
            " 0.00771031 0.03672895 0.21404835 0.38001346] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.115794738950207, delta shape : (2000, 10), delta[0] : [ 1.35018295e-05  7.11588898e-05  3.23105299e-05  4.16800872e-05\n",
            "  7.16986644e-06  1.49282632e-05  3.85515491e-06  1.83644732e-05\n",
            "  1.07024176e-04 -3.09993270e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17686525 0.93055137 0.42165226 0.54359074 0.09349807 0.19473588\n",
            " 0.05017515 0.23977058 1.40121085 2.48176554] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.53381569] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02706921 0.14242082 0.06453385 0.08319652 0.01430987 0.02980431\n",
            " 0.0076793  0.03669687 0.21445522 0.37983403] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.114892485708494, delta shape : (2000, 10), delta[0] : [ 1.35346067e-05  7.12104089e-05  3.22669237e-05  4.15982607e-05\n",
            "  7.15493608e-06  1.49021556e-05  3.83965183e-06  1.83484347e-05\n",
            "  1.07227608e-04 -3.10082986e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17741706 0.93183522 0.42138561 0.54286653 0.09336471 0.19453755\n",
            " 0.05000741 0.23972214 1.40484849 2.48220107] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.53818579] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02713552 0.14252199 0.06444993 0.08303015 0.01427991 0.02975406\n",
            " 0.00764852 0.03666493 0.21486824 0.37964676] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.113994048277055, delta shape : (2000, 10), delta[0] : [ 1.35677593e-05  7.12609927e-05  3.22249647e-05  4.15150733e-05\n",
            "  7.13995539e-06  1.48770281e-05  3.82425753e-06  1.83324662e-05\n",
            "  1.07434121e-04 -3.10176619e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17796967 0.93309925 0.42112608 0.54215927 0.0932287  0.19434536\n",
            " 0.04984015 0.23966587 1.40845756 2.48268678] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.54257869] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02720176 0.14261949 0.06436699 0.0828663  0.01424953 0.0297047\n",
            " 0.00761781 0.03663171 0.2152756  0.37946609] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1130942180008465, delta shape : (2000, 10), delta[0] : [ 1.36008812e-05  7.13097461e-05  3.21834935e-05  4.14331485e-05\n",
            "  7.12476737e-06  1.48523519e-05  3.80890701e-06  1.83158566e-05\n",
            "  1.07637801e-04 -3.10266953e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17851992 0.93433625 0.42086832 0.54144754 0.09309311 0.1941528\n",
            " 0.04967331 0.2396017  1.4120142  2.48328006] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.54698723] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02726749 0.1427124  0.06428427 0.08270179 0.01421923 0.02965529\n",
            " 0.0075872  0.03659725 0.21567389 0.37930119] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1121961113366243, delta shape : (2000, 10), delta[0] : [ 1.36337461e-05  7.13561994e-05  3.21421372e-05  4.13508932e-05\n",
            "  7.10961458e-06  1.48276443e-05  3.79360101e-06  1.82986229e-05\n",
            "  1.07836945e-04 -3.10349404e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17906275 0.93558563 0.42061421 0.54075196 0.09295841 0.19396178\n",
            " 0.04950881 0.23954155 1.41551319 2.48391829] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.55141658] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02733191 0.14280662 0.06420202 0.0825397  0.01418905 0.02960608\n",
            " 0.00755696 0.03656332 0.21606216 0.37914217] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.111299979623128, delta shape : (2000, 10), delta[0] : [ 1.36659570e-05  7.14033078e-05  3.21010124e-05  4.12698497e-05\n",
            "  7.09452741e-06  1.48030414e-05  3.77848142e-06  1.82816607e-05\n",
            "  1.08031078e-04 -3.10428916e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.17960677 0.9368416  0.42033453 0.54006322 0.09282534 0.19376261\n",
            " 0.04934675 0.23949542 1.41902733 2.48460884] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.55591242] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02739615 0.14290026 0.06411534 0.08237804 0.01415903 0.0295554\n",
            " 0.00752706 0.03653121 0.21645001 0.3789875 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.110407374209433, delta shape : (2000, 10), delta[0] : [ 1.36980756e-05  7.14501306e-05  3.20576684e-05  4.11890204e-05\n",
            "  7.07951373e-06  1.47777000e-05  3.76353038e-06  1.82656052e-05\n",
            "  1.08225007e-04 -3.10506251e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18015851 0.93810488 0.42006258 0.53937615 0.09269796 0.19356711\n",
            " 0.04918744 0.23944654 1.42248756 2.48529771] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.56038643] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02746157 0.14299537 0.06403016 0.08221713 0.01412995 0.02950544\n",
            " 0.00749764 0.03649885 0.21682984 0.37883404] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.109516901255703, delta shape : (2000, 10), delta[0] : [ 1.37307846e-05  7.14976843e-05  3.20150793e-05  4.11085652e-05\n",
            "  7.06497726e-06  1.47527215e-05  3.74882172e-06  1.82494236e-05\n",
            "  1.08414922e-04 -3.10582979e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18071356 0.93940529 0.41978572 0.53871466 0.09257131 0.19337268\n",
            " 0.04902941 0.23939952 1.42593904 2.48594367] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.56487486] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02752734 0.14309569 0.06394421 0.08206016 0.014101   0.02945565\n",
            " 0.00746845 0.03646673 0.21720735 0.37867343] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1086307451418644, delta shape : (2000, 10), delta[0] : [ 1.37636712e-05  7.15478443e-05  3.19721036e-05  4.10300784e-05\n",
            "  7.05050088e-06  1.47278272e-05  3.73422264e-06  1.82333648e-05\n",
            "  1.08603673e-04 -3.10663286e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1812597  0.94067171 0.41952088 0.53806261 0.09244161 0.19318676\n",
            " 0.04887479 0.23936373 1.42929301 2.48656364] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.56923844] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02759219 0.14319342 0.06386142 0.08190639 0.01407189 0.02940779\n",
            " 0.00743995 0.03643706 0.21757362 0.37851627] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1077465598185308, delta shape : (2000, 10), delta[0] : [ 1.37960966e-05  7.15967090e-05  3.19307089e-05  4.09531956e-05\n",
            "  7.03594594e-06  1.47038935e-05  3.71997370e-06  1.82185296e-05\n",
            "  1.08786811e-04 -3.10741864e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18181119 0.94194125 0.41926396 0.5374322  0.09231537 0.1929997\n",
            " 0.04872228 0.23931986 1.43271508 2.48731934] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.57384021] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02765677 0.1432863  0.06377763 0.08175316 0.01404284 0.02935875\n",
            " 0.00741154 0.03640488 0.21794188 0.37836626] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1068622754248594, delta shape : (2000, 10), delta[0] : [ 1.38283852e-05  7.16431506e-05  3.18888157e-05  4.08765792e-05\n",
            "  7.02141866e-06  1.46793729e-05  3.70576967e-06  1.82024393e-05\n",
            "  1.08970939e-04 -3.10816870e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18235263 0.94325337 0.41899915 0.53680107 0.09218181 0.19281327\n",
            " 0.04856648 0.23927534 1.43622323 2.48806009] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.57852643] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02771937 0.14338369 0.06369195 0.08159898 0.01401253 0.02930949\n",
            " 0.00738258 0.03637218 0.2183199  0.37820933] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.105977900523273, delta shape : (2000, 10), delta[0] : [ 1.38596866e-05  7.16918430e-05  3.18459727e-05  4.07994921e-05\n",
            "  7.00626580e-06  1.46547459e-05  3.69128835e-06  1.81860896e-05\n",
            "  1.09159949e-04 -3.10895334e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18291044 0.94457664 0.41876862 0.53619431 0.09205489 0.19264161\n",
            " 0.0484159  0.23922106 1.43970716 2.48862205] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.58311268] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0277848  0.14348481 0.06361256 0.08144997 0.01398349 0.029263\n",
            " 0.00735456 0.03633859 0.21869703 0.37803121] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.105097211721858, delta shape : (2000, 10), delta[0] : [ 1.38923976e-05  7.17424026e-05  3.18062777e-05  4.07249833e-05\n",
            "  6.99174534e-06  1.46314986e-05  3.67728038e-06  1.81692972e-05\n",
            "  1.09348513e-04 -3.10984395e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18347054 0.94589781 0.41854311 0.53558947 0.09192859 0.19247379\n",
            " 0.04826543 0.23916045 1.44314087 2.48917834] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.5876484] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02785069 0.14358657 0.06353453 0.08130207 0.01395469 0.02921737\n",
            " 0.00732666 0.03630437 0.21906768 0.37785537] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.1042184651590814, delta shape : (2000, 10), delta[0] : [ 1.39253437e-05  7.17932826e-05  3.17672625e-05  4.06510368e-05\n",
            "  6.97734459e-06  1.46086869e-05  3.66332795e-06  1.81521869e-05\n",
            "  1.09533842e-04 -3.11072313e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18403981 0.94729336 0.41831489 0.53500082 0.0918077  0.19230225\n",
            " 0.04811844 0.23910109 1.44649219 2.48958897] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.59205951] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02791841 0.14370219 0.06345739 0.08115837 0.01392701 0.0291718\n",
            " 0.00729946 0.03627108 0.21942948 0.37766482] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.103340274759961, delta shape : (2000, 10), delta[0] : [ 1.39592040e-05  7.18510928e-05  3.17286949e-05  4.05791858e-05\n",
            "  6.96350656e-06  1.45859006e-05  3.64972765e-06  1.81355376e-05\n",
            "  1.09714740e-04 -3.11167590e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18460827 0.94869021 0.4180797  0.53442347 0.09168401 0.19213034\n",
            " 0.04796938 0.23903116 1.4497666  2.49007678] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.59645992] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02798596 0.14381808 0.0633794  0.08101671 0.01389897 0.02912628\n",
            " 0.00727199 0.03623628 0.21977949 0.37748684] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.102463475014193, delta shape : (2000, 10), delta[0] : [ 1.39929807e-05  7.19090405e-05  3.16897023e-05  4.05083539e-05\n",
            "  6.94948584e-06  1.45631403e-05  3.63599439e-06  1.81181393e-05\n",
            "  1.09889745e-04 -3.11256582e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18517    0.95005363 0.41785492 0.53386092 0.0915608  0.19196407\n",
            " 0.04782461 0.23896538 1.45304867 2.49059147] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.60089446] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02805226 0.14392801 0.06330277 0.08087706 0.01387097 0.02908152\n",
            " 0.00724517 0.03620197 0.22012906 0.37731121] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.10158978421613, delta shape : (2000, 10), delta[0] : [ 1.40261295e-05  7.19640068e-05  3.16513863e-05  4.04385289e-05\n",
            "  6.93548401e-06  1.45407619e-05  3.62258546e-06  1.81009846e-05\n",
            "  1.10064528e-04 -3.11344396e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18573382 0.95143835 0.41762966 0.53331659 0.09143799 0.19179768\n",
            " 0.04767942 0.23889955 1.45631471 2.49110509] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.60535287] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02811868 0.1440405  0.06322594 0.08074006 0.01384301 0.0290367\n",
            " 0.0072183  0.03616757 0.22047493 0.37713429] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.100717246684437, delta shape : (2000, 10), delta[0] : [ 1.40593410e-05  7.20202518e-05  3.16129715e-05  4.03700305e-05\n",
            "  6.92150686e-06  1.45183521e-05  3.60915034e-06  1.80837839e-05\n",
            "  1.10237465e-04 -3.11432853e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18630062 0.95288065 0.41740469 0.53277236 0.09131126 0.1916309\n",
            " 0.04753529 0.23881594 1.45958915 2.49159764] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.60983849] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02818535 0.14416096 0.063149   0.08060293 0.01381445 0.02899177\n",
            " 0.0071916  0.03613037 0.2208207  0.37695288] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0998424043637534, delta shape : (2000, 10), delta[0] : [ 1.40926756e-05  7.20804790e-05  3.15744998e-05  4.03014658e-05\n",
            "  6.90722317e-06  1.44958835e-05  3.59579804e-06  1.80651875e-05\n",
            "  1.10410349e-04 -3.11523561e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18686503 0.9542971  0.41719271 0.53222883 0.09118098 0.19146553\n",
            " 0.04739222 0.23872709 1.46285375 2.49210892] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.61431214] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02825162 0.1442776  0.06307424 0.08046624 0.01378541 0.02894716\n",
            " 0.0071651  0.0360925  0.22116491 0.37677522] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.098969369879677, delta shape : (2000, 10), delta[0] : [ 1.41258095e-05  7.21388013e-05  3.15371197e-05  4.02331203e-05\n",
            "  6.89270290e-06  1.44735782e-05  3.58255117e-06  1.80462519e-05\n",
            "  1.10582455e-04 -3.11612390e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18743299 0.95574719 0.41698309 0.53170847 0.09106009 0.19129789\n",
            " 0.04725076 0.23862836 1.46608913 2.49268945] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.61888742] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0283179  0.14439696 0.06299897 0.080332   0.01375761 0.02890182\n",
            " 0.00713878 0.03605264 0.22150084 0.37660249] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0980986708251486, delta shape : (2000, 10), delta[0] : [ 1.41589497e-05  7.21984776e-05  3.14994849e-05  4.01660004e-05\n",
            "  6.87880628e-06  1.44509099e-05  3.56938823e-06  1.80263199e-05\n",
            "  1.10750421e-04 -3.11698757e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18800063 0.95716949 0.41676406 0.53116167 0.09094095 0.19112887\n",
            " 0.04710861 0.2385454  1.4693879  2.49321899] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.62342657] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02838419 0.14451274 0.06292273 0.08019439 0.0137302  0.02885649\n",
            " 0.00711242 0.03601541 0.22184709 0.37642434] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.097231265009269, delta shape : (2000, 10), delta[0] : [ 1.41920975e-05  7.22563679e-05  3.14613631e-05  4.00971966e-05\n",
            "  6.86509860e-06  1.44282469e-05  3.55621170e-06  1.80077029e-05\n",
            "  1.10923544e-04 -3.11787829e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18855738 0.95857932 0.41654855 0.53059905 0.09081681 0.19096165\n",
            " 0.04696476 0.23845715 1.47270499 2.49368531] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.62787496] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02844915 0.14462846 0.06284798 0.08005568 0.01370225 0.0288119\n",
            " 0.00708594 0.03597792 0.22219867 0.37624206] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.096365957768579, delta shape : (2000, 10), delta[0] : [ 1.42245730e-05  7.23142279e-05  3.14239895e-05  4.00278413e-05\n",
            "  6.85112540e-06  1.44059486e-05  3.54297233e-06  1.79889598e-05\n",
            "  1.11099334e-04 -3.11878972e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18911326 0.95991488 0.41632658 0.53006776 0.09068867 0.19080143\n",
            " 0.0468221  0.23837566 1.47600935 2.49418913] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.63230882] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02851394 0.14473314 0.0627725  0.07992206 0.01367377 0.02876848\n",
            " 0.0070597  0.03594158 0.22254835 0.3760665 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.095501790537124, delta shape : (2000, 10), delta[0] : [ 1.42569706e-05  7.23665698e-05  3.13862478e-05  3.99610281e-05\n",
            "  6.83688531e-06  1.43842386e-05  3.52984898e-06  1.79707904e-05\n",
            "  1.11274173e-04 -3.11966752e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.18966701 0.96129157 0.41609554 0.52953102 0.09056645 0.19063399\n",
            " 0.04667733 0.23829145 1.47922795 2.49471872] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.63670103] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02857851 0.14484479 0.06269614 0.07978829 0.01364631 0.02872421\n",
            " 0.00703321 0.03590511 0.22288603 0.37589741] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.094640847722265, delta shape : (2000, 10), delta[0] : [ 1.42892541e-05  7.24223949e-05  3.13480701e-05  3.98941443e-05\n",
            "  6.82315295e-06  1.43621050e-05  3.51660661e-06  1.79525529e-05\n",
            "  1.11443015e-04 -3.12051296e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19023204 0.96265515 0.41588624 0.52902686 0.09045304 0.19048023\n",
            " 0.04653723 0.23820879 1.48241813 2.49532666] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.64122436] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02864412 0.14495146 0.06262192 0.07965803 0.01361993 0.02868149\n",
            " 0.00700733 0.0358682  0.22321458 0.37573293] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0937833141018314, delta shape : (2000, 10), delta[0] : [ 1.43220607e-05  7.24757284e-05  3.13109617e-05  3.98290159e-05\n",
            "  6.80996689e-06  1.43407461e-05  3.50366314e-06  1.79341022e-05\n",
            "  1.11607292e-04 -3.12133537e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19079968 0.96406142 0.41566874 0.52853323 0.09033407 0.19033074\n",
            " 0.04639287 0.2381132  1.48557029 2.49592167] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.64572593] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02871013 0.14506488 0.06254678 0.0795298  0.01359281 0.02863957\n",
            " 0.00698086 0.03582952 0.2235377  0.37556795] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0929274930573074, delta shape : (2000, 10), delta[0] : [ 1.43550672e-05  7.25324391e-05  3.12733886e-05  3.97648984e-05\n",
            "  6.79640385e-06  1.43197857e-05  3.49042912e-06  1.79147624e-05\n",
            "  1.11768850e-04 -3.12216025e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19136117 0.96546534 0.41545582 0.52802434 0.09021024 0.1901815\n",
            " 0.04624767 0.23801447 1.48867213 2.49648996] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.65012264] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02877558 0.14518008 0.06247341 0.07940069 0.0135652  0.02859819\n",
            " 0.00695441 0.03579099 0.22385634 0.3754051 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.09207199847904, delta shape : (2000, 10), delta[0] : [ 1.43877922e-05  7.25900402e-05  3.12367040e-05  3.97003459e-05\n",
            "  6.78259982e-06  1.42990973e-05  3.47720410e-06  1.78954948e-05\n",
            "  1.11928171e-04 -3.12297450e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19193141 0.96679601 0.41524074 0.52751622 0.0900886  0.19003619\n",
            " 0.04610464 0.23791161 1.49176664 2.49703275] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.65442481] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02884267 0.14528619 0.0624007  0.079273   0.01353815 0.02855787\n",
            " 0.00692842 0.03575239 0.22417665 0.37524396] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.091217399472652, delta shape : (2000, 10), delta[0] : [ 1.44213371e-05  7.26430939e-05  3.12003478e-05  3.96365005e-05\n",
            "  6.76907501e-06  1.42789346e-05  3.46420934e-06  1.78761962e-05\n",
            "  1.12088323e-04 -3.12378018e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19251144 0.96819766 0.41503724 0.52698602 0.08996398 0.1898928\n",
            " 0.04595798 0.23778674 1.49489086 2.49743263] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.65865734] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02891145 0.14540434 0.06233047 0.07914299 0.01351083 0.02851818\n",
            " 0.00690199 0.03571091 0.22450335 0.3750655 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.090363194769559, delta shape : (2000, 10), delta[0] : [ 1.44557248e-05  7.27021685e-05  3.11652347e-05  3.95714928e-05\n",
            "  6.75541477e-06  1.42590910e-05  3.45099466e-06  1.78554568e-05\n",
            "  1.12251673e-04 -3.12467251e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1930794  0.96959551 0.41481718 0.5264436  0.08984251 0.1897472\n",
            " 0.04581269 0.23769498 1.49808978 2.49801145] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.66313431] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02897726 0.14551643 0.06225556 0.0790084  0.01348352 0.02847717\n",
            " 0.00687555 0.03567315 0.2248326  0.37490036] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0895094907453964, delta shape : (2000, 10), delta[0] : [ 1.44886321e-05  7.27582144e-05  3.11277815e-05  3.95042016e-05\n",
            "  6.74176055e-06  1.42385845e-05  3.43777328e-06  1.78365745e-05\n",
            "  1.12416298e-04 -3.12549820e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19361843 0.97137148 0.41454416 0.52596071 0.08973083 0.18960005\n",
            " 0.04568231 0.23768841 1.50122247 2.49934963] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.66876848] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02903361 0.1456598  0.06216203 0.07886924 0.01345538 0.02843104\n",
            " 0.00685019 0.03564202 0.2251124  0.37478428] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0886598888514754, delta shape : (2000, 10), delta[0] : [ 1.45168053e-05  7.28298999e-05  3.10810132e-05  3.94346207e-05\n",
            "  6.72769115e-06  1.42155222e-05  3.42509347e-06  1.78210122e-05\n",
            "  1.12556199e-04 -3.12607858e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19415251 0.97314808 0.41425021 0.52548868 0.08961982 0.18945046\n",
            " 0.04555342 0.23768627 1.50436047 2.50077293] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.67448284] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02908877 0.14580127 0.06206476 0.078731   0.01342723 0.02838429\n",
            " 0.00682501 0.03561119 0.22538982 0.37467666] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0878147217585994, delta shape : (2000, 10), delta[0] : [ 1.45443857e-05  7.29006353e-05  3.10323823e-05  3.93654979e-05\n",
            "  6.71361513e-06  1.41921455e-05  3.41250592e-06  1.78055942e-05\n",
            "  1.12694909e-04 -3.12661671e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19469847 0.97496168 0.41396286 0.52500523 0.08950531 0.1893078\n",
            " 0.04542514 0.23767712 1.50746996 2.50206316] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.68007673] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02914614 0.14595067 0.06196978 0.07859269 0.01339884 0.02833917\n",
            " 0.00680009 0.03558    0.22566656 0.37455605] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0869709369528553, delta shape : (2000, 10), delta[0] : [ 1.45730715e-05  7.29753351e-05  3.09848883e-05  3.92963473e-05\n",
            "  6.69942205e-06  1.41695827e-05  3.40004640e-06  1.77899993e-05\n",
            "  1.12833282e-04 -3.12721975e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19523928 0.97679695 0.41366262 0.52455135 0.08939348 0.18915516\n",
            " 0.04530078 0.23767969 1.51056333 2.50343636] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.68577899] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02920217 0.14610069 0.06187202 0.07845778 0.01337069 0.02829216\n",
            " 0.00677569 0.03555004 0.22593677 0.37444199] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.086126641608208, delta shape : (2000, 10), delta[0] : [ 1.46010867e-05  7.30503471e-05  3.09360076e-05  3.92288878e-05\n",
            "  6.68534549e-06  1.41460820e-05  3.38784579e-06  1.77750188e-05\n",
            "  1.12968386e-04 -3.12779007e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19579784 0.9786396  0.41338461 0.52409449 0.08928546 0.18900686\n",
            " 0.04517869 0.23767942 1.5136652  2.50477197] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.69150414] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02926066 0.14625106 0.06177753 0.07832237 0.01334311 0.0282458\n",
            " 0.00675165 0.03551958 0.22620702 0.37432122] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0852818656763765, delta shape : (2000, 10), delta[0] : [ 1.46303307e-05  7.31255321e-05  3.08887662e-05  3.91611869e-05\n",
            "  6.67155413e-06  1.41228977e-05  3.37582441e-06  1.77597905e-05\n",
            "  1.13103509e-04 -3.12839392e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.1963405  0.98053823 0.41306375 0.52369538 0.08917685 0.18884603\n",
            " 0.04505802 0.23767145 1.5165894  2.5064401 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.69741971] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02931584 0.14640537 0.06167506 0.0781936  0.01331511 0.02819683\n",
            " 0.00672767 0.03548702 0.22644383 0.37423966] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0844422853855726, delta shape : (2000, 10), delta[0] : [ 1.46579208e-05  7.32026864e-05  3.08375290e-05  3.90968018e-05\n",
            "  6.65755275e-06  1.40984172e-05  3.36383405e-06  1.77435089e-05\n",
            "  1.13221917e-04 -3.12880168e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19687928 0.98241016 0.41275089 0.52331947 0.08906874 0.18869243\n",
            " 0.04494064 0.23767096 1.51939558 2.50799779] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.70312595] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02937126 0.14656    0.06157588 0.07807096 0.01328764 0.02814992\n",
            " 0.00670443 0.03545674 0.2266697  0.37415346] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0836051856229023, delta shape : (2000, 10), delta[0] : [ 1.46856320e-05  7.32800012e-05  3.07879408e-05  3.90354797e-05\n",
            "  6.64382145e-06  1.40749579e-05  3.35221530e-06  1.77283675e-05\n",
            "  1.13334852e-04 -3.12923268e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19742065 0.984338   0.41241951 0.52295306 0.08896812 0.18853097\n",
            " 0.04482547 0.23766994 1.52217296 2.50960734] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.70890602] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02942665 0.14672109 0.06147344 0.07794908 0.0132612  0.0281016\n",
            " 0.00668149 0.03542603 0.2268884  0.37407102] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0827703424094337, delta shape : (2000, 10), delta[0] : [ 1.47133266e-05  7.33605444e-05  3.07367187e-05  3.89745407e-05\n",
            "  6.63059818e-06  1.40507980e-05  3.34074384e-06  1.77130175e-05\n",
            "  1.13444201e-04 -3.12964489e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19795588 0.98625757 0.41208786 0.52259941 0.08886507 0.18837326\n",
            " 0.04471001 0.23766603 1.5248811  2.51122836] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.71462455] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0294813  0.14688201 0.06137169 0.07783003 0.01323456 0.02805418\n",
            " 0.0066586  0.03539528 0.22709849 0.37399386] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0819369745036505, delta shape : (2000, 10), delta[0] : [ 1.47406512e-05  7.34410065e-05  3.06858453e-05  3.89150134e-05\n",
            "  6.61727753e-06  1.40270882e-05  3.32930059e-06  1.76976413e-05\n",
            "  1.13549245e-04 -3.13003069e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19848791 0.98814913 0.41175334 0.52222681 0.08876242 0.18820769\n",
            " 0.04459395 0.23766575 1.52764012 2.51297557] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.72046269] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02953486 0.14703588 0.0612686  0.07770697 0.01320778 0.02800517\n",
            " 0.00663555 0.03536449 0.22731175 0.37392895] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0811041914844153, delta shape : (2000, 10), delta[0] : [ 1.47674290e-05  7.35179387e-05  3.06342999e-05  3.88534865e-05\n",
            "  6.60389238e-06  1.40025844e-05  3.31777358e-06  1.76822464e-05\n",
            "  1.13655874e-04 -3.13035524e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19901015 0.99002829 0.41144219 0.52187837 0.08866324 0.1880489\n",
            " 0.04447896 0.2376722  1.53046757 2.51480565] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.72649552] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02958601 0.14718337 0.06116739 0.07758548 0.01318119 0.02795644\n",
            " 0.0066125  0.03533373 0.22752822 0.37386565] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0802730095795963, delta shape : (2000, 10), delta[0] : [ 1.47930039e-05  7.35916859e-05  3.05836964e-05  3.87927390e-05\n",
            "  6.59059660e-06  1.39782221e-05  3.30625090e-06  1.76668671e-05\n",
            "  1.13764111e-04 -3.13067173e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.19953215 0.99193269 0.41112251 0.52155099 0.08856059 0.1878908\n",
            " 0.04436222 0.23767514 1.53322382 2.5166568 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.7325077] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02963712 0.1473348  0.06106529 0.07746757 0.01315418 0.027908\n",
            " 0.00658926 0.03530262 0.22773443 0.37380675] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0794429886476946, delta shape : (2000, 10), delta[0] : [ 1.48185609e-05  7.36674007e-05  3.05326434e-05  3.87337832e-05\n",
            "  6.57708781e-06  1.39539979e-05  3.29462842e-06  1.76513082e-05\n",
            "  1.13867217e-04 -3.13096627e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20005043 0.99377922 0.41083544 0.52118999 0.0884577  0.18773657\n",
            " 0.04424298 0.23766594 1.53597537 2.518433  ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.73836665] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02968827 0.14748073 0.06096959 0.07734664 0.01312747 0.02786084\n",
            " 0.00656583 0.03527056 0.22794476 0.37374532] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.078613115580682, delta shape : (2000, 10), delta[0] : [ 1.48441339e-05  7.37403642e-05  3.04847941e-05  3.86733180e-05\n",
            "  6.56373461e-06  1.39304214e-05  3.28291561e-06  1.76352782e-05\n",
            "  1.13972380e-04 -3.13127340e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20056773 0.99561468 0.41053466 0.52080945 0.08834719 0.18758237\n",
            " 0.04411922 0.23764122 1.5387766  2.52021735] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.74421046] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02973925 0.14762509 0.06087216 0.07722319 0.01309971 0.02781384\n",
            " 0.00654179 0.03523633 0.2281626  0.37368605] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0777826129842376, delta shape : (2000, 10), delta[0] : [ 1.48696228e-05  7.38125452e-05  3.04360799e-05  3.86115951e-05\n",
            "  6.54985434e-06  1.39069186e-05  3.27089575e-06  1.76181643e-05\n",
            "  1.14081300e-04 -3.13156976e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20110637 0.99745156 0.41027436 0.52042938 0.08823851 0.18743476\n",
            " 0.04400055 0.23761607 1.5416304  2.5218287 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.75001065] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02979349 0.14777037 0.06078129 0.07710053 0.01307235 0.02776807\n",
            " 0.00651859 0.03520232 0.22838933 0.37360366] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0769540620612634, delta shape : (2000, 10), delta[0] : [ 1.48967449e-05  7.38851841e-05  3.03906453e-05  3.85502638e-05\n",
            "  6.53617526e-06  1.38840341e-05  3.25929477e-06  1.76011624e-05\n",
            "  1.14194664e-04 -3.13198169e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20164796 0.99923656 0.41003017 0.52005266 0.08812525 0.18729957\n",
            " 0.04388101 0.23758172 1.54441159 2.52337942] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.75564591] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02984881 0.14791133 0.06069444 0.07698045 0.01304468 0.02772489\n",
            " 0.00649546 0.03516788 0.2286105  0.37352156] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0761282440876974, delta shape : (2000, 10), delta[0] : [ 1.49244029e-05  7.39556643e-05  3.03472218e-05  3.84902246e-05\n",
            "  6.52234070e-06  1.38624474e-05  3.24772886e-06  1.75839381e-05\n",
            "  1.14305250e-04 -3.13239219e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20218906 1.00104128 0.40978533 0.51967792 0.08801588 0.18716325\n",
            " 0.04376446 0.23754595 1.54712499 2.52494001] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.76124813] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0299041  0.14805569 0.06060794 0.07686124 0.0130177  0.02768176\n",
            " 0.00647284 0.03513345 0.22882239 0.37344289] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.075303373557882, delta shape : (2000, 10), delta[0] : [ 1.49520517e-05  7.40278469e-05  3.03039708e-05  3.84306206e-05\n",
            "  6.50884828e-06  1.38408798e-05  3.23641859e-06  1.75667231e-05\n",
            "  1.14411197e-04 -3.13278557e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20273476 1.00283593 0.40953406 0.51930622 0.0879067  0.18702707\n",
            " 0.04364747 0.23750301 1.54979777 2.52654984] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.76684284] \n",
            "softmax shape : (2000, 10) , output[0] : [0.02996002 0.1481985  0.0605207  0.07674276 0.0129908  0.02763875\n",
            " 0.0064502  0.03509805 0.22902819 0.37337203] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0744805359867224, delta shape : (2000, 10), delta[0] : [ 1.49800113e-05  7.40992481e-05  3.02603496e-05  3.83713818e-05\n",
            "  6.49539982e-06  1.38193744e-05  3.22509877e-06  1.75490266e-05\n",
            "  1.14514096e-04 -3.13313986e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20327265 1.00462143 0.40927293 0.51894352 0.08779421 0.18689282\n",
            " 0.04352887 0.23747575 1.55248494 2.52835024] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.77263736] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03001381 0.14833534 0.06043036 0.07662355 0.01296308 0.02759528\n",
            " 0.00642717 0.035064   0.22922901 0.37331841] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0736595229309236, delta shape : (2000, 10), delta[0] : [ 1.50069046e-05  7.41676677e-05  3.02151809e-05  3.83117752e-05\n",
            "  6.48153798e-06  1.37976395e-05  3.21358359e-06  1.75319994e-05\n",
            "  1.14614504e-04 -3.13340793e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20382376 1.00635931 0.409028   0.51859955 0.08768068 0.18676911\n",
            " 0.04341316 0.23744429 1.55514052 2.5299875 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.77824587] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03007028 0.14846899 0.06034423 0.0765094  0.0129356  0.0275542\n",
            " 0.00640478 0.03503034 0.22943112 0.37325107] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.072841726151547, delta shape : (2000, 10), delta[0] : [ 1.50351407e-05  7.42344941e-05  3.01721130e-05  3.82547016e-05\n",
            "  6.46779987e-06  1.37770976e-05  3.20238894e-06  1.75151721e-05\n",
            "  1.14715559e-04 -3.13374467e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20437305 1.00808953 0.4087744  0.51825749 0.08756539 0.18664349\n",
            " 0.04329775 0.23740821 1.55772189 2.53163236] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.78376356] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0301268  0.14860328 0.06025776 0.07639675 0.01290808 0.02751327\n",
            " 0.00638256 0.03499653 0.22962503 0.37318995] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0720261457330107, delta shape : (2000, 10), delta[0] : [ 1.50633975e-05  7.43016407e-05  3.01288799e-05  3.81983753e-05\n",
            "  6.45404208e-06  1.37566329e-05  3.19127761e-06  1.74982669e-05\n",
            "  1.14812514e-04 -3.13405026e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20492076 1.00980748 0.40852901 0.51790873 0.08745068 0.18651681\n",
            " 0.0431818  0.23736518 1.56035373 2.5333268 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.78936099] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03018263 0.1487338  0.06017194 0.0762824  0.01288055 0.02747192\n",
            " 0.00636022 0.03496134 0.22982336 0.37313185] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.071211217041502, delta shape : (2000, 10), delta[0] : [ 1.50913145e-05  7.43669013e-05  3.00859693e-05  3.81411984e-05\n",
            "  6.44027348e-06  1.37359621e-05  3.18010767e-06  1.74806718e-05\n",
            "  1.14911678e-04 -3.13434077e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2054616  1.01155291 0.4082646  0.51758224 0.08733719 0.18638527\n",
            " 0.04306844 0.2373237  1.56292837 2.53502306] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.7949274] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0302375  0.14886883 0.06008373 0.07617186 0.01285329 0.02743006\n",
            " 0.00633832 0.0349266  0.23001399 0.37307581] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0703984822186605, delta shape : (2000, 10), delta[0] : [ 1.51187489e-05  7.44344167e-05  3.00418660e-05  3.80859289e-05\n",
            "  6.42664660e-06  1.37150301e-05  3.16916120e-06  1.74632993e-05\n",
            "  1.15006996e-04 -3.13462093e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20599164 1.01330116 0.40799232 0.51725521 0.08722492 0.1862517\n",
            " 0.04295545 0.23729807 1.56554674 2.53674202] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.80055922] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0302904  0.14900262 0.05999394 0.07606069 0.01282614 0.0273877\n",
            " 0.00631646 0.0348939  0.23020853 0.37301962] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.06959027742557, delta shape : (2000, 10), delta[0] : [ 1.51451988e-05  7.45013114e-05  2.99969685e-05  3.80303437e-05\n",
            "  6.41306938e-06  1.36938515e-05  3.15822904e-06  1.74469525e-05\n",
            "  1.15104265e-04 -3.13490190e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20652624 1.01513532 0.40774297 0.51695207 0.08711244 0.18612477\n",
            " 0.04284396 0.23725424 1.56809782 2.53842427] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.8062141] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03034378 0.14914831 0.05990746 0.07595295 0.01279896 0.0273463\n",
            " 0.00629483 0.03485847 0.23039208 0.37295686] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.068785278730171, delta shape : (2000, 10), delta[0] : [ 1.51718886e-05  7.45741543e-05  2.99537277e-05  3.79764770e-05\n",
            "  6.39947843e-06  1.36731500e-05  3.14741523e-06  1.74292370e-05\n",
            "  1.15196040e-04 -3.13521568e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20705576 1.01692832 0.40749323 0.5166374  0.08700001 0.18599989\n",
            " 0.04273383 0.23721835 1.57061286 2.54007299] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.81175266] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03039684 0.14929026 0.05982208 0.075845   0.01277205 0.02730573\n",
            " 0.00627354 0.03482486 0.23057397 0.37289566] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0679839205934094, delta shape : (2000, 10), delta[0] : [ 1.51984207e-05  7.46451299e-05  2.99110412e-05  3.79225015e-05\n",
            "  6.38602261e-06  1.36528659e-05  3.13677230e-06  1.74124313e-05\n",
            "  1.15286985e-04 -3.13552171e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20759139 1.01872858 0.40723265 0.51631475 0.08688609 0.18586913\n",
            " 0.0426238  0.23717168 1.5730692  2.54175186] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.81723912] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03045095 0.14943419 0.05973571 0.07573663 0.01274506 0.02726458\n",
            " 0.00625236 0.03478999 0.23074872 0.37284182] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0671843098632126, delta shape : (2000, 10), delta[0] : [ 1.52254736e-05  7.47170928e-05  2.98678573e-05  3.78683171e-05\n",
            "  6.37252779e-06  1.36322877e-05  3.12617774e-06  1.73949948e-05\n",
            "  1.15374360e-04 -3.13579089e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20812638 1.02046523 0.40699384 0.51596954 0.08677381 0.18574543\n",
            " 0.04251503 0.23713031 1.57558335 2.5435477 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.82285062] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03050431 0.14956582 0.05965158 0.07562375 0.01271812 0.02722402\n",
            " 0.00623127 0.03475531 0.23092743 0.37279839] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.066384076066494, delta shape : (2000, 10), delta[0] : [ 1.52521575e-05  7.47829087e-05  2.98257911e-05  3.78118744e-05\n",
            "  6.35905833e-06  1.36120108e-05  3.11563531e-06  1.73776567e-05\n",
            "  1.15463714e-04 -3.13600807e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20865809 1.0222333  0.40675691 0.51564315 0.08666061 0.18562383\n",
            " 0.04240854 0.23707862 1.57795685 2.54512485] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.82814474] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03055853 0.14970879 0.05957063 0.07551731 0.01269168 0.02718511\n",
            " 0.00621084 0.0347208  0.23109599 0.37274032] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.06558404312958, delta shape : (2000, 10), delta[0] : [ 1.52792668e-05  7.48543957e-05  2.97853169e-05  3.77586571e-05\n",
            "  6.34583873e-06  1.35925525e-05  3.10542151e-06  1.73603980e-05\n",
            "  1.15547993e-04 -3.13629841e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20917845 1.02397451 0.40652962 0.51530009 0.08654616 0.18550246\n",
            " 0.04230071 0.23702975 1.58035289 2.54689923] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.83361387] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03061022 0.14984378 0.0594897  0.07540667 0.01266477 0.02714559\n",
            " 0.00619009 0.03468586 0.23126166 0.37270166] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0647831628322857, delta shape : (2000, 10), delta[0] : [ 1.53051116e-05  7.49218885e-05  2.97448489e-05  3.77033368e-05\n",
            "  6.33238621e-06  1.35727935e-05  3.09504655e-06  1.73429282e-05\n",
            "  1.15630830e-04 -3.13649170e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.20971182 1.02573321 0.40631876 0.51494433 0.08643744 0.18538439\n",
            " 0.04219449 0.23697412 1.58284625 2.54858748] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.83913228] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03066351 0.14998002 0.05941086 0.07529381 0.01263866 0.02710642\n",
            " 0.00616957 0.03464974 0.23143963 0.37264778] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0639825150303928, delta shape : (2000, 10), delta[0] : [ 1.53317567e-05  7.49900107e-05  2.97054319e-05  3.76469051e-05\n",
            "  6.31932791e-06  1.35532100e-05  3.08478363e-06  1.73248677e-05\n",
            "  1.15719815e-04 -3.13676109e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21026225 1.02742091 0.40613282 0.51459273 0.08633084 0.18528273\n",
            " 0.04208371 0.23693367 1.58541053 2.55013882] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.844589] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03071948 0.15010703 0.05933633 0.07518242 0.01261301 0.02706996\n",
            " 0.00614846 0.0346162  0.23162976 0.37257735] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0631833152868, delta shape : (2000, 10), delta[0] : [ 1.53597425e-05  7.50535136e-05  2.96681668e-05  3.75912077e-05\n",
            "  6.30650270e-06  1.35349785e-05  3.07423191e-06  1.73081009e-05\n",
            "  1.15814881e-04 -3.13711326e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21083324 1.02913812 0.4059455  0.51422238 0.08623388 0.18517063\n",
            " 0.04197611 0.23687658 1.5881262  2.55164048] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.85016312] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03077784 0.15023556 0.05926071 0.07506717 0.01258859 0.02703157\n",
            " 0.00612775 0.0345797  0.23183772 0.37249339] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0623842767354743, delta shape : (2000, 10), delta[0] : [ 1.53889210e-05  7.51177818e-05  2.96303529e-05  3.75335865e-05\n",
            "  6.29429415e-06  1.35157827e-05  3.06387679e-06  1.72898493e-05\n",
            "  1.15918860e-04 -3.13753305e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21139908 1.03077544 0.40577083 0.51383137 0.08613261 0.18506852\n",
            " 0.04186607 0.2368236  1.59077747 2.55310496] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.85554997] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0308362  0.15035635 0.05918866 0.07495115 0.01256392 0.02699543\n",
            " 0.00610689 0.0345448  0.23204228 0.37241432] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0615859417288784, delta shape : (2000, 10), delta[0] : [ 1.54180978e-05  7.51781730e-05  2.95943312e-05  3.74755764e-05\n",
            "  6.28196229e-06  1.34977151e-05  3.05344356e-06  1.72724001e-05\n",
            "  1.16021142e-04 -3.13792841e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21196719 1.03246424 0.40559292 0.51345452 0.08603376 0.18496591\n",
            " 0.04175842 0.23677109 1.59344301 2.55455349] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.86100454] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03089448 0.15048296 0.05911568 0.07483664 0.01253953 0.02695901\n",
            " 0.00608634 0.03450968 0.23224631 0.37232937] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.060789918316176, delta shape : (2000, 10), delta[0] : [ 1.54472415e-05  7.52414776e-05  2.95578375e-05  3.74183198e-05\n",
            "  6.26976375e-06  1.34795068e-05  3.04317104e-06  1.72548414e-05\n",
            "  1.16123156e-04 -3.13835316e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21253088 1.03405661 0.40541738 0.51304629 0.08593173 0.18485968\n",
            " 0.04165138 0.23670607 1.59602516 2.55609693] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.86632211] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03095265 0.15059833 0.05904433 0.07471923 0.01251496 0.02692266\n",
            " 0.00606604 0.03447349 0.23244251 0.3722658 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.059996653685301, delta shape : (2000, 10), delta[0] : [ 1.54763264e-05  7.52991629e-05  2.95221645e-05  3.73596141e-05\n",
            "  6.25747879e-06  1.34613317e-05  3.03301954e-06  1.72367439e-05\n",
            "  1.16221256e-04 -3.13867098e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21308695 1.0357048  0.40522084 0.51267604 0.08583117 0.18475189\n",
            " 0.04154512 0.23663848 1.5984989  2.55761323] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.87156742] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03100995 0.15072322 0.05897066 0.07460831 0.01249077 0.02688643\n",
            " 0.00604594 0.03443734 0.23262508 0.3722023 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0592050500761943, delta shape : (2000, 10), delta[0] : [ 1.55049738e-05  7.53616121e-05  2.94853278e-05  3.73041557e-05\n",
            "  6.24538537e-06  1.34432133e-05  3.02297229e-06  1.72186686e-05\n",
            "  1.16312539e-04 -3.13898848e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21364418 1.03736574 0.40500343 0.51228177 0.08573046 0.18463639\n",
            " 0.04143845 0.23658708 1.60111947 2.55912234] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.87692933] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0310668  0.15084723 0.05889306 0.07449281 0.01246639 0.02684867\n",
            " 0.00602572 0.03440301 0.23282477 0.37213155] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0584118681413375, delta shape : (2000, 10), delta[0] : [ 1.55333998e-05  7.54236152e-05  2.94465314e-05  3.72464038e-05\n",
            "  6.23319304e-06  1.34243339e-05  3.01286015e-06  1.72015060e-05\n",
            "  1.16412384e-04 -3.13934227e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2141931  1.03897304 0.40479032 0.5118623  0.08563153 0.18451995\n",
            " 0.04133126 0.23652895 1.60367344 2.5607435 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.88224738] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03112255 0.15096421 0.05881659 0.07437429 0.01244238 0.026811\n",
            " 0.00600549 0.03436798 0.23301595 0.37207955] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0576213928895806, delta shape : (2000, 10), delta[0] : [ 1.55612755e-05  7.54821049e-05  2.94082947e-05  3.71871475e-05\n",
            "  6.22118937e-06  1.34055014e-05  3.00274463e-06  1.71839910e-05\n",
            "  1.16507977e-04 -3.13960226e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21474526 1.04056261 0.40459721 0.5114845  0.08553029 0.18441299\n",
            " 0.04122952 0.23647233 1.60616363 2.56234695] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.88754529] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03117878 0.15107888 0.05874331 0.07426223 0.01241811 0.02677485\n",
            " 0.0059861  0.03433332 0.23319827 0.37202615] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.056834214431501, delta shape : (2000, 10), delta[0] : [ 1.55893901e-05  7.55394386e-05  2.93716551e-05  3.71311167e-05\n",
            "  6.20905458e-06  1.33874252e-05  2.99304890e-06  1.71666623e-05\n",
            "  1.16599134e-04 -3.13986925e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2153035  1.04215689 0.40440001 0.51111937 0.08543014 0.18430861\n",
            " 0.04112907 0.2364111  1.60860339 2.56392984] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.89279193] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03123604 0.15119518 0.05866999 0.07415274 0.01239413 0.02673933\n",
            " 0.00596697 0.03429831 0.23337472 0.37197262] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0560487362103523, delta shape : (2000, 10), delta[0] : [ 1.56180182e-05  7.55975881e-05  2.93349936e-05  3.70763676e-05\n",
            "  6.19706380e-06  1.33696631e-05  2.98348374e-06  1.71491542e-05\n",
            "  1.16687360e-04 -3.14013692e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21585977 1.04377512 0.40417661 0.51072075 0.08533387 0.18419661\n",
            " 0.04102568 0.23636413 1.61114078 2.56549607] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.89808938] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03129269 0.15131366 0.05859254 0.074038   0.01237065 0.02670256\n",
            " 0.0059474  0.03426516 0.23356334 0.37191401] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.055265037588767, delta shape : (2000, 10), delta[0] : [ 1.56463446e-05  7.56568277e-05  2.92962722e-05  3.70190006e-05\n",
            "  6.18532623e-06  1.33512777e-05  2.97369859e-06  1.71325794e-05\n",
            "  1.16781669e-04 -3.14042996e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21641502 1.04534388 0.40395043 0.51033553 0.08523829 0.18408286\n",
            " 0.04092448 0.23632074 1.61369251 2.567155  ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.90345874] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03134878 0.15142321 0.05851421 0.07392462 0.01234719 0.02666531\n",
            " 0.00592811 0.03423222 0.23375131 0.37186505] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0544835527589194, delta shape : (2000, 10), delta[0] : [ 1.56743908e-05  7.57116046e-05  2.92571047e-05  3.69623078e-05\n",
            "  6.17359305e-06  1.33326542e-05  2.96405639e-06  1.71161118e-05\n",
            "  1.16875654e-04 -3.14067477e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21696246 1.04686991 0.40368885 0.50998246 0.08514342 0.18396792\n",
            " 0.04082318 0.23627722 1.6160952  2.56890941] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.90872003] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03140415 0.15152878 0.05843179 0.07381721 0.01232405 0.02662836\n",
            " 0.00590894 0.03419985 0.23392107 0.3718358 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.053704876101502, delta shape : (2000, 10), delta[0] : [ 1.57020736e-05  7.57643897e-05  2.92158928e-05  3.69086069e-05\n",
            "  6.16202536e-06  1.33141824e-05  2.95446751e-06  1.70999273e-05\n",
            "  1.16960537e-04 -3.14082102e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21750927 1.04837098 0.40342364 0.50964878 0.08504928 0.18385267\n",
            " 0.04072459 0.23623205 1.61837989 2.57076154] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.9139527] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03145947 0.15163121 0.0583492  0.07371308 0.01230111 0.02659154\n",
            " 0.0058902  0.03416744 0.23407448 0.37182226] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0529269208299357, delta shape : (2000, 10), delta[0] : [ 1.57297336e-05  7.58156026e-05  2.91746021e-05  3.68565422e-05\n",
            "  6.15055398e-06  1.32957717e-05  2.94510189e-06  1.70837192e-05\n",
            "  1.17037241e-04 -3.14088868e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21806032 1.04986559 0.40316123 0.50928587 0.08496397 0.18373552\n",
            " 0.04062957 0.23618646 1.62067024 2.57259506] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.91915384] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03151546 0.15173323 0.05826742 0.07360522 0.01227953 0.02655462\n",
            " 0.00587204 0.03413517 0.23422954 0.37180776] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.052149371509383, delta shape : (2000, 10), delta[0] : [ 1.57577304e-05  7.58666170e-05  2.91337088e-05  3.68026122e-05\n",
            "  6.13976596e-06  1.32773116e-05  2.93602179e-06  1.70675827e-05\n",
            "  1.17114771e-04 -3.14096122e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21860472 1.05125248 0.402907   0.50889508 0.08487278 0.18361983\n",
            " 0.04053476 0.23614404 1.62297943 2.57449683] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.92430695] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03157063 0.15182061 0.05818734 0.07349401 0.01225722 0.02651815\n",
            " 0.00585398 0.03410364 0.23438872 0.37180571] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0513741438969646, delta shape : (2000, 10), delta[0] : [ 1.57853140e-05  7.59103031e-05  2.90936698e-05  3.67470049e-05\n",
            "  6.12861155e-06  1.32590764e-05  2.92699048e-06  1.70518179e-05\n",
            "  1.17194359e-04 -3.14097147e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21915865 1.05267676 0.40265731 0.5084802  0.08478548 0.18350272\n",
            " 0.04043919 0.236087   1.62532283 2.57633252] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.92944267] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03162717 0.15191363 0.05810818 0.07337967 0.01223554 0.0264816\n",
            " 0.00583585 0.03407013 0.23455318 0.37179506] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0505995394142933, delta shape : (2000, 10), delta[0] : [ 1.58135840e-05  7.59568127e-05  2.90540905e-05  3.66898340e-05\n",
            "  6.11777082e-06  1.32407996e-05  2.91792538e-06  1.70350643e-05\n",
            "  1.17276591e-04 -3.14102472e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.21971542 1.05414034 0.40240742 0.50807428 0.08470227 0.1833862\n",
            " 0.04034431 0.23603192 1.62773935 2.57824587] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.93478737] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03168308 0.15200759 0.05802736 0.07326458 0.01221411 0.02644439\n",
            " 0.00581767 0.03403593 0.23472087 0.37178442] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0498263622744686, delta shape : (2000, 10), delta[0] : [ 1.58415396e-05  7.60037965e-05  2.90136809e-05  3.66322896e-05\n",
            "  6.10705605e-06  1.32221936e-05  2.90883545e-06  1.70179637e-05\n",
            "  1.17360437e-04 -3.14107792e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22027693 1.05551091 0.40217889 0.50766305 0.0846177  0.18327708\n",
            " 0.0402501  0.23597064 1.63009066 2.58024753] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.94008351] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03173981 0.15208908 0.05795015 0.07314941 0.01219261 0.02640848\n",
            " 0.00579966 0.03400112 0.23488055 0.37178912] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0490555108836768, delta shape : (2000, 10), delta[0] : [ 1.58699051e-05  7.60445396e-05  2.89750759e-05  3.65747073e-05\n",
            "  6.09630307e-06  1.32042418e-05  2.89982843e-06  1.70005623e-05\n",
            "  1.17440277e-04 -3.14105441e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22082905 1.05690747 0.40195248 0.50726647 0.08453259 0.18316931\n",
            " 0.04015755 0.23591362 1.63241447 2.58237493] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.94551793] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03179447 0.15217115 0.05787221 0.07303508 0.01217081 0.0263723\n",
            " 0.00578179 0.03396631 0.23503135 0.37180452] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.04828554497948, delta shape : (2000, 10), delta[0] : [ 1.58972339e-05  7.60855764e-05  2.89361057e-05  3.65175408e-05\n",
            "  6.08540546e-06  1.31861518e-05  2.89089695e-06  1.69831554e-05\n",
            "  1.17515676e-04 -3.14097742e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22137976 1.0582816  0.40173426 0.50685611 0.08444857 0.18306447\n",
            " 0.0400653  0.23585959 1.63473912 2.58451661] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.95094537] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03184887 0.15225002 0.05779563 0.07291902 0.01214922 0.02633663\n",
            " 0.00576401 0.03393202 0.23518227 0.37182232] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.047516408215198, delta shape : (2000, 10), delta[0] : [ 1.59244354e-05  7.61250117e-05  2.88978142e-05  3.64595087e-05\n",
            "  6.07461042e-06  1.31683143e-05  2.88200377e-06  1.69660081e-05\n",
            "  1.17591135e-04 -3.14088842e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22192219 1.05962353 0.40152313 0.50642161 0.08436065 0.18295819\n",
            " 0.03997249 0.23580253 1.63710111 2.58668293] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.95636836] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03190202 0.15232424 0.05772022 0.07279971 0.01212711 0.02630082\n",
            " 0.00574617 0.03389736 0.23533847 0.37184387] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.046748952897213, delta shape : (2000, 10), delta[0] : [ 1.59510094e-05  7.61621206e-05  2.88601115e-05  3.63998559e-05\n",
            "  6.06355520e-06  1.31504096e-05  2.87308610e-06  1.69486805e-05\n",
            "  1.17669237e-04 -3.14078065e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22246681 1.06101131 0.40129643 0.50600935 0.08427417 0.18285036\n",
            " 0.03988143 0.23574714 1.63936463 2.58884107] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.9617427] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03195562 0.15240599 0.0576431  0.07268429 0.01210533 0.02626503\n",
            " 0.00572866 0.03386324 0.23548193 0.37186681] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.045982187267481, delta shape : (2000, 10), delta[0] : [ 1.59778105e-05  7.62029963e-05  2.88215503e-05  3.63421466e-05\n",
            "  6.05266310e-06  1.31325133e-05  2.86432817e-06  1.69316183e-05\n",
            "  1.17740967e-04 -3.14066594e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22300212 1.06254109 0.40105613 0.50562646 0.0841871  0.18273618\n",
            " 0.03979128 0.23567995 1.64158433 2.59104902] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.96725367] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03200718 0.15250501 0.05756302 0.07257185 0.01208325 0.02622786\n",
            " 0.00571119 0.03382681 0.23561426 0.37188958] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.045214394411652, delta shape : (2000, 10), delta[0] : [ 1.60035884e-05  7.62525050e-05  2.87815080e-05  3.62859230e-05\n",
            "  6.04162746e-06  1.31139320e-05  2.85559292e-06  1.69134035e-05\n",
            "  1.17807131e-04 -3.14055211e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22353806 1.06401627 0.40082537 0.50522826 0.08409958 0.18262312\n",
            " 0.03970155 0.23561373 1.64383472 2.593291  ] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.97277166] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03205871 0.15259589 0.05748437 0.07245731 0.01206114 0.02619089\n",
            " 0.0056938  0.03379054 0.23575055 0.37191681] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.044446192103742, delta shape : (2000, 10), delta[0] : [ 1.60293545e-05  7.62979428e-05  2.87421839e-05  3.62286534e-05\n",
            "  6.03057059e-06  1.30954466e-05  2.84689898e-06  1.68952705e-05\n",
            "  1.17875273e-04 -3.14041594e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22407715 1.06546985 0.40061099 0.50481792 0.08401245 0.18251266\n",
            " 0.03961026 0.23553636 1.64605349 2.59545787] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.978159] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03211121 0.15268638 0.05740927 0.07234256 0.01203934 0.02615484\n",
            " 0.00567632 0.03375337 0.2358865  0.3719402 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.04367751650778, delta shape : (2000, 10), delta[0] : [ 1.60556066e-05  7.63431907e-05  2.87046336e-05  3.61712823e-05\n",
            "  6.01967158e-06  1.30774223e-05  2.83815963e-06  1.68766835e-05\n",
            "  1.17943249e-04 -3.14029899e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22461168 1.06696649 0.40038722 0.50442878 0.08392797 0.18239836\n",
            " 0.03952415 0.23546538 1.64822393 2.59759773] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.98353168] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03216305 0.15278322 0.05733306 0.07223119 0.01201798 0.02611835\n",
            " 0.00565962 0.03371723 0.23601582 0.37196047] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0429094650554958, delta shape : (2000, 10), delta[0] : [ 1.60815252e-05  7.63916122e-05  2.86665288e-05  3.61155931e-05\n",
            "  6.00899210e-06  1.30591773e-05  2.82981075e-06  1.68586174e-05\n",
            "  1.18007908e-04 -3.14019765e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22513685 1.06858463 0.40014855 0.50404135 0.08384333 0.18227855\n",
            " 0.03943618 0.23539281 1.65024665 2.59956266] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.98867155] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03221454 0.1529024  0.05725674 0.07212263 0.01199703 0.026082\n",
            " 0.00564287 0.03368205 0.23613167 0.37196807] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0421403520547927, delta shape : (2000, 10), delta[0] : [ 1.61072710e-05  7.64511986e-05  2.86283698e-05  3.60613134e-05\n",
            "  5.99851673e-06  1.30410012e-05  2.82143590e-06  1.68410266e-05\n",
            "  1.18065833e-04 -3.14015966e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22566165 1.07018745 0.39992644 0.50368061 0.08375664 0.18216506\n",
            " 0.03934991 0.23532018 1.65227182 2.60147732] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.99379708] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03226597 0.15301952 0.05718302 0.07201819 0.01197585 0.02604666\n",
            " 0.0056264  0.03364698 0.23624818 0.37196923] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0413734916888693, delta shape : (2000, 10), delta[0] : [ 1.61329850e-05  7.65097581e-05  2.85915103e-05  3.60090954e-05\n",
            "  5.98792295e-06  1.30233303e-05  2.81320096e-06  1.68234923e-05\n",
            "  1.18124089e-04 -3.14015384e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22617324 1.07177249 0.39971543 0.50332272 0.08366946 0.18205586\n",
            " 0.03926707 0.23526358 1.65428652 2.60340779] \n",
            "softmax sums : (2000, 1) , sums[0] : [6.99893414] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03231538 0.15313367 0.0571109  0.0719142  0.0119546  0.02601194\n",
            " 0.00561044 0.0336142  0.23636264 0.37197204] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0406092115237335, delta shape : (2000, 10), delta[0] : [ 1.61576916e-05  7.65668362e-05  2.85554499e-05  3.59570976e-05\n",
            "  5.97730009e-06  1.30059703e-05  2.80521766e-06  1.68071006e-05\n",
            "  1.18181318e-04 -3.14013982e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22668735 1.07333464 0.39951906 0.50295471 0.08358257 0.18195081\n",
            " 0.03918275 0.23519955 1.65636025 2.60528047] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.00405215] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03236517 0.15324481 0.05704113 0.0718091  0.01193346 0.02597793\n",
            " 0.0055943  0.0335805  0.236486   0.3719676 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.039846382673329, delta shape : (2000, 10), delta[0] : [ 1.61825862e-05  7.66224050e-05  2.85205656e-05  3.59045517e-05\n",
            "  5.96672939e-06  1.29889672e-05  2.79714832e-06  1.67902481e-05\n",
            "  1.18242998e-04 -3.14016200e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22720157 1.07490631 0.39931866 0.50262408 0.08349788 0.18184843\n",
            " 0.03910003 0.2351373  1.65840107 2.60713817] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.00917351] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03241489 0.15335707 0.05697086 0.07170946 0.01191266 0.02594435\n",
            " 0.00557841 0.03354708 0.23660437 0.37196086] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0390869688407838, delta shape : (2000, 10), delta[0] : [ 1.62074436e-05  7.66785351e-05  2.84854309e-05  3.58547323e-05\n",
            "  5.95632865e-06  1.29721738e-05  2.78920409e-06  1.67735395e-05\n",
            "  1.18302184e-04 -3.14019572e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22771635 1.07641561 0.39912963 0.50227338 0.0834124  0.18174844\n",
            " 0.03901637 0.23507306 1.66043795 2.60905447] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.01427766] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03246469 0.15346065 0.05690246 0.07160729 0.0118918  0.02591121\n",
            " 0.00556242 0.03351351 0.23672259 0.37196339] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0383305649663557, delta shape : (2000, 10), delta[0] : [ 1.62323449e-05  7.67303247e-05  2.84512284e-05  3.58036428e-05\n",
            "  5.94590058e-06  1.29556062e-05  2.78121082e-06  1.67567548e-05\n",
            "  1.18361294e-04 -3.14018307e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22823356 1.07787651 0.39894842 0.50190253 0.08332871 0.18164467\n",
            " 0.03893195 0.23499148 1.66246651 2.61110356] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.01942789] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03251455 0.15355618 0.05683489 0.07150191 0.01187115 0.02587742\n",
            " 0.00554631 0.0334773  0.23683789 0.37198239] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0375770045929444, delta shape : (2000, 10), delta[0] : [ 1.62572762e-05  7.67780886e-05  2.84174459e-05  3.57509570e-05\n",
            "  5.93557672e-06  1.29387093e-05  2.77315682e-06  1.67386489e-05\n",
            "  1.18418946e-04 -3.14008805e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22874561 1.07941231 0.39873739 0.50157835 0.0832479  0.18154068\n",
            " 0.0388501  0.23491614 1.66447726 2.61321434] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.02472008] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03256295 0.15365912 0.05676203 0.0714019  0.01185071 0.02584312\n",
            " 0.00553048 0.03344135 0.23694571 0.37200263] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0368239766888783, delta shape : (2000, 10), delta[0] : [ 1.62814749e-05  7.68295606e-05  2.83810162e-05  3.57009492e-05\n",
            "  5.92535366e-06  1.29215596e-05  2.76524176e-06  1.67206764e-05\n",
            "  1.18472853e-04 -3.13998686e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22925539 1.08092071 0.39853442 0.50125478 0.08316532 0.18144013\n",
            " 0.03876817 0.23483862 1.66648483 2.61539674] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.03005912] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03261073 0.15375699 0.05669005 0.07130164 0.01182996 0.02580919\n",
            " 0.00551463 0.03340493 0.23705133 0.37203055] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0360730678076577, delta shape : (2000, 10), delta[0] : [ 1.63053671e-05  7.68784939e-05  2.83450262e-05  3.56508222e-05\n",
            "  5.91498037e-06  1.29045949e-05  2.75731494e-06  1.67024642e-05\n",
            "  1.18525663e-04 -3.13984727e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.22976969 1.08241978 0.39833001 0.5009108  0.08308467 0.18133406\n",
            " 0.03868446 0.23476297 1.66854607 2.61767691] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.0355194] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03265853 0.15385073 0.056617   0.07119742 0.01180932 0.02577408\n",
            " 0.00549845 0.03336825 0.23716032 0.37206591] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0353229769975867, delta shape : (2000, 10), delta[0] : [ 1.63292625e-05  7.69253641e-05  2.83085006e-05  3.55987075e-05\n",
            "  5.90465764e-06  1.28870412e-05  2.74922569e-06  1.66841249e-05\n",
            "  1.18580162e-04 -3.13967046e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23028463 1.08391241 0.3981338  0.50057237 0.08300195 0.18123151\n",
            " 0.03860114 0.23468457 1.67055971 2.61992099] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.04090308] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03270669 0.15394508 0.05654584 0.07109491 0.01178854 0.02573981\n",
            " 0.00548241 0.0333316  0.23726498 0.37210014] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.034575292382778, delta shape : (2000, 10), delta[0] : [ 1.63533446e-05  7.69725415e-05  2.82729217e-05  3.55474548e-05\n",
            "  5.89426856e-06  1.28699050e-05  2.74120690e-06  1.66658007e-05\n",
            "  1.18632488e-04 -3.13949932e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2307856  1.08541731 0.39793456 0.50024966 0.0829218  0.18112846\n",
            " 0.03852138 0.23461975 1.6725466  2.62226731] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.04639243] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03275231 0.15403873 0.05647352 0.07099373 0.01176798 0.02570513\n",
            " 0.00546682 0.03329643 0.23736211 0.37214324] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.033830455958892, delta shape : (2000, 10), delta[0] : [ 1.63761531e-05  7.70193626e-05  2.82367583e-05  3.54968633e-05\n",
            "  5.88398940e-06  1.28525670e-05  2.73341172e-06  1.66482174e-05\n",
            "  1.18681057e-04 -3.13928380e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23126179 1.08688686 0.39775194 0.49990728 0.08284263 0.18102515\n",
            " 0.03843797 0.23455941 1.67458721 2.6246975 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.05195776] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03279398 0.15412555 0.05640305 0.07088915 0.01174747 0.0256702\n",
            " 0.00545068 0.0332616  0.23746416 0.37219416] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0330883674469495, delta shape : (2000, 10), delta[0] : [ 1.63969922e-05  7.70627741e-05  2.82015263e-05  3.54445743e-05\n",
            "  5.87373278e-06  1.28350991e-05  2.72534066e-06  1.66308011e-05\n",
            "  1.18732079e-04 -3.13902920e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23173085 1.08836099 0.39756844 0.49959008 0.08276413 0.18092562\n",
            " 0.03835511 0.23450216 1.67653757 2.62701273] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.05734768] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0328354  0.15421672 0.05633397 0.07079006 0.01172737 0.02563649\n",
            " 0.00543478 0.03322809 0.23755916 0.37223796] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.032347418630971, delta shape : (2000, 10), delta[0] : [ 1.64177015e-05  7.71083586e-05  2.81669873e-05  3.53950313e-05\n",
            "  5.86368486e-06  1.28182446e-05  2.71738811e-06  1.66140434e-05\n",
            "  1.18779579e-04 -3.13881018e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23219769 1.08989002 0.39738821 0.49928001 0.08268035 0.18082754\n",
            " 0.0382715  0.23443624 1.67847979 2.62932189] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.06277324] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03287628 0.15431474 0.05626518 0.07069178 0.0117065  0.02560291\n",
            " 0.00541876 0.03319323 0.23765166 0.37227896] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0316061137885915, delta shape : (2000, 10), delta[0] : [ 1.64381384e-05  7.71573704e-05  2.81325902e-05  3.53458896e-05\n",
            "  5.85324991e-06  1.28014546e-05  2.70938210e-06  1.65966135e-05\n",
            "  1.18825830e-04 -3.13860519e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23267436 1.09140236 0.39721749 0.49894839 0.08260134 0.18072726\n",
            " 0.03818878 0.23436902 1.68050544 2.63167836] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.06831279] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03291795 0.15440776 0.05619693 0.07058946 0.01168615 0.02556866\n",
            " 0.00540281 0.0331577  0.23775199 0.37232059] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0308642370862966, delta shape : (2000, 10), delta[0] : [ 1.64589747e-05  7.72038810e-05  2.80984659e-05  3.52947302e-05\n",
            "  5.84307304e-06  1.27843279e-05  2.70140711e-06  1.65788519e-05\n",
            "  1.18875996e-04 -3.13839707e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23316676 1.09295792 0.39704517 0.49860835 0.08252092 0.18063293\n",
            " 0.03810892 0.23428895 1.6824018  2.63385405] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.07358578] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03296302 0.15451257 0.05613068 0.07048877 0.01166607 0.02553626\n",
            " 0.0053875  0.03312167 0.23784285 0.37235062] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0301220353156815, delta shape : (2000, 10), delta[0] : [ 1.64815106e-05  7.72562855e-05  2.80653396e-05  3.52443845e-05\n",
            "  5.83303300e-06  1.27681306e-05  2.69374811e-06  1.65608335e-05\n",
            "  1.18921425e-04 -3.13824690e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2336621  1.09449687 0.39685905 0.49824085 0.08243951 0.18053531\n",
            " 0.03802706 0.23421641 1.68440031 2.63598174] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.07885921] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03300844 0.15461487 0.05606257 0.07038434 0.01164587 0.02550345\n",
            " 0.00537192 0.03308675 0.23794799 0.37237381] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.029380641618865, delta shape : (2000, 10), delta[0] : [ 1.65042200e-05  7.73074330e-05  2.80312855e-05  3.51921714e-05\n",
            "  5.82293749e-06  1.27517237e-05  2.68595928e-06  1.65433727e-05\n",
            "  1.18973994e-04 -3.13813097e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23416034 1.09607511 0.39665233 0.497865   0.08236202 0.18043161\n",
            " 0.03794624 0.23416012 1.68638196 2.63805038] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.08408511] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03305442 0.15472359 0.05599203 0.07027936 0.01162635 0.02546999\n",
            " 0.00535655 0.03305439 0.23805219 0.37239112] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.028640717150839, delta shape : (2000, 10), delta[0] : [ 1.65272110e-05  7.73617970e-05  2.79960167e-05  3.51396823e-05\n",
            "  5.81317291e-06  1.27349971e-05  2.67827363e-06  1.65271957e-05\n",
            "  1.19026094e-04 -3.13804440e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23464001 1.09768283 0.39644886 0.49747199 0.08227962 0.1803278\n",
            " 0.03786307 0.23409533 1.68835432 2.6400506 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.08921442] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03309817 0.15483843 0.05592282 0.07017308 0.01160631 0.02543692\n",
            " 0.00534094 0.03302134 0.23815817 0.37240383] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.027902879498545, delta shape : (2000, 10), delta[0] : [ 1.65490843e-05  7.74192147e-05  2.79614096e-05  3.50865384e-05\n",
            "  5.80315514e-06  1.27184617e-05  2.67046991e-06  1.65106679e-05\n",
            "  1.19079084e-04 -3.13798086e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23512301 1.09928031 0.39626146 0.49707777 0.08219892 0.18022925\n",
            " 0.03778149 0.23403067 1.69031848 2.64206649] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.09436784] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03314221 0.15495113 0.05585578 0.07006654 0.0115865  0.02540455\n",
            " 0.00532556 0.03298823 0.23826203 0.37241747] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0271655369367747, delta shape : (2000, 10), delta[0] : [ 1.65711037e-05  7.74755647e-05  2.79278906e-05  3.50332675e-05\n",
            "  5.79325177e-06  1.27022766e-05  2.66278066e-06  1.64941174e-05\n",
            "  1.19131014e-04 -3.13791267e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2356112  1.10086346 0.396093   0.49667466 0.08211942 0.18013898\n",
            " 0.03770106 0.23397064 1.69230719 2.64400442] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.09948402] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03318709 0.15506246 0.0557918  0.06995926 0.01156696 0.02537353\n",
            " 0.00531039 0.03295601 0.23837045 0.37242205] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.026426136546681, delta shape : (2000, 10), delta[0] : [ 1.65935438e-05  7.75312304e-05  2.78959002e-05  3.49796307e-05\n",
            "  5.78347798e-06  1.26867659e-05  2.65519725e-06  1.64780031e-05\n",
            "  1.19185224e-04 -3.13788973e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23609962 1.102401   0.39591428 0.49626588 0.08203692 0.18004561\n",
            " 0.03762022 0.23390312 1.69423657 2.64596039] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.10448361] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03323248 0.15516976 0.05572738 0.06985249 0.0115472  0.02534253\n",
            " 0.00529528 0.03292331 0.23847427 0.37243529] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0256884233174905, delta shape : (2000, 10), delta[0] : [ 1.66162409e-05  7.75848789e-05  2.78636915e-05  3.49262459e-05\n",
            "  5.77360171e-06  1.26712663e-05  2.64763905e-06  1.64616553e-05\n",
            "  1.19237137e-04 -3.13782356e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23658842 1.10390243 0.39574716 0.49583385 0.08195117 0.17995656\n",
            " 0.03753907 0.23383796 1.69621434 2.64780934] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.10938031] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03327835 0.15527407 0.05566549 0.06974361 0.01152719 0.02531255\n",
            " 0.00528022 0.03289147 0.23858821 0.37243884] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0249520376600008, delta shape : (2000, 10), delta[0] : [ 1.66391729e-05  7.76370358e-05  2.78327465e-05  3.48718054e-05\n",
            "  5.76359472e-06  1.26562763e-05  2.64010851e-06  1.64457343e-05\n",
            "  1.19294107e-04 -3.13780581e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.237086   1.10536376 0.39558597 0.49540177 0.08186368 0.17987036\n",
            " 0.03745897 0.23377013 1.69818581 2.64957754] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.11416399] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03332591 0.15537507 0.0556054  0.06963598 0.01150714 0.02528342\n",
            " 0.00526541 0.03285982 0.2387049  0.37243695] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0242166961205066, delta shape : (2000, 10), delta[0] : [ 1.66629557e-05  7.76875370e-05  2.78027024e-05  3.48179893e-05\n",
            "  5.75357010e-06  1.26417076e-05  2.63270370e-06  1.64299087e-05\n",
            "  1.19352451e-04 -3.13781525e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23756515 1.10691747 0.39547828 0.49500039 0.08179148 0.17979761\n",
            " 0.03737609 0.2336974  1.7004237  2.65151012] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.11955768] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03336796 0.15547559 0.05554815 0.06952685 0.01148828 0.02525404\n",
            " 0.00524978 0.03282471 0.23883839 0.37242624] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0234809507124725, delta shape : (2000, 10), delta[0] : [ 1.66839822e-05  7.77377975e-05  2.77740764e-05  3.47634232e-05\n",
            "  5.74414079e-06  1.26270214e-05  2.62488828e-06  1.64123537e-05\n",
            "  1.19419195e-04 -3.13786879e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23805143 1.10856191 0.39533683 0.49462957 0.08172687 0.17972266\n",
            " 0.03729783 0.23363592 1.70257508 2.65344498] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.12498309] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03341081 0.15558801 0.055486   0.06942186 0.01147047 0.02522429\n",
            " 0.0052348  0.03279108 0.23895847 0.37241421] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0227492446805075, delta shape : (2000, 10), delta[0] : [ 1.67054032e-05  7.77940029e-05  2.77430016e-05  3.47109295e-05\n",
            "  5.73523281e-06  1.26121467e-05  2.61739797e-06  1.63955421e-05\n",
            "  1.19479236e-04 -3.13792893e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23853146 1.11019457 0.39520187 0.49426005 0.08166338 0.17964452\n",
            " 0.03721863 0.23356373 1.70471871 2.65545211] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.13044902] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03345252 0.15569771 0.05542454 0.06931682 0.01145277 0.025194\n",
            " 0.00521968 0.03275582 0.23907593 0.37241022] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0220190167530383, delta shape : (2000, 10), delta[0] : [ 1.67262580e-05  7.78488543e-05  2.77122706e-05  3.46584097e-05\n",
            "  5.72638382e-06  1.25969991e-05  2.60983758e-06  1.63779118e-05\n",
            "  1.19537963e-04 -3.13794888e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23901598 1.11183436 0.3950611  0.49391231 0.08160163 0.1795696\n",
            " 0.03714284 0.23349688 1.70680778 2.65739225] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.13583473] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03349517 0.15580999 0.05536298 0.06921577 0.01143547 0.02516448\n",
            " 0.00520512 0.03272173 0.23918824 0.37240104] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0212912245280736, delta shape : (2000, 10), delta[0] : [ 1.67475835e-05  7.79049967e-05  2.76814915e-05  3.46078859e-05\n",
            "  5.71773535e-06  1.25822419e-05  2.60255779e-06  1.63608668e-05\n",
            "  1.19594122e-04 -3.13799481e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23949963 1.1134049  0.3949415  0.49355168 0.08154489 0.17949627\n",
            " 0.03706821 0.23342022 1.70881438 2.65942677] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.14116846] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03353788 0.15591355 0.05530488 0.06911357 0.01141898 0.02513542\n",
            " 0.00519078 0.03268656 0.23929058 0.37240779] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0205633697757897, delta shape : (2000, 10), delta[0] : [ 1.67689388e-05  7.79567732e-05  2.76524422e-05  3.45567872e-05\n",
            "  5.70949198e-06  1.25677103e-05  2.59538849e-06  1.63432795e-05\n",
            "  1.19645292e-04 -3.13796104e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.23998322 1.11507777 0.39479858 0.49322102 0.08148671 0.17942332\n",
            " 0.03699389 0.23334119 1.71074667 2.66149371] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.14656607] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03358021 0.15602987 0.05524312 0.06901511 0.01140222 0.02510623\n",
            " 0.00517646 0.03265081 0.23938024 0.37241574] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0198355709531266, delta shape : (2000, 10), delta[0] : [ 1.67901073e-05  7.80149350e-05  2.76215578e-05  3.45075531e-05\n",
            "  5.70110930e-06  1.25531139e-05  2.58822857e-06  1.63254062e-05\n",
            "  1.19690118e-04 -3.13792129e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24047236 1.11670635 0.39467455 0.49288126 0.0814266  0.17935126\n",
            " 0.03691893 0.23325428 1.7126836  2.66359067] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.15195985] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03362328 0.15613991 0.05518411 0.06891555 0.01138521 0.02507722\n",
            " 0.00516207 0.03261404 0.23947053 0.37242808] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0191100611202972, delta shape : (2000, 10), delta[0] : [ 1.68116409e-05  7.80699535e-05  2.75920555e-05  3.44577759e-05\n",
            "  5.69260736e-06  1.25386090e-05  2.58103611e-06  1.63070184e-05\n",
            "  1.19735264e-04 -3.13785960e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2409588  1.11834229 0.39454009 0.49257295 0.08137024 0.17927916\n",
            " 0.03684667 0.23317368 1.71448787 2.66574081] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.15731255] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0336661  0.15625171 0.05512405 0.06882094 0.01136883 0.02504839\n",
            " 0.00514811 0.03257838 0.23954352 0.37244996] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0183862461044186, delta shape : (2000, 10), delta[0] : [ 1.68330503e-05  7.81258525e-05  2.75620271e-05  3.44104678e-05\n",
            "  5.68441325e-06  1.25241950e-05  2.57405747e-06  1.62891920e-05\n",
            "  1.19771762e-04 -3.13775018e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24144052 1.1199651  0.39441197 0.49226076 0.08131379 0.17920831\n",
            " 0.03677307 0.23308724 1.71629194 2.66793868] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.16269138] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03370807 0.15636093 0.05506477 0.06872567 0.01135241 0.02501969\n",
            " 0.00513397 0.03254185 0.23961551 0.37247712] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0176628338995997, delta shape : (2000, 10), delta[0] : [ 1.68540360e-05  7.81804658e-05  2.75323860e-05  3.43628350e-05\n",
            "  5.67620368e-06  1.25098444e-05  2.56698718e-06  1.62709261e-05\n",
            "  1.19807754e-04 -3.13761438e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24193045 1.12162088 0.3942844  0.49196503 0.08125927 0.17913676\n",
            " 0.03670011 0.2329864  1.71799835 2.67013562] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.16801727] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03375138 0.15647575 0.05500606 0.06863335 0.01133637 0.02499112\n",
            " 0.00511998 0.03250361 0.23967553 0.37250686] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0169406661653344, delta shape : (2000, 10), delta[0] : [ 1.68756885e-05  7.82378750e-05  2.75030310e-05  3.43166742e-05\n",
            "  5.66818332e-06  1.24955587e-05  2.55999000e-06  1.62518026e-05\n",
            "  1.19837766e-04 -3.13746569e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24242528 1.12325215 0.39413009 0.49164673 0.08120187 0.17905673\n",
            " 0.03662925 0.23288605 1.71962879 2.67235813] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.17321507] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0337959  0.15658978 0.05494469 0.06853924 0.01132015 0.02496185\n",
            " 0.00510639 0.03246606 0.23972915 0.37254677] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.016219191657854, delta shape : (2000, 10), delta[0] : [ 1.68979512e-05  7.82948887e-05  2.74723459e-05  3.42696214e-05\n",
            "  5.66007504e-06  1.24809260e-05  2.55319626e-06  1.62330312e-05\n",
            "  1.19864577e-04 -3.13726613e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24294704 1.12478599 0.39399882 0.49131183 0.08114446 0.17898359\n",
            " 0.03656065 0.23276589 1.72126142 2.67443098] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.17819067] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03384516 0.15669492 0.05488832 0.06844508 0.01130431 0.02493436\n",
            " 0.0050933  0.03242682 0.23979043 0.37257731] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0154974083145407, delta shape : (2000, 10), delta[0] : [ 1.69225817e-05  7.83474586e-05  2.74441596e-05  3.42225397e-05\n",
            "  5.65215280e-06  1.24671798e-05  2.54664776e-06  1.62134096e-05\n",
            "  1.19895215e-04 -3.13711344e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24345881 1.12637526 0.39385494 0.49099399 0.0810827  0.17891047\n",
            " 0.03649013 0.23264001 1.72280873 2.67645696] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.183072] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03389341 0.15680969 0.05483099 0.06835432 0.01128803 0.02490724\n",
            " 0.00508002 0.03238726 0.23984289 0.37260617] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.014775669469149, delta shape : (2000, 10), delta[0] : [ 1.69467052e-05  7.84048425e-05  2.74154945e-05  3.41771589e-05\n",
            "  5.64401267e-06  1.24536182e-05  2.54000878e-06  1.61936294e-05\n",
            "  1.19921444e-04 -3.13696914e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24398457 1.12790401 0.39371769 0.49060439 0.08102397 0.17883327\n",
            " 0.036419   0.2324904  1.72458501 2.67841225] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.18797458] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03394344 0.15691541 0.0547745  0.0682535  0.01127216 0.02487951\n",
            " 0.00506666 0.03234435 0.23992642 0.37262406] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0140547377965152, delta shape : (2000, 10), delta[0] : [ 1.69717194e-05  7.84577070e-05  2.73872486e-05  3.41267480e-05\n",
            "  5.63607796e-06  1.24397542e-05  2.53332853e-06  1.61721774e-05\n",
            "  1.19963210e-04 -3.13687971e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2445179  1.12940752 0.39355544 0.49021875 0.08096025 0.17875055\n",
            " 0.03635107 0.23233908 1.72611278 2.68030996] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.19252331] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03399612 0.15702522 0.0547173  0.06815671 0.01125617 0.02485227\n",
            " 0.00505401 0.03230286 0.2399871  0.37265225] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0133370115555245, delta shape : (2000, 10), delta[0] : [ 1.69980611e-05  7.85126077e-05  2.73586491e-05  3.40783565e-05\n",
            "  5.62808387e-06  1.24261362e-05  2.52700430e-06  1.61514302e-05\n",
            "  1.19993548e-04 -3.13673877e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24504474 1.13087405 0.39338721 0.48982825 0.0808963  0.17866782\n",
            " 0.03628098 0.23219992 1.72766109 2.68224518] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.19708554] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03404777 0.15712944 0.05465924 0.06805925 0.01124015 0.02482502\n",
            " 0.00504107 0.03226305 0.2400501  0.37268491] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.012620836150697, delta shape : (2000, 10), delta[0] : [ 1.70238870e-05  7.85647222e-05  2.73296190e-05  3.40296252e-05\n",
            "  5.62007324e-06  1.24125118e-05  2.52053304e-06  1.61315244e-05\n",
            "  1.20025049e-04 -3.13657545e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24557155 1.13235653 0.39321221 0.48942709 0.0808316  0.17858099\n",
            " 0.03620988 0.23204719 1.72921689 2.68424432] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.20169823] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03409912 0.15723465 0.05459993 0.06795995 0.01122396 0.02479707\n",
            " 0.00502796 0.03222118 0.24011238 0.3727238 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0119054342358984, delta shape : (2000, 10), delta[0] : [ 1.70495582e-05  7.86173274e-05  2.72999642e-05  3.39799774e-05\n",
            "  5.61198158e-06  1.23985331e-05  2.51398185e-06  1.61105881e-05\n",
            "  1.20056189e-04 -3.13638101e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2461061  1.13383898 0.39302855 0.48903488 0.08077164 0.17849101\n",
            " 0.03614069 0.23190407 1.73083087 2.68621084] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.20635765] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03415125 0.15733871 0.05453914 0.06786159 0.01120839 0.02476855\n",
            " 0.00501511 0.03218048 0.24018109 0.37275569] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.011188975811803, delta shape : (2000, 10), delta[0] : [ 1.70756238e-05  7.86693527e-05  2.72695702e-05  3.39307947e-05\n",
            "  5.60419312e-06  1.23842739e-05  2.50755569e-06  1.60902417e-05\n",
            "  1.20090547e-04 -3.13622153e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24666846 1.13523002 0.39289453 0.48868379 0.0807139  0.17842141\n",
            " 0.03607356 0.23176755 1.73248506 2.68812583] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.2110641] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03420694 0.15742892 0.05448496 0.06776861 0.01119306 0.02474273\n",
            " 0.00500253 0.03214055 0.24025373 0.37277797] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0104732576758155, delta shape : (2000, 10), delta[0] : [ 1.71034719e-05  7.87144587e-05  2.72424794e-05  3.38843050e-05\n",
            "  5.59653160e-06  1.23713645e-05  2.50126444e-06  1.60702741e-05\n",
            "  1.20126865e-04 -3.13611015e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24722462 1.13666917 0.39276651 0.48834114 0.08065979 0.17835355\n",
            " 0.03600774 0.2316346  1.73414807 2.69020003] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.21600522] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03426059 0.15752056 0.05442991 0.06767472 0.0111779  0.02471638\n",
            " 0.00498998 0.03210012 0.24031968 0.37281016] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.009758241825181, delta shape : (2000, 10), delta[0] : [ 1.71302965e-05  7.87602791e-05  2.72149549e-05  3.38373606e-05\n",
            "  5.58895009e-06  1.23581915e-05  2.49499102e-06  1.60500579e-05\n",
            "  1.20159841e-04 -3.13594922e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24776725 1.13812121 0.39264188 0.48803963 0.08060247 0.17829053\n",
            " 0.03594262 0.23150228 1.73561797 2.69226162] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.22078746] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03431305 0.15761733 0.0543766  0.06758814 0.01116256 0.02469129\n",
            " 0.00497766 0.03206053 0.24036409 0.37284876] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.009042311578255, delta shape : (2000, 10), delta[0] : [ 1.71565258e-05  7.88086630e-05  2.71883002e-05  3.37940723e-05\n",
            "  5.58127943e-06  1.23456431e-05  2.48882963e-06  1.60302656e-05\n",
            "  1.20182043e-04 -3.13575622e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24830169 1.1395367  0.39254027 0.48772921 0.080543   0.17823363\n",
            " 0.03587835 0.23136645 1.7371469  2.69428026] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.22555646] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03436437 0.1577092  0.05432665 0.06750057 0.01114696 0.02466711\n",
            " 0.00496548 0.03202057 0.24041704 0.37288204] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.008325631640013, delta shape : (2000, 10), delta[0] : [ 1.71821848e-05  7.88545983e-05  2.71633242e-05  3.37502872e-05\n",
            "  5.57348077e-06  1.23335572e-05  2.48273924e-06  1.60102860e-05\n",
            "  1.20208520e-04 -3.13558978e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24884611 1.14094858 0.39240401 0.48739698 0.08048393 0.17816814\n",
            " 0.03581523 0.23122807 1.73858329 2.69640386] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.23027819] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03441722 0.15780148 0.05427232 0.06741054 0.01113151 0.02464195\n",
            " 0.00495351 0.03198052 0.2404587  0.37293224] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.007609536369318, delta shape : (2000, 10), delta[0] : [ 1.72086124e-05  7.89007388e-05  2.71361624e-05  3.37052713e-05\n",
            "  5.56575592e-06  1.23209741e-05  2.47675304e-06  1.59902610e-05\n",
            "  1.20229350e-04 -3.13533879e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24938503 1.14232598 0.39226891 0.48707018 0.08042296 0.17810071\n",
            " 0.03575239 0.23109464 1.74003309 2.69849516] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.23494905] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03446949 0.15788998 0.05421861 0.06732185 0.0111159  0.02461672\n",
            " 0.00494162 0.03194143 0.24050385 0.37298053] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0068933133135363, delta shape : (2000, 10), delta[0] : [ 1.72347465e-05  7.89449915e-05  2.71093072e-05  3.36609265e-05\n",
            "  5.55794914e-06  1.23083594e-05  2.47081167e-06  1.59707167e-05\n",
            "  1.20251924e-04 -3.13509733e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.24992229 1.14372926 0.39214135 0.4867604  0.08036664 0.178039\n",
            " 0.03569055 0.23095811 1.7413891  2.70072235] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.23971905] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03452099 0.15797979 0.05416527 0.06723471 0.0111008  0.02459198\n",
            " 0.00492982 0.03190153 0.24053269 0.37304242] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0061753012450314, delta shape : (2000, 10), delta[0] : [ 1.72604963e-05  7.89898927e-05  2.70826362e-05  3.36173542e-05\n",
            "  5.55039801e-06  1.22959884e-05  2.46491243e-06  1.59507644e-05\n",
            "  1.20266345e-04 -3.13478788e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25044138 1.14518919 0.39200771 0.48645065 0.08030847 0.17797348\n",
            " 0.03563087 0.23084776 1.74288852 2.70296263] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.24470065] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03456891 0.15807267 0.05410958 0.06714572 0.01108513 0.02456602\n",
            " 0.0049182  0.03186436 0.24057426 0.37309514] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0054581674319487, delta shape : (2000, 10), delta[0] : [ 1.72844530e-05  7.90363360e-05  2.70547897e-05  3.35728603e-05\n",
            "  5.54256671e-06  1.22830114e-05  2.45909895e-06  1.59321807e-05\n",
            "  1.20287132e-04 -3.13452429e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25096093 1.14662977 0.39189231 0.48614268 0.08025151 0.17791206\n",
            " 0.03557272 0.23072865 1.74431509 2.7051753 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.24958102] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0346173  0.15816497 0.05405724 0.06705804 0.01106981 0.02454101\n",
            " 0.00490687 0.03182648 0.24060909 0.37314919] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0047408746182565, delta shape : (2000, 10), delta[0] : [ 1.73086506e-05  7.90824856e-05  2.70286180e-05  3.35290190e-05\n",
            "  5.53490652e-06  1.22705065e-05  2.45343280e-06  1.59132403e-05\n",
            "  1.20304545e-04 -3.13425404e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25148222 1.14816538 0.39177573 0.48584012 0.08019344 0.17785274\n",
            " 0.03551314 0.23061537 1.74575817 2.70742202] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.25461833] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03466512 0.15826682 0.05400363 0.06696977 0.01105412 0.0245158\n",
            " 0.00489525 0.03178877 0.24064094 0.37319979] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.00402391668141, delta shape : (2000, 10), delta[0] : [ 1.73325603e-05  7.91334105e-05  2.70018156e-05  3.34848851e-05\n",
            "  5.52706107e-06  1.22578978e-05  2.44762295e-06  1.58943831e-05\n",
            "  1.20320470e-04 -3.13400106e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2520045  1.14960376 0.39169311 0.48552643 0.08013654 0.17780252\n",
            " 0.03545656 0.23050537 1.74719427 2.70961792] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.25954097] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03471356 0.15835764 0.05395563 0.06688115 0.01103879 0.02449225\n",
            " 0.00488413 0.03175206 0.24067558 0.37324921] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0033098226660093, delta shape : (2000, 10), delta[0] : [ 1.73567794e-05  7.91788190e-05  2.69778152e-05  3.34405735e-05\n",
            "  5.51939411e-06  1.22461270e-05  2.44206620e-06  1.58760294e-05\n",
            "  1.20337792e-04 -3.13375396e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25253309 1.15105683 0.39159153 0.48522513 0.08007855 0.17775164\n",
            " 0.0353987  0.23040268 1.74861519 2.71176759] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.26442093] \n",
            "softmax shape : (2000, 10) , output[0] : [0.034763   0.15845129 0.0539054  0.06679474 0.01102339 0.0244688\n",
            " 0.00487289 0.03171659 0.24070951 0.37329439] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.002600044945139, delta shape : (2000, 10), delta[0] : [ 1.73815014e-05  7.92256426e-05  2.69527007e-05  3.33973718e-05\n",
            "  5.51169507e-06  1.22343986e-05  2.43644339e-06  1.58582964e-05\n",
            "  1.20354754e-04 -3.13352804e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25305843 1.15248923 0.3914684  0.48491239 0.08001418 0.17769465\n",
            " 0.03534189 0.23029507 1.74991845 2.71392441] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.26911711] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03481282 0.15854597 0.05385364 0.06670857 0.01100741 0.02444515\n",
            " 0.00486192 0.0316813  0.24073329 0.37334994] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.0018934097988796, delta shape : (2000, 10), delta[0] : [ 1.74064076e-05  7.92729856e-05  2.69268191e-05  3.33542837e-05\n",
            "  5.50370699e-06  1.22225746e-05  2.43096194e-06  1.58406491e-05\n",
            "  1.20366643e-04 -3.13325032e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25359733 1.15387271 0.39133819 0.48457492 0.07994874 0.17763348\n",
            " 0.03528353 0.23017895 1.7512222  2.71609211] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.27374215] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03486477 0.15863536 0.05380149 0.06661975 0.01099142 0.0244212\n",
            " 0.00485081 0.03164519 0.24075946 0.37341056] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.001187217572267, delta shape : (2000, 10), delta[0] : [ 1.74323839e-05  7.93176802e-05  2.69007467e-05  3.33098772e-05\n",
            "  5.49570877e-06  1.22105976e-05  2.42540448e-06  1.58225946e-05\n",
            "  1.20379728e-04 -3.13294721e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25413826 1.15529122 0.39120815 0.48422965 0.07988644 0.17757212\n",
            " 0.03522669 0.23005548 1.75253319 2.71827936] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.27842056] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03491668 0.15872829 0.05374904 0.0665295  0.01097579 0.02439707\n",
            " 0.00483988 0.03160789 0.24078482 0.37347105] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 2.000480812182484, delta shape : (2000, 10), delta[0] : [ 1.74583383e-05  7.93641428e-05  2.68745225e-05  3.32647479e-05\n",
            "  5.48789677e-06  1.21985337e-05  2.41994075e-06  1.58039427e-05\n",
            "  1.20392410e-04 -3.13264476e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25468404 1.15668338 0.39108453 0.48389073 0.07982575 0.17751157\n",
            " 0.03517026 0.22992768 1.75377679 2.72046431] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.28301906] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03496957 0.15881922 0.05369813 0.06644095 0.01096053 0.02437335\n",
            " 0.00482908 0.03157038 0.24080354 0.37353525] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9997761988420297, delta shape : (2000, 10), delta[0] : [ 1.74847845e-05  7.94096083e-05  2.68490667e-05  3.32204770e-05\n",
            "  5.48026519e-06  1.21866751e-05  2.41453876e-06  1.57851904e-05\n",
            "  1.20401771e-04 -3.13232377e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25522457 1.15809997 0.39094074 0.48357787 0.07976659 0.17744423\n",
            " 0.0351152  0.22980402 1.7549386  2.7227833 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.2876951] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0350213  0.15891169 0.05364395 0.06635539 0.01094538 0.02434847\n",
            " 0.00481842 0.03153316 0.24080846 0.37361378] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9990722585288172, delta shape : (2000, 10), delta[0] : [ 1.75106512e-05  7.94558468e-05  2.68219745e-05  3.31776964e-05\n",
            "  5.47268957e-06  1.21742354e-05  2.40921151e-06  1.57665779e-05\n",
            "  1.20404228e-04 -3.13193111e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25576745 1.15953869 0.39079001 0.48328955 0.07970864 0.17737724\n",
            " 0.03506088 0.2296785  1.7561039  2.72512016] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.29243503] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03507298 0.15900569 0.05358841 0.06627273 0.01093032 0.02432346\n",
            " 0.00480784 0.03149545 0.24081173 0.37369139] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9983696024458462, delta shape : (2000, 10), delta[0] : [ 1.75364916e-05  7.95028470e-05  2.67942056e-05  3.31363632e-05\n",
            "  5.46515948e-06  1.21617290e-05  2.40392124e-06  1.57477236e-05\n",
            "  1.20405866e-04 -3.13154306e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25632033 1.16089371 0.39065451 0.48296043 0.07965272 0.17730853\n",
            " 0.03500615 0.22954643 1.75741375 2.7274072 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.29716375] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03512602 0.15908835 0.05353512 0.06618468 0.01091557 0.02429828\n",
            " 0.00479723 0.03145694 0.24083518 0.37376264] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.997667847469004, delta shape : (2000, 10), delta[0] : [ 1.75630110e-05  7.95441726e-05  2.67675579e-05  3.30923385e-05\n",
            "  5.45778598e-06  1.21491402e-05  2.39861359e-06  1.57284691e-05\n",
            "  1.20417590e-04 -3.13118679e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25686847 1.16231124 0.39051665 0.4826484  0.07959995 0.17723934\n",
            " 0.03495356 0.22940206 1.75864926 2.72971711] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.30190606] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03517828 0.15917916 0.05348147 0.06609896 0.01090126 0.02427302\n",
            " 0.00478691 0.03141674 0.24084797 0.37383624] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.996967237860233, delta shape : (2000, 10), delta[0] : [ 1.75891380e-05  7.95895781e-05  2.67407339e-05  3.30494804e-05\n",
            "  5.45062841e-06  1.21365120e-05  2.39345441e-06  1.57083686e-05\n",
            "  1.20423986e-04 -3.13081880e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25740458 1.16373215 0.39035841 0.48233571 0.07954786 0.17715645\n",
            " 0.03490187 0.22927191 1.75990043 2.73213911] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.30674849] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03522833 0.15926813 0.05342437 0.06601236 0.0108869  0.02424559\n",
            " 0.00477666 0.0313781  0.24085959 0.37391996] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9962658348858704, delta shape : (2000, 10), delta[0] : [ 1.76141674e-05  7.96340634e-05  2.67121835e-05  3.30061799e-05\n",
            "  5.44345151e-06  1.21227968e-05  2.38833109e-06  1.56890517e-05\n",
            "  1.20429794e-04 -3.13040020e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25793758 1.16520883 0.39020589 0.48203521 0.07949663 0.17707444\n",
            " 0.03485108 0.22913442 1.7610696  2.7345802 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.31159388] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03527789 0.15936454 0.0533681  0.06592751 0.01087268 0.02421831\n",
            " 0.00476655 0.03133851 0.24085988 0.37400603] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9955637317858008, delta shape : (2000, 10), delta[0] : [ 1.76389436e-05  7.96822723e-05  2.66840508e-05  3.29637568e-05\n",
            "  5.43634068e-06  1.21091547e-05  2.38327528e-06  1.56692526e-05\n",
            "  1.20429938e-04 -3.12996985e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25847469 1.16659137 0.39003601 0.48171608 0.07943936 0.1769863\n",
            " 0.03479866 0.22899763 1.76220995 2.7370411 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.31629115] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03532865 0.1594512  0.05331062 0.06584157 0.01085787 0.02419071\n",
            " 0.00475633 0.03129969 0.2408611  0.37410227] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9948646748762864, delta shape : (2000, 10), delta[0] : [ 1.76643248e-05  7.97255977e-05  2.66553097e-05  3.29207841e-05\n",
            "  5.42893672e-06  1.20953567e-05  2.37816269e-06  1.56498437e-05\n",
            "  1.20430551e-04 -3.12948867e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25899988 1.16803288 0.38985817 0.48141387 0.0793823  0.17689681\n",
            " 0.03474665 0.22886204 1.76335522 2.73960078] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.32114861] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03537695 0.1595423  0.05325096 0.0657566  0.01084288 0.02416244\n",
            " 0.00474607 0.0312604  0.24085773 0.37420368] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9941653544566602, delta shape : (2000, 10), delta[0] : [ 1.76884732e-05  7.97711492e-05  2.66254786e-05  3.28783021e-05\n",
            "  5.42143761e-06  1.20812197e-05  2.37303286e-06  1.56302007e-05\n",
            "  1.20428864e-04 -3.12898158e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.25952999 1.1694201  0.38969814 0.48107493 0.07932846 0.17680965\n",
            " 0.03469554 0.22872208 1.76450034 2.74206044] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.32583967] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03542665 0.1596295  0.05319501 0.06566823 0.01082858 0.02413507\n",
            " 0.00473605 0.03122128 0.24085981 0.37429982] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9934696131869774, delta shape : (2000, 10), delta[0] : [ 1.77133271e-05  7.98147482e-05  2.65975069e-05  3.28341152e-05\n",
            "  5.41429115e-06  1.20675348e-05  2.36802483e-06  1.56106394e-05\n",
            "  1.20429904e-04 -3.12850092e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26006366 1.17081274 0.38954612 0.48073726 0.07927068 0.17672565\n",
            " 0.03464203 0.22857534 1.76564133 2.74447892] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.33049373] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03547696 0.15971813 0.0531405  0.06558048 0.01081383 0.02410829\n",
            " 0.00472574 0.03118144 0.24086254 0.3743921 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9927756118786786, delta shape : (2000, 10), delta[0] : [ 1.77384818e-05  7.98590640e-05  2.65702513e-05  3.27902377e-05\n",
            "  5.40691256e-06  1.20541436e-05  2.36287167e-06  1.55907194e-05\n",
            "  1.20431270e-04 -3.12803951e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26058213 1.17218522 0.38939406 0.48039458 0.07921319 0.17664106\n",
            " 0.03458823 0.22843247 1.76677354 2.74694729] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.33515177] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03552512 0.15980381 0.05308603 0.06549211 0.01079912 0.02408145\n",
            " 0.00471541 0.03114216 0.24086394 0.37449086] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9920830330112473, delta shape : (2000, 10), delta[0] : [ 1.77625589e-05  7.99019063e-05  2.65430132e-05  3.27460560e-05\n",
            "  5.39956035e-06  1.20407230e-05  2.35770381e-06  1.55710802e-05\n",
            "  1.20431969e-04 -3.12754570e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26109226 1.17363405 0.38923954 0.48009243 0.07915325 0.17655691\n",
            " 0.03453623 0.22828894 1.76789112 2.74934896] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.3398337] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03557196 0.15989927 0.05303111 0.06540917 0.01078407 0.02405462\n",
            " 0.00470532 0.03110274 0.24086256 0.37457919] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.99139191854814, delta shape : (2000, 10), delta[0] : [ 1.77859796e-05  7.99496347e-05  2.65155559e-05  3.27045850e-05\n",
            "  5.39203316e-06  1.20273101e-05  2.35265766e-06  1.55513700e-05\n",
            "  1.20431279e-04 -3.12710405e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26160071 1.17506014 0.38908642 0.4797945  0.07909332 0.17647294\n",
            " 0.03448383 0.22814565 1.76899567 2.7518096 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.34454279] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03561838 0.15999092 0.05297626 0.06532667 0.01076899 0.02402776\n",
            " 0.00469516 0.03106329 0.24085852 0.37467405] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9907015888780162, delta shape : (2000, 10), delta[0] : [ 1.78091895e-05  7.99954588e-05  2.64881309e-05  3.26633332e-05\n",
            "  5.38449591e-06  1.20138820e-05  2.34758189e-06  1.55316443e-05\n",
            "  1.20429258e-04 -3.12662974e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26208134 1.17651093 0.38891002 0.47951861 0.0790311  0.17638964\n",
            " 0.03443208 0.22800868 1.77008414 2.75462043] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.34958699] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03565933 0.16007851 0.0529159  0.06524429 0.01075313 0.02399994\n",
            " 0.0046849  0.03102333 0.24084131 0.37479935] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9900110510684406, delta shape : (2000, 10), delta[0] : [ 1.78296648e-05  8.00392547e-05  2.64579509e-05  3.26221469e-05\n",
            "  5.37656743e-06  1.19999698e-05  2.34245000e-06  1.55116659e-05\n",
            "  1.20420654e-04 -3.12600324e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26255854 1.17792812 0.38873858 0.47924141 0.0789679  0.17630632\n",
            " 0.03437868 0.22787134 1.77118578 2.75747347] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.35465015] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03569966 0.160161   0.05285616 0.06516169 0.01073714 0.02397209\n",
            " 0.00467441 0.0309833  0.24082529 0.37492925] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9893219277637246, delta shape : (2000, 10), delta[0] : [ 1.78498322e-05  8.00804997e-05  2.64280813e-05  3.25808432e-05\n",
            "  5.36856946e-06  1.19860442e-05  2.33720699e-06  1.54916507e-05\n",
            "  1.20412647e-04 -3.12535375e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26302898 1.17934405 0.38856591 0.47895764 0.07890034 0.17623473\n",
            " 0.03432603 0.22775442 1.77213805 2.760292  ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.35954214] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03573986 0.16024693 0.05279757 0.06507981 0.01072082 0.02394643\n",
            " 0.00466415 0.03094682 0.24079461 0.37506301] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9886347063872762, delta shape : (2000, 10), delta[0] : [ 1.78699284e-05  8.01234661e-05  2.63987832e-05  3.25399072e-05\n",
            "  5.36041083e-06  1.19732127e-05  2.33207671e-06  1.54734093e-05\n",
            "  1.20397303e-04 -3.12468497e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26350231 1.18072667 0.38839661 0.4786776  0.07882545 0.17617035\n",
            " 0.03427073 0.22764032 1.7731101  2.76309554] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.36441568] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03578048 0.16032863 0.05273964 0.06499872 0.01070356 0.02392184\n",
            " 0.00465356 0.03091085 0.24076725 0.37519549] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9879511251997146, delta shape : (2000, 10), delta[0] : [ 1.78902388e-05  8.01643145e-05  2.63698183e-05  3.24993607e-05\n",
            "  5.35177899e-06  1.19609182e-05  2.32677834e-06  1.54554231e-05\n",
            "  1.20383624e-04 -3.12402255e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26396951 1.18216158 0.38823484 0.47841437 0.0787555  0.17610327\n",
            " 0.03421938 0.22751731 1.77402403 2.76594804] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.36934783] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03581993 0.16041604 0.05268239 0.0649195  0.0106869  0.02389672\n",
            " 0.00464347 0.03087347 0.24073013 0.37533145] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9872695059581025, delta shape : (2000, 10), delta[0] : [ 1.79099644e-05  8.02080187e-05  2.63411940e-05  3.24597492e-05\n",
            "  5.34345139e-06  1.19483622e-05  2.32173720e-06  1.54367330e-05\n",
            "  1.20365063e-04 -3.12334273e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26443592 1.18354788 0.38808485 0.47812798 0.07868354 0.17603811\n",
            " 0.03416698 0.22739044 1.77492903 2.76889634] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.37430107] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03585912 0.16049628 0.05262666 0.06483706 0.01066997 0.02387184\n",
            " 0.00463325 0.03083552 0.24069115 0.37547916] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9865888545088104, delta shape : (2000, 10), delta[0] : [ 1.79295584e-05  8.02481392e-05  2.63133313e-05  3.24185287e-05\n",
            "  5.33498263e-06  1.19359182e-05  2.31662484e-06  1.54177623e-05\n",
            "  1.20345577e-04 -3.12260422e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26489917 1.18496509 0.38793473 0.47785258 0.07861237 0.17597488\n",
            " 0.03411542 0.22727475 1.77584111 2.77184741] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.3793175] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03589752 0.16057923 0.05257054 0.06475566 0.01065307 0.02384704\n",
            " 0.00462311 0.03079888 0.24065113 0.37562382] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9859083759556133, delta shape : (2000, 10), delta[0] : [ 1.79487579e-05  8.02896129e-05  2.62852714e-05  3.23778303e-05\n",
            "  5.32653396e-06  1.19235201e-05  2.31155630e-06  1.53994423e-05\n",
            "  1.20325566e-04 -3.12188091e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26535956 1.18632061 0.38779063 0.47756166 0.07854167 0.17591191\n",
            " 0.03406319 0.22716379 1.77677367 2.77483175] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.38431845] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03593555 0.16065404 0.05251543 0.06467241 0.01063628 0.02382236\n",
            " 0.00461291 0.030763   0.24061444 0.37577358] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9852275417430973, delta shape : (2000, 10), delta[0] : [ 1.79677761e-05  8.03270211e-05  2.62577131e-05  3.23362041e-05\n",
            "  5.31813967e-06  1.19111815e-05  2.30645447e-06  1.53815002e-05\n",
            "  1.20307221e-04 -3.12113212e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26581781 1.18767704 0.38765382 0.47727627 0.07846995 0.17585105\n",
            " 0.03401045 0.22704538 1.77775556 2.77784714] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.38940447] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03597283 0.16072703 0.05246077 0.06458927 0.01061925 0.02379773\n",
            " 0.0046026  0.0307258  0.24058171 0.37592301] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9845461911083306, delta shape : (2000, 10), delta[0] : [ 1.79864163e-05  8.03635156e-05  2.62303831e-05  3.22946369e-05\n",
            "  5.30962638e-06  1.18988648e-05  2.30129852e-06  1.53629011e-05\n",
            "  1.20290855e-04 -3.12038497e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26627882 1.18908604 0.38750615 0.47699844 0.07839788 0.17578861\n",
            " 0.03395675 0.22692523 1.77872341 2.78077992] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.39444125] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03601067 0.1608081  0.05240506 0.06450771 0.01060227 0.02377308\n",
            " 0.0045922  0.03068862 0.24054872 0.37606356] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9838652100893324, delta shape : (2000, 10), delta[0] : [ 1.80053372e-05  8.04040493e-05  2.62025311e-05  3.22538530e-05\n",
            "  5.30113626e-06  1.18865377e-05  2.29609992e-06  1.53443123e-05\n",
            "  1.20274362e-04 -3.11968219e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26673886 1.19042541 0.38736881 0.4767089  0.07832714 0.17572596\n",
            " 0.03390173 0.2268029  1.77972446 2.78379333] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.39951749] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03604814 0.16087879 0.05235055 0.06442432 0.01058544 0.0237483\n",
            " 0.00458161 0.03065104 0.24051899 0.37621282] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9831851906268865, delta shape : (2000, 10), delta[0] : [ 1.80240710e-05  8.04393945e-05  2.61752747e-05  3.22121609e-05\n",
            "  5.29271921e-06  1.18741499e-05  2.29080703e-06  1.53255194e-05\n",
            "  1.20259494e-04 -3.11893591e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26717074 1.19180555 0.38720444 0.47641819 0.07825549 0.17566078\n",
            " 0.03384577 0.22668967 1.78062706 2.78693189] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.40460958] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03608168 0.16095454 0.05229235 0.06434076 0.01056848 0.02372317\n",
            " 0.00457091 0.03061467 0.24047548 0.37637796] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9825071712286446, delta shape : (2000, 10), delta[0] : [ 1.80408392e-05  8.04772717e-05  2.61461752e-05  3.21703787e-05\n",
            "  5.28424115e-06  1.18615831e-05  2.28545288e-06  1.53073344e-05\n",
            "  1.20237741e-04 -3.11811018e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2676097  1.1932492  0.38703793 0.47613232 0.0781895  0.17558628\n",
            " 0.03379142 0.22656823 1.78152463 2.79028559] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.40997481] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03611479 0.16103283 0.05223202 0.06425559 0.01055193 0.02369594\n",
            " 0.00456026 0.03057611 0.24042249 0.37655804] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9818302699534964, delta shape : (2000, 10), delta[0] : [ 1.80573958e-05  8.05164144e-05  2.61160084e-05  3.21277959e-05\n",
            "  5.27596290e-06  1.18479676e-05  2.28013066e-06  1.52880570e-05\n",
            "  1.20211247e-04 -3.11720980e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26805092 1.19467944 0.38686182 0.47586535 0.0781212  0.17551286\n",
            " 0.03373477 0.22645322 1.78238426 2.79348699] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.41515083] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03614909 0.1611133  0.05217181 0.06417474 0.01053535 0.02366949\n",
            " 0.00454944 0.03053926 0.2403706  0.37672693] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9811542499934547, delta shape : (2000, 10), delta[0] : [ 1.80745429e-05  8.05566515e-05  2.60859039e-05  3.20873681e-05\n",
            "  5.26767429e-06  1.18347461e-05  2.27471903e-06  1.52696301e-05\n",
            "  1.20185301e-04 -3.11636536e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26849432 1.1961391  0.38671854 0.47561321 0.07806003 0.17544811\n",
            " 0.03367968 0.22633994 1.78336336 2.79664941] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.42050571] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03618275 0.16119374 0.05211485 0.06409445 0.0105195  0.02364369\n",
            " 0.00453873 0.03050196 0.24032909 0.37688124] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9804789252186816, delta shape : (2000, 10), delta[0] : [ 1.80913764e-05  8.05968721e-05  2.60574248e-05  3.20472235e-05\n",
            "  5.25975153e-06  1.18218434e-05  2.26936553e-06  1.52509778e-05\n",
            "  1.20164544e-04 -3.11559379e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2689459  1.19762462 0.3865611  0.47533504 0.07800123 0.1753745\n",
            " 0.03362395 0.22622148 1.78446847 2.79971449] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.42587079] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03621742 0.16127733 0.052056   0.06401068 0.01050398 0.02361669\n",
            " 0.00452795 0.03046397 0.24030427 0.37702171] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9798048167617082, delta shape : (2000, 10), delta[0] : [ 1.81087114e-05  8.06386657e-05  2.60279982e-05  3.20053398e-05\n",
            "  5.25199227e-06  1.18083456e-05  2.26397366e-06  1.52319831e-05\n",
            "  1.20152136e-04 -3.11489146e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26940472 1.19909032 0.38640328 0.47505903 0.07794082 0.17530245\n",
            " 0.03356856 0.22610204 1.78558207 2.80256245] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.43101573] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03625409 0.16136291 0.05199872 0.06392922 0.01048858 0.02359064\n",
            " 0.00451736 0.0304268  0.24028775 0.37714393] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9791315494740818, delta shape : (2000, 10), delta[0] : [ 1.81270454e-05  8.06814546e-05  2.59993582e-05  3.19646094e-05\n",
            "  5.24429088e-06  1.17953223e-05  2.25867895e-06  1.52134009e-05\n",
            "  1.20143876e-04 -3.11428037e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.26985481 1.20059448 0.38625396 0.47477631 0.07788291 0.17522821\n",
            " 0.03351526 0.22598007 1.78671392 2.80564904] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.43644897] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03628813 0.16144728 0.05194065 0.06384449 0.01047313 0.02356343\n",
            " 0.00450689 0.03038817 0.2402644  0.37728344] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9784587047074855, delta shape : (2000, 10), delta[0] : [ 1.81440640e-05  8.07236415e-05  2.59703230e-05  3.19222462e-05\n",
            "  5.23656580e-06  1.17817129e-05  2.25344492e-06  1.51940845e-05\n",
            "  1.20132198e-04 -3.11358281e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27030922 1.20206517 0.38612151 0.47448077 0.07782558 0.17515656\n",
            " 0.03346092 0.22584905 1.78787582 2.80869627] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.44184086] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0363229  0.16152793 0.05188521 0.06375852 0.01045784 0.02353672\n",
            " 0.00449632 0.03034855 0.24024645 0.37741956] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9777861143782642, delta shape : (2000, 10), delta[0] : [ 1.81614483e-05  8.07639667e-05  2.59426072e-05  3.18792607e-05\n",
            "  5.22891988e-06  1.17683623e-05  2.24816136e-06  1.51742729e-05\n",
            "  1.20123223e-04 -3.11290222e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27075829 1.20352876 0.38598395 0.47420835 0.07776649 0.17508628\n",
            " 0.03340651 0.22571514 1.78892058 2.81172488] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.44709921] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03635755 0.16161041 0.05183011 0.06367692 0.01044252 0.02351067\n",
            " 0.00448584 0.03030914 0.2402171  0.37755974] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9771145648472688, delta shape : (2000, 10), delta[0] : [ 1.81787753e-05  8.08052052e-05  2.59150538e-05  3.18384606e-05\n",
            "  5.22126026e-06  1.17553339e-05  2.24292097e-06  1.51545675e-05\n",
            "  1.20108550e-04 -3.11220128e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27121352 1.20498799 0.38584194 0.47393452 0.0777067  0.17501649\n",
            " 0.03335141 0.22557853 1.78993398 2.81453144] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.45209652] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03639426 0.16169785 0.05177629 0.06359747 0.0104275  0.02348554\n",
            " 0.00447544 0.03027048 0.240192   0.37768317] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9764445557863362, delta shape : (2000, 10), delta[0] : [ 1.81971285e-05  8.08489254e-05  2.58881470e-05  3.17987373e-05\n",
            "  5.21374771e-06  1.17427687e-05  2.23771995e-06  1.51352396e-05\n",
            "  1.20096001e-04 -3.11158415e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27166363 1.20647383 0.3856965  0.47366151 0.07765238 0.17494182\n",
            " 0.03329752 0.22542937 1.7910501  2.8176071 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.45747376] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03642837 0.1617805  0.05171946 0.06351501 0.01041269 0.02345859\n",
            " 0.00446499 0.03022865 0.24016847 0.37782327] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9757748010623832, delta shape : (2000, 10), delta[0] : [ 1.82141864e-05  8.08902497e-05  2.58597291e-05  3.17575041e-05\n",
            "  5.20634624e-06  1.17292948e-05  2.23249343e-06  1.51143254e-05\n",
            "  1.20084237e-04 -3.11088366e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27212237 1.20790371 0.38557396 0.4733696  0.07759569 0.17487103\n",
            " 0.0332413  0.22527147 1.79216881 2.82056526] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.46268319] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03646441 0.16185917 0.05166693 0.06343155 0.01039783 0.02343273\n",
            " 0.00445434 0.03018639 0.24015073 0.37795592] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9751013373626367, delta shape : (2000, 10), delta[0] : [ 1.82322071e-05  8.09295850e-05  2.58334668e-05  3.17157773e-05\n",
            "  5.19891361e-06  1.17163642e-05  2.22716839e-06  1.50931952e-05\n",
            "  1.20075365e-04 -3.11022042e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27256442 1.20934676 0.38546109 0.47309128 0.07753929 0.17480321\n",
            " 0.03318515 0.22511198 1.7931604  2.82334831] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.46761189] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03649954 0.16194558 0.05161772 0.06335242 0.01038341 0.02340818\n",
            " 0.00444388 0.03014511 0.24012501 0.37807914] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9744281205166554, delta shape : (2000, 10), delta[0] : [ 1.82497714e-05  8.09727912e-05  2.58088595e-05  3.16762096e-05\n",
            "  5.19170623e-06  1.17040907e-05  2.22193828e-06  1.50725551e-05\n",
            "  1.20062506e-04 -3.10960428e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27302414 1.21074207 0.38536053 0.47284129 0.07748136 0.17473839\n",
            " 0.03313143 0.22494724 1.7941372  2.82638305] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.4727867] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03653579 0.16202016 0.05156852 0.0632751  0.01036847 0.0233833\n",
            " 0.00443361 0.03010219 0.24008944 0.37822343] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9737558497843124, delta shape : (2000, 10), delta[0] : [ 1.82678935e-05  8.10100782e-05  2.57842584e-05  3.16375477e-05\n",
            "  5.18423455e-06  1.16916487e-05  2.21680527e-06  1.50510950e-05\n",
            "  1.20044722e-04 -3.10888283e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2734919  1.21213168 0.38525169 0.4725664  0.07742601 0.17467367\n",
            " 0.03307553 0.22478213 1.7951013  2.82930896] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.47780927] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0365738  0.16209716 0.05151933 0.06319584 0.0103541  0.02335894\n",
            " 0.00442316 0.03005989 0.24005711 0.37836067] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.973085488997927, delta shape : (2000, 10), delta[0] : [ 1.82868998e-05  8.10485821e-05  2.57596629e-05  3.15979175e-05\n",
            "  5.17705184e-06  1.16794681e-05  2.21157878e-06  1.50299453e-05\n",
            "  1.20028556e-04 -3.10819663e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27394411 1.21347959 0.38513704 0.47227703 0.07737128 0.17460717\n",
            " 0.03301919 0.22461553 1.7960219  2.83238729] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.48286013] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03660955 0.16216788 0.05146923 0.06311451 0.0103398  0.02333428\n",
            " 0.00441264 0.03001734 0.2400181  0.37851667] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9724172492981256, delta shape : (2000, 10), delta[0] : [ 1.83047730e-05  8.10839420e-05  2.57346145e-05  3.15572535e-05\n",
            "  5.16989995e-06  1.16671408e-05  2.20632178e-06  1.50086681e-05\n",
            "  1.20009052e-04 -3.10741665e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27440024 1.2148228  0.38503724 0.4719819  0.07731269 0.17454661\n",
            " 0.03296179 0.22444773 1.79695538 2.83545989] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.48792626] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03664569 0.16223755 0.05142108 0.06303239 0.01032498 0.02331041\n",
            " 0.00440199 0.02997462 0.23998038 0.37867091] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.971749432935659, delta shape : (2000, 10), delta[0] : [ 1.83228459e-05  8.11187744e-05  2.57105390e-05  3.15161955e-05\n",
            "  5.16248992e-06  1.16552038e-05  2.20099596e-06  1.49873092e-05\n",
            "  1.19990189e-04 -3.10664543e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27485525 1.21622886 0.38492477 0.47168468 0.07725712 0.17447722\n",
            " 0.03290427 0.22427783 1.79788239 2.83861291] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.4931053] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03668109 0.16231306 0.05137053 0.06294916 0.01031043 0.02328504\n",
            " 0.00439127 0.02993123 0.23993823 0.37882998] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9710819846426058, delta shape : (2000, 10), delta[0] : [ 1.83405435e-05  8.11565307e-05  2.56852637e-05  3.14745799e-05\n",
            "  5.15521411e-06  1.16425176e-05  2.19563625e-06  1.49656129e-05\n",
            "  1.19969113e-04 -3.10585011e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27531951 1.21768873 0.38480691 0.47138902 0.0772029  0.17441392\n",
            " 0.03284747 0.22411257 1.79881034 2.84163111] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.49822248] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03671797 0.16239699 0.05131975 0.06286677 0.01029616 0.0232607\n",
            " 0.0043807  0.02988876 0.23989824 0.37897397] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9704154663589417, delta shape : (2000, 10), delta[0] : [ 1.83589851e-05  8.11984927e-05  2.56598757e-05  3.14333845e-05\n",
            "  5.14808038e-06  1.16303509e-05  2.19035019e-06  1.49443799e-05\n",
            "  1.19949118e-04 -3.10513017e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27578253 1.21912655 0.3846989  0.47110563 0.07715035 0.17435165\n",
            " 0.032792   0.22395125 1.79974621 2.84461859] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.50332366] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03675472 0.1624782  0.05127047 0.06278626 0.01028216 0.02323659\n",
            " 0.00437033 0.02984694 0.23985987 0.37911447] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9697485690138374, delta shape : (2000, 10), delta[0] : [ 1.83773579e-05  8.12391016e-05  2.56352330e-05  3.13931297e-05\n",
            "  5.14107860e-06  1.16182945e-05  2.18516472e-06  1.49234702e-05\n",
            "  1.19929933e-04 -3.10442764e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27622898 1.22061271 0.38456868 0.47084268 0.07710125 0.17428514\n",
            " 0.03273814 0.2237924  1.80055803 2.84778018] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.5085082] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0367888  0.16256394 0.05121772 0.06270789 0.01026852 0.02321169\n",
            " 0.00436014 0.02980518 0.23980237 0.37927377] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9690838609630137, delta shape : (2000, 10), delta[0] : [ 1.83943979e-05  8.12819722e-05  2.56088608e-05  3.13539435e-05\n",
            "  5.13425915e-06  1.16058433e-05  2.18006946e-06  1.49025876e-05\n",
            "  1.19901183e-04 -3.10363117e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27667841 1.22208555 0.38445066 0.4705812  0.07705191 0.17422438\n",
            " 0.03268525 0.2236418  1.80136736 2.85096315] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.51372967] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03682305 0.162647   0.05116642 0.06262951 0.01025482 0.02318747\n",
            " 0.00435007 0.02976442 0.23974343 0.37943382] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9684199046148998, delta shape : (2000, 10), delta[0] : [ 1.84115228e-05  8.13234977e-05  2.55832106e-05  3.13147545e-05\n",
            "  5.12740788e-06  1.15937346e-05  2.17503479e-06  1.48822098e-05\n",
            "  1.19871717e-04 -3.10283090e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27711123 1.22365431 0.38429869 0.47035573 0.07699851 0.174161\n",
            " 0.03263236 0.22350586 1.80202559 2.85392551] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.51866879] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03685642 0.1627488  0.0511126  0.06255838 0.01024098 0.02316381\n",
            " 0.00434018 0.02972679 0.23967349 0.37957856] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9677566201635175, delta shape : (2000, 10), delta[0] : [ 1.84282113e-05  8.13743989e-05  2.55562983e-05  3.12791891e-05\n",
            "  5.12048835e-06  1.15819039e-05  2.17008927e-06  1.48633933e-05\n",
            "  1.19836745e-04 -3.10210718e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27754544 1.22519912 0.38416166 0.47011019 0.07694845 0.17409554\n",
            " 0.03258054 0.22336626 1.80277665 2.85708963] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.52387347] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03688864 0.16284154 0.05105903 0.06248247 0.01022724 0.02313908\n",
            " 0.00433029 0.02968767 0.23960752 0.37973653] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9670944668379193, delta shape : (2000, 10), delta[0] : [ 1.84443185e-05  8.14207687e-05  2.55295134e-05  3.12412344e-05\n",
            "  5.11361910e-06  1.15695418e-05  2.16514429e-06  1.48438342e-05\n",
            "  1.19803759e-04 -3.10131733e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27797729 1.22667088 0.38404767 0.46985885 0.07689297 0.1740427\n",
            " 0.03252791 0.22323377 1.80350782 2.86014166] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.52890153] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03692136 0.16292827 0.05100979 0.06240736 0.01021304 0.02311661\n",
            " 0.00432041 0.02965024 0.23954462 0.37988831] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9664332938368483, delta shape : (2000, 10), delta[0] : [ 1.84606807e-05  8.14641337e-05  2.55048940e-05  3.12036786e-05\n",
            "  5.10652001e-06  1.15583062e-05  2.16020313e-06  1.48251222e-05\n",
            "  1.19772308e-04 -3.10055846e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27839746 1.22824868 0.38391215 0.46964374 0.07683664 0.17398764\n",
            " 0.0324755  0.22310549 1.80415384 2.86317917] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.5339403] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03695244 0.16302872 0.05095768 0.06233707 0.01019873 0.02309384\n",
            " 0.00431056 0.02961339 0.23947015 0.38003741] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9657734930292028, delta shape : (2000, 10), delta[0] : [ 1.84762188e-05  8.15143622e-05  2.54788420e-05  3.11685332e-05\n",
            "  5.09936608e-06  1.15469216e-05  2.15528007e-06  1.48066937e-05\n",
            "  1.19735077e-04 -3.09981294e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27881966 1.22971987 0.38379722 0.46940362 0.07678325 0.17393362\n",
            " 0.03242372 0.22297585 1.80486451 2.8663955 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.53911682] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03698307 0.16311193 0.05090745 0.06226241 0.01018465 0.02307082\n",
            " 0.00430073 0.02957586 0.23939999 0.38020309] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9651160314123366, delta shape : (2000, 10), delta[0] : [ 1.84915334e-05  8.15559636e-05  2.54537256e-05  3.11312074e-05\n",
            "  5.09232360e-06  1.15354111e-05  2.15036604e-06  1.47879290e-05\n",
            "  1.19699996e-04 -3.09898456e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.27923885 1.23128206 0.38365745 0.46918568 0.07673182 0.17387777\n",
            " 0.03237328 0.2228517  1.80544522 2.86958134] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.54422515] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03701359 0.16320855 0.05085445 0.06219137 0.01017093 0.0230478\n",
            " 0.00429113 0.02953937 0.23931486 0.38036793] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9644588787821686, delta shape : (2000, 10), delta[0] : [ 1.85067944e-05  8.16042755e-05  2.54272269e-05  3.10956838e-05\n",
            "  5.08546746e-06  1.15238985e-05  2.14556693e-06  1.47696875e-05\n",
            "  1.19657432e-04 -3.09816033e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2796561  1.23283403 0.38352279 0.46897185 0.07667981 0.17382308\n",
            " 0.0323223  0.2227256  1.80600546 2.87280907] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.5493501] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03704373 0.16330333 0.05080209 0.06212082 0.01015714 0.02302491\n",
            " 0.00428147 0.02950262 0.23922661 0.38053727] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9638023551302808, delta shape : (2000, 10), delta[0] : [ 1.85218658e-05  8.16516663e-05  2.54010471e-05  3.10604120e-05\n",
            "  5.07857045e-06  1.15124534e-05  2.14073368e-06  1.47513098e-05\n",
            "  1.19613307e-04 -3.09731365e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28007472 1.2343691  0.38338575 0.46876418 0.07662975 0.17376725\n",
            " 0.03227288 0.22260553 1.80658443 2.87605072] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.55450431] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03707387 0.16339512 0.05074929 0.06205095 0.01014358 0.02300181\n",
            " 0.004272   0.0294666  0.23914004 0.38070674] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9631451318846498, delta shape : (2000, 10), delta[0] : [ 1.85369359e-05  8.16975577e-05  2.53746462e-05  3.10254756e-05\n",
            "  5.07179185e-06  1.15009032e-05  2.13600235e-06  1.47332985e-05\n",
            "  1.19570018e-04 -3.09646629e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28047846 1.23589367 0.38323132 0.46856028 0.07657993 0.17370803\n",
            " 0.03222227 0.22249221 1.80693857 2.87918358] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.55928832] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03710382 0.16349339 0.05069675 0.06198471 0.01013057 0.02297942\n",
            " 0.00426261 0.02943296 0.23903554 0.38088024] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9624886530662864, delta shape : (2000, 10), delta[0] : [ 1.85519094e-05  8.17466945e-05  2.53483728e-05  3.09923538e-05\n",
            "  5.06528723e-06  1.14897081e-05  2.13130304e-06  1.47164786e-05\n",
            "  1.19517770e-04 -3.09559878e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28087171 1.23743855 0.38307294 0.46836732 0.07653078 0.17364782\n",
            " 0.03217258 0.22237987 1.80725517 2.88244715] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.56418389] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03713179 0.16359181 0.050643   0.06191908 0.01011752 0.02295658\n",
            " 0.00425328 0.02939906 0.23892269 0.38106519] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9618342626143859, delta shape : (2000, 10), delta[0] : [ 1.85658963e-05  8.17959058e-05  2.53214984e-05  3.09595410e-05\n",
            "  5.05875991e-06  1.14782918e-05  2.12663899e-06  1.46995283e-05\n",
            "  1.19461346e-04 -3.09467406e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28127757 1.23899554 0.38291017 0.46816704 0.07648343 0.17358755\n",
            " 0.03212085 0.22226605 1.80758259 2.88563878] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.56902957] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03716164 0.16369279 0.05058907 0.06185298 0.01010479 0.02293392\n",
            " 0.00424372 0.0293652  0.23881299 0.3812429 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9611808979945755, delta shape : (2000, 10), delta[0] : [ 1.85808214e-05  8.18463929e-05  2.52945352e-05  3.09264901e-05\n",
            "  5.05239332e-06  1.14669624e-05  2.12186053e-06  1.46825989e-05\n",
            "  1.19406495e-04 -3.09378550e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.281672   1.24057263 0.38274644 0.46799161 0.07643808 0.17352699\n",
            " 0.03206969 0.22214665 1.8078022  2.88896807] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.57393435] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03718965 0.16379501 0.05053469 0.06178976 0.01009226 0.02291108\n",
            " 0.00423422 0.02933042 0.23868733 0.38143558] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9605268793654447, delta shape : (2000, 10), delta[0] : [ 1.85948270e-05  8.18975036e-05  2.52673458e-05  3.08948816e-05\n",
            "  5.04612769e-06  1.14555382e-05  2.11710887e-06  1.46652084e-05\n",
            "  1.19343667e-04 -3.09282208e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28206807 1.24212768 0.38259046 0.46780351 0.07638913 0.17347227\n",
            " 0.03201743 0.22203519 1.80809346 2.89209689] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.57869409] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03721856 0.16389732 0.05048237 0.06172614 0.01007946 0.02288947\n",
            " 0.00422466 0.02929729 0.23857586 0.38160887] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9598748692095644, delta shape : (2000, 10), delta[0] : [ 1.86092792e-05  8.19486619e-05  2.52411865e-05  3.08630686e-05\n",
            "  5.03972885e-06  1.14447339e-05  2.11233134e-06  1.46486447e-05\n",
            "  1.19287930e-04 -3.09195565e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2824597  1.24368979 0.38244432 0.46759893 0.07634037 0.17342041\n",
            " 0.0319648  0.22191372 1.80841625 2.89526596] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.58351426] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03724654 0.16399914 0.05043101 0.06165993 0.01006662 0.02286808\n",
            " 0.00421504 0.02926265 0.23846678 0.3817842 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.959224277958726, delta shape : (2000, 10), delta[0] : [ 1.86232723e-05  8.19995684e-05  2.52155073e-05  3.08299634e-05\n",
            "  5.03331123e-06  1.14340400e-05  2.10751876e-06  1.46313246e-05\n",
            "  1.19233392e-04 -3.09107898e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28285188 1.24520975 0.3823145  0.46740513 0.07629044 0.17337289\n",
            " 0.03191268 0.22179256 1.80863367 2.89829838] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.58808188] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03727581 0.16410073 0.05038355 0.06159727 0.01005398 0.02284805\n",
            " 0.00420563 0.02922907 0.23835189 0.38195402] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9585748081498318, delta shape : (2000, 10), delta[0] : [ 1.86379038e-05  8.20503631e-05  2.51917751e-05  3.07986348e-05\n",
            "  5.02699092e-06  1.14240262e-05  2.10281591e-06  1.46145339e-05\n",
            "  1.19175946e-04 -3.09022990e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28323371 1.2466965  0.38217525 0.46719945 0.07624256 0.17332296\n",
            " 0.03186083 0.22167704 1.80886794 2.90138205] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.59265828] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03730363 0.16419763 0.05033484 0.06153305 0.01004162 0.02282771\n",
            " 0.00419627 0.02919624 0.23823908 0.38212994] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9579242306136444, delta shape : (2000, 10), delta[0] : [ 1.86518144e-05  8.20988152e-05  2.51674204e-05  3.07665268e-05\n",
            "  5.02080828e-06  1.14138525e-05  2.09813381e-06  1.45981179e-05\n",
            "  1.19119541e-04 -3.08935030e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28362949 1.24812002 0.38207601 0.46697821 0.07619205 0.17328447\n",
            " 0.03180784 0.22154711 1.80916166 2.90426437] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.59706122] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03733411 0.16428985 0.05029261 0.06146827 0.01002915 0.02280941\n",
            " 0.00418686 0.02916221 0.23813967 0.38228787] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9572736544378813, delta shape : (2000, 10), delta[0] : [ 1.86670531e-05  8.21449233e-05  2.51463030e-05  3.07341348e-05\n",
            "  5.01457382e-06  1.14047038e-05  2.09343040e-06  1.45811058e-05\n",
            "  1.19069836e-04 -3.08856064e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28401251 1.24953196 0.38195868 0.46676689 0.07613991 0.17324051\n",
            " 0.03175528 0.22141168 1.80935356 2.90711283] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.60128381] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03736376 0.16438433 0.05024923 0.06140632 0.01001672 0.02279095\n",
            " 0.00417762 0.0291282  0.23803263 0.38245024] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9566241175972645, delta shape : (2000, 10), delta[0] : [ 1.86818778e-05  8.21921662e-05  2.51246164e-05  3.07031614e-05\n",
            "  5.00835854e-06  1.13954772e-05  2.08880999e-06  1.45640976e-05\n",
            "  1.19016314e-04 -3.08774879e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28439815 1.25091215 0.38185187 0.46654616 0.07608833 0.17319844\n",
            " 0.03170331 0.22127784 1.80953887 2.90992407] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.60543919] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03739405 0.16447599 0.05020773 0.06134375 0.01000446 0.02277297\n",
            " 0.0041685  0.02909468 0.23792694 0.38261092] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.955975717000723, delta shape : (2000, 10), delta[0] : [ 1.86970236e-05  8.22379956e-05  2.51038672e-05  3.06718750e-05\n",
            "  5.00223089e-06  1.13864853e-05  2.08425220e-06  1.45473416e-05\n",
            "  1.18963470e-04 -3.08694541e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28477782 1.25228599 0.38175226 0.46633261 0.07603642 0.17315632\n",
            " 0.03165216 0.2211447  1.80972632 2.91277723] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.60964184] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03742329 0.16456569 0.05016692 0.06128181 0.00999211 0.02275486\n",
            " 0.00415948 0.02906112 0.23782017 0.38277455] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.955329466333892, delta shape : (2000, 10), delta[0] : [ 1.87116444e-05  8.22828471e-05  2.50834580e-05  3.06409041e-05\n",
            "  4.99605744e-06  1.13774292e-05  2.07974034e-06  1.45305588e-05\n",
            "  1.18910085e-04 -3.08612725e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28515155 1.25366813 0.38165092 0.46614574 0.07598243 0.17311822\n",
            " 0.03160146 0.22101743 1.80969963 2.91566306] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.61369856] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03745244 0.16465954 0.05012688 0.06122461 0.0099797  0.02273773\n",
            " 0.00415061 0.02902892 0.23768995 0.38294963] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9546849184671633, delta shape : (2000, 10), delta[0] : [ 1.87262176e-05  8.23297720e-05  2.50634376e-05  3.06123058e-05\n",
            "  4.98984985e-06  1.13688649e-05  2.07530263e-06  1.45144589e-05\n",
            "  1.18844975e-04 -3.08525184e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28551765 1.25503563 0.38156462 0.46594851 0.07593514 0.17308206\n",
            " 0.03155332 0.22089136 1.80951429 2.91861193] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.61765451] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03748104 0.16475355 0.05008952 0.06116693 0.00996831 0.02272117\n",
            " 0.00414213 0.02899729 0.23754218 0.38313787] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9540420541732633, delta shape : (2000, 10), delta[0] : [ 1.87405221e-05  8.23767756e-05  2.50447578e-05  3.05834627e-05\n",
            "  4.98415519e-06  1.13605874e-05  2.07106500e-06  1.44986466e-05\n",
            "  1.18771092e-04 -3.08431065e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28587747 1.25642501 0.38147678 0.46575335 0.07589235 0.17304254\n",
            " 0.03150497 0.22078051 1.80946208 2.92150701] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.62172206] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03750825 0.16484792 0.05005126 0.06110868 0.00995738 0.02270386\n",
            " 0.00413358 0.02896727 0.23740856 0.38331324] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.953399597891421, delta shape : (2000, 10), delta[0] : [ 1.87541259e-05  8.24239585e-05  2.50256291e-05  3.05543385e-05\n",
            "  4.97868795e-06  1.13519320e-05  2.06678790e-06  1.44836367e-05\n",
            "  1.18704281e-04 -3.08343378e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28623671 1.25781627 0.38138664 0.46556769 0.0758489  0.17300501\n",
            " 0.03145735 0.22066807 1.80936259 2.92435858] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.62570781] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03753576 0.1649442  0.05001328 0.06105239 0.00994647 0.02268708\n",
            " 0.00412517 0.02893739 0.23727143 0.38348684] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9527586605283922, delta shape : (2000, 10), delta[0] : [ 1.87678780e-05  8.24720997e-05  2.50066385e-05  3.05261954e-05\n",
            "  4.97323688e-06  1.13435379e-05  2.06258573e-06  1.44686941e-05\n",
            "  1.18635714e-04 -3.08256580e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28658728 1.25919907 0.38129204 0.46538518 0.07580317 0.1729665\n",
            " 0.03140924 0.22055945 1.8091737  2.92712051] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.62949614] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03756307 0.16504354 0.04997604 0.06099815 0.00993554 0.02267076\n",
            " 0.00411682 0.02890878 0.23712886 0.38365843] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9521196631189603, delta shape : (2000, 10), delta[0] : [ 1.87815338e-05  8.25217712e-05  2.49880225e-05  3.04990768e-05\n",
            "  4.96777049e-06  1.13353817e-05  2.05840838e-06  1.44543917e-05\n",
            "  1.18564428e-04 -3.08170785e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28694895 1.26062008 0.38118423 0.46517833 0.07575738 0.17292151\n",
            " 0.0313599  0.22044672 1.8091146  2.92996018] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.63349188] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03759079 0.1651433  0.04993576 0.06093913 0.00992434 0.022653\n",
            " 0.0041082  0.02887888 0.23699699 0.38382961] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9514824011522591, delta shape : (2000, 10), delta[0] : [ 1.87953926e-05  8.25716525e-05  2.49678807e-05  3.04695636e-05\n",
            "  4.96217066e-06  1.13265012e-05  2.05409916e-06  1.44394413e-05\n",
            "  1.18498495e-04 -3.08085197e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28729553 1.26204784 0.38109876 0.4650065  0.07571218 0.17288274\n",
            " 0.03131235 0.22033094 1.80897196 2.93276452] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.63742332] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03761681 0.16524524 0.04989887 0.06088526 0.00991331 0.02263626\n",
            " 0.00409986 0.02884886 0.23685632 0.38399921] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.95084676323465, delta shape : (2000, 10), delta[0] : [ 1.88084065e-05  8.26226194e-05  2.49494330e-05  3.04426300e-05\n",
            "  4.95665716e-06  1.13181325e-05  2.04992877e-06  1.44244289e-05\n",
            "  1.18428159e-04 -3.08000395e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28764458 1.26354193 0.38098555 0.46485564 0.0756648  0.17284231\n",
            " 0.03126329 0.22023311 1.80875198 2.93504956] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.64083274] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03764571 0.16536704 0.04986178 0.06083835 0.00990269 0.02262087\n",
            " 0.00409161 0.02882318 0.23672184 0.38412692] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9502113407164192, delta shape : (2000, 10), delta[0] : [ 1.88228552e-05  8.26835221e-05  2.49308919e-05  3.04191742e-05\n",
            "  4.95134527e-06  1.13104364e-05  2.04580393e-06  1.44115908e-05\n",
            "  1.18360920e-04 -3.07936539e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28798824 1.26496471 0.38089369 0.46469564 0.07561852 0.17280984\n",
            " 0.0312149  0.22012541 1.80837965 2.93735504] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.64404565] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03767485 0.16548367 0.04982881 0.06079185 0.00989247 0.02260712\n",
            " 0.00408356 0.02879698 0.23657363 0.38426707] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9495781387558841, delta shape : (2000, 10), delta[0] : [ 1.88374230e-05  8.27418340e-05  2.49144043e-05  3.03959228e-05\n",
            "  4.94623684e-06  1.13035587e-05  2.04177904e-06  1.43984889e-05\n",
            "  1.18286817e-04 -3.07866464e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28834155 1.26630934 0.3808146  0.46450371 0.07556608 0.17277674\n",
            " 0.03116602 0.22001214 1.80808821 2.93964208] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.64722047] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03770541 0.1655908  0.04979778 0.06074151 0.00988151 0.0225934\n",
            " 0.00407547 0.02877021 0.23643731 0.38440661] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.948946472435026, delta shape : (2000, 10), delta[0] : [ 1.88527031e-05  8.27953993e-05  2.48988896e-05  3.03707542e-05\n",
            "  4.94075445e-06  1.12967020e-05  2.03773536e-06  1.43851049e-05\n",
            "  1.18218653e-04 -3.07796696e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28868347 1.26768536 0.38073457 0.4643423  0.07551645 0.1727427\n",
            " 0.03111829 0.21990783 1.80783153 2.94185175] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.65041426] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03773436 0.16570153 0.04976653 0.06069505 0.0098709  0.02257952\n",
            " 0.00406753 0.02874457 0.23630505 0.38453496] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.948314839670502, delta shape : (2000, 10), delta[0] : [ 1.88671787e-05  8.28507656e-05  2.48832650e-05  3.03475266e-05\n",
            "  4.93544873e-06  1.12897613e-05  2.03376517e-06  1.43722827e-05\n",
            "  1.18152525e-04 -3.07732519e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2890252  1.26904583 0.38065728 0.46417111 0.07546808 0.17270862\n",
            " 0.03106912 0.21980334 1.8076894  2.94418433] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.6538223] \n",
            "softmax shape : (2000, 10) , output[0] : [0.0377622  0.1658055  0.04973427 0.06064566 0.00986018 0.02256502\n",
            " 0.00405929 0.02871811 0.23618126 0.3846685 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.947685056736454, delta shape : (2000, 10), delta[0] : [ 1.88811020e-05  8.29027500e-05  2.48671359e-05  3.03228306e-05\n",
            "  4.93009067e-06  1.12825075e-05  2.02964721e-06  1.43590571e-05\n",
            "  1.18090630e-04 -3.07665751e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.28937583 1.2703626  0.38056295 0.46399875 0.07541973 0.17267127\n",
            " 0.0310216  0.21969493 1.80744108 2.94663344] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.65718217] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03779143 0.16590471 0.04970013 0.06059654 0.00984954 0.02255024\n",
            " 0.00405131 0.02869136 0.2360452  0.38481956] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9470550168651464, delta shape : (2000, 10), delta[0] : [ 1.88957126e-05  8.29523560e-05  2.48500649e-05  3.02982702e-05\n",
            "  4.92477043e-06  1.12751181e-05  2.02565368e-06  1.43456775e-05\n",
            "  1.18022599e-04 -3.07590222e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2897186  1.27166979 0.38046544 0.46383692 0.07537449 0.17263451\n",
            " 0.03097476 0.2195928  1.80718141 2.94907818] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.6605269] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03781967 0.16600291 0.0496657  0.06054896 0.00983934 0.02253559\n",
            " 0.00404342 0.0286655  0.23590824 0.38497067] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9464247298654656, delta shape : (2000, 10), delta[0] : [ 1.89098349e-05  8.30014571e-05  2.48328507e-05  3.02744790e-05\n",
            "  4.91966770e-06  1.12677958e-05  2.02171197e-06  1.43327481e-05\n",
            "  1.17954119e-04 -3.07514665e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29006589 1.272996   0.3803816  0.46368352 0.07533086 0.17259936\n",
            " 0.03092754 0.21947714 1.80695667 2.95164726] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.66406584] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03784752 0.1660993  0.04963183 0.06050098 0.0098291  0.0225206\n",
            " 0.0040354  0.02863717 0.23576998 0.38512812] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9457941885387453, delta shape : (2000, 10), delta[0] : [ 1.89237601e-05  8.30496518e-05  2.48159143e-05  3.02504915e-05\n",
            "  4.91454963e-06  1.12603000e-05  2.01769778e-06  1.43185840e-05\n",
            "  1.17884991e-04 -3.07435940e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29040637 1.27431849 0.38029617 0.46354108 0.07528586 0.17256593\n",
            " 0.03088026 0.21936821 1.80664078 2.95416049] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.66746364] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03787515 0.16619818 0.04959869 0.0604556  0.00981887 0.02250626\n",
            " 0.00402744 0.02861027 0.2356243  0.38528523] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.945164760161953, delta shape : (2000, 10), delta[0] : [ 1.89375773e-05  8.30990894e-05  2.47993459e-05  3.02277975e-05\n",
            "  4.90943692e-06  1.12531301e-05  2.01372070e-06  1.43051354e-05\n",
            "  1.17812152e-04 -3.07357385e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29076927 1.27559056 0.38021916 0.46336051 0.07524396 0.17252726\n",
            " 0.03083245 0.21925561 1.80659682 2.95673831] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.6711339] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03790434 0.16628449 0.04956492 0.06040313 0.00980871 0.02249045\n",
            " 0.00401928 0.0285819  0.23550584 0.38543693] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9445364606134072, delta shape : (2000, 10), delta[0] : [ 1.89521702e-05  8.31422432e-05  2.47824612e-05  3.02015657e-05\n",
            "  4.90435714e-06  1.12452255e-05  2.00964084e-06  1.42909517e-05\n",
            "  1.17752919e-04 -3.07281535e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29113254 1.27689323 0.38013648 0.46316658 0.07519979 0.17249068\n",
            " 0.03078154 0.21915263 1.80663416 2.95908162] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.67466925] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03793421 0.16637762 0.04953132 0.06035004 0.00979844 0.02247532\n",
            " 0.0040108  0.02855532 0.23540222 0.38556471] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.943909821864375, delta shape : (2000, 10), delta[0] : [ 1.89671064e-05  8.31888118e-05  2.47656588e-05  3.01750187e-05\n",
            "  4.89922048e-06  1.12376624e-05  2.00539864e-06  1.42776594e-05\n",
            "  1.17701109e-04 -3.07217645e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29149507 1.27819215 0.38005051 0.46297326 0.07516036 0.17245017\n",
            " 0.03073212 0.21903801 1.80658174 2.96164229] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.67831568] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03796341 0.16646778 0.0494966  0.0602962  0.00978865 0.02245937\n",
            " 0.00400246 0.02852683 0.2352836  0.3857151 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.943284362741062, delta shape : (2000, 10), delta[0] : [ 1.89817068e-05  8.32338892e-05  2.47482991e-05  3.01481000e-05\n",
            "  4.89432614e-06  1.12296873e-05  2.00122826e-06  1.42634150e-05\n",
            "  1.17641799e-04 -3.07142451e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29186186 1.2795045  0.37997792 0.46276241 0.0751167  0.17241193\n",
            " 0.03068157 0.21892166 1.80673188 2.96420873] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.68217916] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03799207 0.16655489 0.04946226 0.06023843 0.00977805 0.0224431\n",
            " 0.00399386 0.02849734 0.23518481 0.38585519] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9426579648399422, delta shape : (2000, 10), delta[0] : [ 1.89960332e-05  8.32774445e-05  2.47311286e-05  3.01192147e-05\n",
            "  4.88902294e-06  1.12215513e-05  1.99693124e-06  1.42486695e-05\n",
            "  1.17592407e-04 -3.07072403e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29219983 1.28084584 0.37991099 0.46256011 0.07507198 0.17237305\n",
            " 0.03063301 0.21880635 1.80686693 2.96669839] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.68596648] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03801732 0.16664734 0.04942918 0.06018243 0.00976741 0.02242698\n",
            " 0.00398558 0.02846829 0.2350865  0.38598898] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9420312761884966, delta shape : (2000, 10), delta[0] : [ 1.90086587e-05  8.33236678e-05  2.47145877e-05  3.00912129e-05\n",
            "  4.88370491e-06  1.12134924e-05  1.99278833e-06  1.42341469e-05\n",
            "  1.17543248e-04 -3.07005508e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29252209 1.28210186 0.37984802 0.46234868 0.07502512 0.17234174\n",
            " 0.0305831  0.21869774 1.80698282 2.96933871] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.68978988] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03804032 0.16672782 0.04939641 0.06012501 0.00975646 0.02241176\n",
            " 0.0039771  0.02844001 0.23498468 0.38614042] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9414059306087161, delta shape : (2000, 10), delta[0] : [ 1.90201614e-05  8.33639076e-05  2.46982056e-05  3.00625042e-05\n",
            "  4.87822958e-06  1.12058807e-05  1.98855235e-06  1.42200075e-05\n",
            "  1.17492340e-04 -3.06929789e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29285374 1.28326085 0.37981907 0.46213744 0.07497354 0.17232319\n",
            " 0.03053286 0.21858333 1.80719902 2.9720068 ] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.69368985] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03806415 0.16679394 0.04936761 0.06006707 0.00974481 0.02239799\n",
            " 0.00396856 0.02841073 0.23489367 0.38629148] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9407820715913244, delta shape : (2000, 10), delta[0] : [ 1.90320734e-05  8.33969705e-05  2.46838044e-05  3.00335374e-05\n",
            "  4.87240483e-06  1.11989951e-05  1.98427911e-06  1.42053643e-05\n",
            "  1.17446834e-04 -3.06854262e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29316442 1.28444373 0.37977124 0.46195081 0.07492379 0.17229875\n",
            " 0.03048405 0.21847601 1.80731331 2.97485857] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.6976847] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03808475 0.16686105 0.04933578 0.06001166 0.00973329 0.02238319\n",
            " 0.00396016 0.02838204 0.23478661 0.38646147] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9401595268983973, delta shape : (2000, 10), delta[0] : [ 1.90423767e-05  8.34305233e-05  2.46678877e-05  3.00058286e-05\n",
            "  4.86664452e-06  1.11915959e-05  1.98007931e-06  1.41910213e-05\n",
            "  1.17393306e-04 -3.06769263e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29349041 1.28562078 0.37972468 0.46177083 0.07486913 0.17228167\n",
            " 0.03043468 0.21837364 1.80738518 2.97754907] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.70150006] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03810821 0.16693122 0.04930529 0.05995856 0.00972137 0.02236989\n",
            " 0.00395179 0.02835469 0.23467963 0.38661937] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9395384895059624, delta shape : (2000, 10), delta[0] : [ 1.90541067e-05  8.34656085e-05  2.46526438e-05  2.99792786e-05\n",
            "  4.86068485e-06  1.11849427e-05  1.97589302e-06  1.41773443e-05\n",
            "  1.17339815e-04 -3.06690317e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29376846 1.28660349 0.37952768 0.46146297 0.07480667 0.17227874\n",
            " 0.0303968  0.2182058  1.80753637 2.97914229] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.70372928] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03813328 0.16701047 0.04926545 0.05990124 0.00971045 0.02236303\n",
            " 0.00394573 0.0283247  0.23463135 0.3867143 ] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.938918883840588, delta shape : (2000, 10), delta[0] : [ 1.90666395e-05  8.35052374e-05  2.46327246e-05  2.99506225e-05\n",
            "  4.85522452e-06  1.11815155e-05  1.97286251e-06  1.41623490e-05\n",
            "  1.17315673e-04 -3.06642849e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29401604 1.28741705 0.37926447 0.46108049 0.07474024 0.17227711\n",
            " 0.03036151 0.21800576 1.80779376 2.98040386] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.7053603] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03815734 0.16708071 0.04922086 0.05983893 0.00969977 0.02235809\n",
            " 0.00394031 0.02829274 0.23461508 0.38679617] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9383012292119943, delta shape : (2000, 10), delta[0] : [ 1.90786692e-05  8.35403540e-05  2.46104303e-05  2.99194636e-05\n",
            "  4.84988601e-06  1.11790433e-05  1.97015508e-06  1.41463705e-05\n",
            "  1.17307542e-04 -3.06601915e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.2942629  1.28824222 0.37899828 0.46069736 0.07467317 0.17227244\n",
            " 0.03032636 0.21780591 1.8080227  2.98168061] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.70698195] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03818134 0.16715262 0.04917597 0.05977662 0.00968903 0.02235278\n",
            " 0.00393492 0.02826086 0.23459542 0.38688045] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9376846622138928, delta shape : (2000, 10), delta[0] : [ 1.90906703e-05  8.35763099e-05  2.45879828e-05  2.98883119e-05\n",
            "  4.84451451e-06  1.11763877e-05  1.96745994e-06  1.41304280e-05\n",
            "  1.17297712e-04 -3.06559777e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29449832 1.2890825  0.37874249 0.46033538 0.07461018 0.17226841\n",
            " 0.03029182 0.2176128  1.80828569 2.98305605] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.70878363] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03820296 0.16722256 0.04913129 0.0597157  0.00967859 0.02234703\n",
            " 0.00392952 0.0282292  0.23457471 0.38696845] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.937069424928935, delta shape : (2000, 10), delta[0] : [ 1.91014777e-05  8.36112778e-05  2.45656453e-05  2.98578478e-05\n",
            "  4.83929657e-06  1.11735142e-05  1.96475993e-06  1.41146004e-05\n",
            "  1.17287356e-04 -3.06515775e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29474974 1.28992877 0.37850055 0.45995879 0.07454645 0.17226466\n",
            " 0.03025737 0.2174128  1.80856202 2.98443971] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.71062087] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03822646 0.16729247 0.04908821 0.05965263 0.00966802 0.02234122\n",
            " 0.00392412 0.02819654 0.23455466 0.38705569] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.9364549453810034, delta shape : (2000, 10), delta[0] : [ 1.91132301e-05  8.36462326e-05  2.45441032e-05  2.98263137e-05\n",
            "  4.83401116e-06  1.11706089e-05  1.96205820e-06  1.40982678e-05\n",
            "  1.17277328e-04 -3.06472154e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "At forward, input.shape : (2000, 128), lin_output.shape : (2000, 64)\n",
            "At forward, input.shape : (2000, 64), lin_output.shape : (2000, 32)\n",
            "At forward, input.shape : (2000, 32), lin_output.shape : (2000, 10)\n",
            "softmax exp : (2000, 10) , exp[0] : [0.29496808 1.29079205 0.37825427 0.45960523 0.07448076 0.17225618\n",
            " 0.03022308 0.21722403 1.80886824 2.98582777] \n",
            "softmax sums : (2000, 1) , sums[0] : [7.7124997] \n",
            "softmax shape : (2000, 10) , output[0] : [0.03824546 0.16736364 0.04904432 0.05959225 0.00965715 0.02233468\n",
            " 0.00391871 0.02816519 0.23453722 0.38714138] \n",
            "softmax check : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "loss shape : () , loss[0] : 1.935840501632692, delta shape : (2000, 10), delta[0] : [ 1.91227291e-05  8.36818221e-05  2.45221578e-05  2.97961266e-05\n",
            "  4.82857430e-06  1.11673381e-05  1.95935685e-06  1.40825956e-05\n",
            "  1.17268610e-04 -3.06429310e-04]\n",
            "At Update, grad_W.shape : (128, 64), grad_b.shape : (1, 64),  W.shape : (128, 64), b.shape : (1, 64)\n",
            "At Update, grad_W.shape : (64, 32), grad_b.shape : (1, 32),  W.shape : (64, 32), b.shape : (1, 32)\n",
            "At Update, grad_W.shape : (32, 10), grad_b.shape : (1, 10),  W.shape : (32, 10), b.shape : (1, 10)\n",
            "loss:0.000968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T05l4p9mTQVZ"
      },
      "source": [
        "#### Plot loss in epochs\n",
        "We can visualize the loss change during the training process, to under how we can the network. As we can see, the loss stays at the large level at the beginning, but drop quickly within the training. A small loss value indicate a well-trained network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFAUpnzyTQVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1434294b-4f0c-4f87-cc84-69acb0896123"
      },
      "source": [
        "pl.figure(figsize=(15,4))\n",
        "pl.plot(MSE)\n",
        "pl.grid()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN93ZYW3TQVc"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpAUm5T7TQVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0667b05-3e87-4c5d-d7cd-d6de6f6e2702"
      },
      "source": [
        "output = nn.predict(input_sample_x)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n",
            "At forward, input.shape : (128,), lin_output.shape : (1, 3)\n",
            "At forward, input.shape : (1, 3), lin_output.shape : (1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9DTHUbXTQVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "e2a59332-117c-4173-d472-fa13cac09d50"
      },
      "source": [
        "# visualizing the predict results\n",
        "# notes: since we use tanh function for the final layer, that means the output will be in range of [0,1]\n",
        "pl.figure(figsize=(8,6))\n",
        "pl.scatter(input_sample_y, output, s=100)\n",
        "pl.xlabel('Targets')\n",
        "pl.ylabel('MLP output')\n",
        "pl.grid()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-4ad67abec03a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# notes: since we use tanh function for the final layer, that means the output will be in range of [0,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sample_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Targets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MLP output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2816\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2817\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}