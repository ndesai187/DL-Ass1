# Neural Netwrk without a library using Numpy

The aim of the study discussed in this report is to implement and train a multi-layer perceptron neural network on the provided training data set, and to test and evaluate the performance of this neural network on a hold-out testing data set. The implementation is using ***only standard numpy libraries and not any package.***

### Pre-Processing
1. One Hot Encoding
2. Normalizatin of input data

### Model
Techniques Used:
1. Weight intialisation
2. ReLU activation function
3. Weight decay
4. Momentum in stochastic gradient descent
5. Dropout
6. Softmax and cross-entropy loss
7. Mini-batch training
8. Batch normalisation

### Results Heatmap:
<p align="center">
  <img src="feature_heatmap.png" width="60%" alt="heatmap">
  <br/>
  <i>Predicted Labels Heatmap</i>
</p>
